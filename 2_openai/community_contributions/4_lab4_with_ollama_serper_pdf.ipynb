{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bb8bcb",
   "metadata": {},
   "source": [
    "# Week 2 Lab 4 Changes for usage of Ollama, free Search API, local pdf export\n",
    "\n",
    "Using Serper API for search and Ollama for the agent models as well as exporting the report not to a mail but pdf in the root dir of the notebook.\n",
    "\n",
    "# ToDos\n",
    "## Adding Requests and xhtml2pdf\n",
    "In Agents Root Dir run \"uv add Markdown requests xhtml2pdf && uv sync\"\n",
    "\n",
    "## Adding serper API Key to .env\n",
    "Register for free Serper API Key\n",
    "Add SERPER_API_KEY=xxx to .env-File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, trace, Runner, function_tool, OpenAIChatCompletionsModel\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "import requests\n",
    "from xhtml2pdf import pisa\n",
    "import webbrowser\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Ollama client for local Model\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"  # Default Ollama OpenAI-compatible endpoint\n",
    "ollama_client = AsyncOpenAI(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    api_key=\"ollama\"  # Ollama doesn't require a real API key, but OpenAI client needs something\n",
    ")\n",
    "\n",
    "# Add local Ollama model\n",
    "ollama_model = OpenAIChatCompletionsModel(\n",
    "    model=\"qwen3:8b\",  # This should match your Ollama model name\n",
    "    openai_client=ollama_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a013fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for the given query using Serper API\"\"\"\n",
    "    url = \"https://google.serper.dev/search\"\n",
    "    headers = {\n",
    "        \"X-API-Key\": os.environ.get(\"SERPER_API_KEY\"),\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\"q\": query}\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        results = response.json().get(\"organic\", [])\n",
    "        search_results = \"\\n\".join([f\"{result['title']}: {result['snippet']}\" for result in results[:5]])  # Limit to first 5 results\n",
    "        return search_results\n",
    "    else:\n",
    "        return \"Failed to retrieve search results\"\n",
    "\n",
    "@function_tool\n",
    "def search_web(query: str) -> str:\n",
    "    return do_search_web(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dbda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given a search term, you search the web for that term and \\\n",
    "produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300 \\\n",
    "words. Capture the main points. Write succintly, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\"\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[search_web],\n",
    "    model=ollama_model,\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See note above about cost of WebSearchTool\n",
    "\n",
    "HOW_MANY_SEARCHES = 3\n",
    "\n",
    "INSTRUCTIONS = f\"You are a helpful research assistant. Given a query, come up with a set of web searches \\\n",
    "to perform to best answer the query. Output {HOW_MANY_SEARCHES} terms to query for.\"\n",
    "\n",
    "# Use Pydantic to define the Schema of our response - this is known as \"Structured Outputs\"\n",
    "# With massive thanks to student Wes C. for discovering and fixing a nasty bug with this!\n",
    "\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this search is important to the query.\")\n",
    "\n",
    "    query: str = Field(description=\"The search term to use for the web search.\")\n",
    "\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem] = Field(description=\"A list of web searches to perform to best answer the query.\")\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[search_web],\n",
    "    model=ollama_model,\n",
    "    output_type=WebSearchPlan,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7749d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_save_to_pdf(subject: str, html_body: str) -> dict:\n",
    "    output_filename = \"output.pdf\"\n",
    "    with open(output_filename, \"w+b\") as f:\n",
    "        pisa_status = pisa.CreatePDF(html_body, dest=f)\n",
    "    if pisa_status.err:\n",
    "        return {\"status\": \"error\", \"message\": \"Failed to create PDF\"}\n",
    "    webbrowser.open(output_filename)\n",
    "    return {\"status\": \"success\", \"file\": output_filename}\n",
    "\n",
    "@function_tool\n",
    "def save_to_pdf(subject: str, html_body: str) -> dict:\n",
    "    return do_save_to_pdf(subject, html_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = do_save_to_pdf(\"Test Subject\", \"<h1>Hello, World!</h1><p>This is a test.</p>\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d129e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = \"\"\"You are able to save a nicely formatted PDFbased on a detailed report.\n",
    "You will be provided with a detailed report. You should use your tool to save the file, providing the \n",
    "report converted into clean, well presented HTML with an appropriate subject line.\"\"\"\n",
    "\n",
    "printing_agent = Agent(\n",
    "    name=\"PrintingAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[save_to_pdf],\n",
    "    model=ollama_model,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8455600",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\"\n",
    ")\n",
    "\n",
    "\n",
    "class ReportData(BaseModel):\n",
    "    short_summary: str = Field(description=\"A short 2-3 sentence summary of the findings.\")\n",
    "\n",
    "    markdown_report: str = Field(description=\"The final report\")\n",
    "\n",
    "    follow_up_questions: list[str] = Field(description=\"Suggested topics to research further\")\n",
    "\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=ollama_model,\n",
    "    output_type=ReportData,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ade501",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_searches(query: str):\n",
    "    \"\"\" Use the planner_agent to plan which searches to run for the query \"\"\"\n",
    "    print(\"Planning searches...\")\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    print(f\"Will perform {len(result.final_output.searches)} searches\")\n",
    "    return result.final_output\n",
    "\n",
    "async def perform_searches(search_plan: WebSearchPlan):\n",
    "    \"\"\" Call search() for each item in the search plan \"\"\"\n",
    "    print(\"Searching...\")\n",
    "    tasks = [asyncio.create_task(search(item)) for item in search_plan.searches]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(\"Finished searching\")\n",
    "    return results\n",
    "\n",
    "async def search(item: WebSearchItem):\n",
    "    \"\"\" Run the web search directly for each item in the search plan \"\"\"\n",
    "    return await asyncio.to_thread(do_search_web, item.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_report(query: str, search_results: list[str]):\n",
    "    \"\"\" Use the writer agent to write a report based on the search results\"\"\"\n",
    "    print(\"Thinking about report...\")\n",
    "    input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "    result = await Runner.run(writer_agent, input)\n",
    "    print(\"Finished writing report\")\n",
    "    return result.final_output\n",
    "\n",
    "async def save_pdf(report: ReportData):\n",
    "    \"\"\"Save the report as a PDF directly (bypass agent to avoid long tool-calling loops).\"\"\"\n",
    "    print(\"Writing File ...\")\n",
    "    subject = \"Research Report\"\n",
    "\n",
    "    # Convert Markdown -> HTML\n",
    "    body_html = markdown.markdown(report.markdown_report, extensions=[\"extra\"])\n",
    "\n",
    "    # Minimal print-friendly HTML + CSS (xhtml2pdf-compatible)\n",
    "    html_body = f\"\"\"<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>{subject}</title>\n",
    "    <style>\n",
    "      @page {{ size: A4; margin: 1in; }}\n",
    "      body {{ font-family: Helvetica, Arial, sans-serif; font-size: 12pt; line-height: 1.5; color: #222; }}\n",
    "      h1, h2, h3 {{ color: #111; margin: 0.4em 0 0.2em; }}\n",
    "      p {{ margin: 0.2em 0 0.6em; }}\n",
    "      ul, ol {{ margin: 0.2em 0 0.6em 1.2em; }}\n",
    "      code, pre {{ font-family: Courier, monospace; font-size: 10pt; background: #f6f8fa; padding: 2pt 4pt; }}\n",
    "      pre {{ white-space: pre-wrap; }}\n",
    "      table {{ border-collapse: collapse; width: 100%; margin: 0.6em 0; }}\n",
    "      th, td {{ border: 1px solid #ccc; padding: 6pt; }}\n",
    "      blockquote {{ border-left: 3pt solid #ccc; margin: 0.6em 0; padding: 0.1em 0 0.1em 0.6em; color: #555; }}\n",
    "      hr {{ border: 0; border-top: 1px solid #ccc; margin: 1em 0; }}\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>{subject}</h1>\n",
    "    {body_html}\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    _ = await asyncio.to_thread(do_save_to_pdf, subject, html_body)\n",
    "    print(\"File saved\")\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Research trace\"):\n",
    "    print(\"Starting research...\")\n",
    "    search_plan = await plan_searches(query)\n",
    "    search_results = await perform_searches(search_plan)\n",
    "    report = await write_report(query, search_results)\n",
    "    await save_pdf(report)  \n",
    "    print(\"Hooray!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
