{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›ï¸ Governance Research Agent\n",
    "\n",
    "## Building a Citation-Enforced, Forensically-Sound Annual Report Analyser\n",
    "\n",
    "**Source Documents:** 5 BHP Annual Reports (FY2016-2020)\n",
    "\n",
    "**Features:**\n",
    "- PDF extraction with page-level citations\n",
    "- Citation enforcement on every claim\n",
    "- Verification agent catches hallucinations\n",
    "- SHA256 hashes for forensic provenance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup\n",
    "\n",
    "### 1.1 Install Dependencies\n",
    "\n",
    "Uncomment and run if you haven't installed these packages yet:\n",
    "- `openai-agents` - OpenAI's agent orchestration SDK\n",
    "- `pydantic` - Data validation and structured outputs\n",
    "- `pymupdf` - PDF text extraction\n",
    "- `python-dotenv` - Environment variable management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - Install dependencies (uncomment if needed)\n",
    "# !pip install openai-agents pydantic python-dotenv pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries\n",
    "\n",
    "Import all required libraries:\n",
    "- Standard library: `os`, `json`, `hashlib`, `re`, `datetime`, `pathlib`\n",
    "- PDF extraction: `fitz` (PyMuPDF)\n",
    "- OpenAI Agents SDK: `Agent`, `Runner`, `function_tool`, `trace`\n",
    "- Pydantic: `BaseModel`, `Field`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 - Import libraries\n",
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# PDF extraction\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# OpenAI Agents SDK\n",
    "from agents import Agent, Runner, function_tool, trace, gen_trace_id\n",
    "\n",
    "# Pydantic for structured outputs\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Jupyter display\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Environment Variables\n",
    "\n",
    "Load API keys from `.env` file. Required:\n",
    "- `OPENAI_API_KEY` - Your OpenAI API key\n",
    "\n",
    "Make sure you have a `.env` file in your project root with:\n",
    "```\n",
    "OPENAI_API_KEY=sk-...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 - Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"âœ… OPENAI_API_KEY is set\")\n",
    "else:\n",
    "    print(\"âŒ OPENAI_API_KEY is missing! Add it to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Configuration\n",
    "\n",
    "### 2.1 Define Paths and PDF Files\n",
    "\n",
    "Set up paths to the assets folder and define which PDF files to process.\n",
    "\n",
    "**Your PDFs:**\n",
    "- BHP_16AR.pdf (2016)\n",
    "- BHP_17AR.pdf (2017)\n",
    "- BHP_18AR.pdf (2018)\n",
    "- BHP_19AR.pdf (2019)\n",
    "- BHP_20AR.pdf (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 - Define paths and PDF files\n",
    "\n",
    "# Path to assets folder (relative to notebooks folder)\n",
    "ASSETS_DIR = Path(\"../assets\")\n",
    "\n",
    "# List of PDF files with metadata\n",
    "PDF_FILES = [\n",
    "    {\"filename\": \"BHP_16AR.pdf\", \"company\": \"BHP\", \"year\": 2016},\n",
    "    {\"filename\": \"BHP_17AR.pdf\", \"company\": \"BHP\", \"year\": 2017},\n",
    "    {\"filename\": \"BHP_18AR.pdf\", \"company\": \"BHP\", \"year\": 2018},\n",
    "    {\"filename\": \"BHP_19AR.pdf\", \"company\": \"BHP\", \"year\": 2019},\n",
    "    {\"filename\": \"BHP_20AR.pdf\", \"company\": \"BHP\", \"year\": 2020},\n",
    "]\n",
    "\n",
    "# Verify PDFs exist\n",
    "print(\"ðŸ“ Checking PDF files:\")\n",
    "for pdf in PDF_FILES:\n",
    "    path = ASSETS_DIR / pdf[\"filename\"]\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   âœ… {pdf['filename']} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"   âŒ {pdf['filename']} NOT FOUND at {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model and Processing Settings\n",
    "\n",
    "Configure:\n",
    "- **Models**: Which GPT models to use (gpt-4o-mini for most tasks, gpt-4o for verification)\n",
    "- **Chunking**: How to split PDF text (1000 chars with 200 char overlap)\n",
    "- **Agent settings**: Max turns before timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 - Model and processing settings\n",
    "\n",
    "CONFIG = {\n",
    "    # Models\n",
    "    \"default_model\": \"gpt-4o-mini\",  # Fast, cheap - for most tasks\n",
    "    \"strong_model\": \"gpt-4o\",         # Stronger - for verification\n",
    "    \n",
    "    # Chunking settings\n",
    "    \"chunk_size\": 1000,      # Characters per chunk\n",
    "    \"chunk_overlap\": 200,    # Overlap between chunks\n",
    "    \n",
    "    # Agent settings\n",
    "    \"max_turns\": 25,         # Max tool calls before stopping\n",
    "    \"max_iterations\": 3,     # Max write-verify loops\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"   Default model: {CONFIG['default_model']}\")\n",
    "print(f\"   Chunk size: {CONFIG['chunk_size']} chars\")\n",
    "print(f\"   Max turns: {CONFIG['max_turns']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Data Models (Pydantic)\n",
    "\n",
    "### 3.1 Source Document Models\n",
    "\n",
    "Define Pydantic models for tracking PDF sources and text chunks:\n",
    "\n",
    "- **PDFSource**: Metadata about each PDF (filename, hash, page count)\n",
    "- **DocumentChunk**: A piece of extracted text with its location (page, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 - Source document models\n",
    "\n",
    "class PDFSource(BaseModel):\n",
    "    \"\"\"Metadata about a source PDF document.\"\"\"\n",
    "    filename: str\n",
    "    company: str\n",
    "    year: int\n",
    "    document_type: str = \"Annual Report\"\n",
    "    sha256_hash: str           # For provenance verification\n",
    "    total_pages: int\n",
    "    file_path: str\n",
    "\n",
    "\n",
    "class DocumentChunk(BaseModel):\n",
    "    \"\"\"A chunk of text extracted from a PDF with full provenance.\"\"\"\n",
    "    chunk_id: str              # Unique ID: bhp_2019_p087_c003\n",
    "    content: str               # The actual text\n",
    "    company: str\n",
    "    year: int\n",
    "    page: int                  # Page number (1-indexed)\n",
    "    section: str = \"General\"   # Detected section name\n",
    "    source_file: str\n",
    "\n",
    "\n",
    "print(\"âœ… Source document models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Agent Output Models\n",
    "\n",
    "Define structured outputs for each agent:\n",
    "\n",
    "- **ClarifyingQuestions**: Output from Clarifier Agent\n",
    "- **AnalystFinding**: A single finding with citation\n",
    "- **AnalystReport**: Complete output from Analyst Agent\n",
    "- **ReportData**: Output from Writer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 - Agent output models\n",
    "\n",
    "class ClarifyingQuestions(BaseModel):\n",
    "    \"\"\"Output from the Clarifier Agent.\"\"\"\n",
    "    questions: list[str]           # Clarifying questions\n",
    "    refined_query: str             # Improved query\n",
    "    identified_companies: list[str]\n",
    "    identified_years: list[int]\n",
    "    focus_areas: list[str]         # e.g., [\"remuneration\", \"board\"]\n",
    "\n",
    "\n",
    "class AnalystFinding(BaseModel):\n",
    "    \"\"\"A single finding with citation.\"\"\"\n",
    "    finding: str                   # The factual finding\n",
    "    evidence: str                  # Quote from source\n",
    "    chunk_id: str                  # Source chunk ID\n",
    "    page: int                      # Page number\n",
    "    confidence: str = \"high\"       # high, medium, low\n",
    "    category: str                  # remuneration, board, etc.\n",
    "\n",
    "\n",
    "class AnalystReport(BaseModel):\n",
    "    \"\"\"Complete output from an Analyst Agent.\"\"\"\n",
    "    analyst_name: str\n",
    "    findings: list[AnalystFinding]\n",
    "    summary: str\n",
    "    red_flags: list[str] = []\n",
    "\n",
    "\n",
    "class ReportData(BaseModel):\n",
    "    \"\"\"Output from the Writer Agent.\"\"\"\n",
    "    short_summary: str             # 2-3 sentence summary\n",
    "    markdown_report: str           # Full report\n",
    "    claims_made: list[str]         # List of factual claims\n",
    "    follow_up_questions: list[str]\n",
    "\n",
    "\n",
    "print(\"âœ… Agent output models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Verification Models\n",
    "\n",
    "Models for the verification process:\n",
    "\n",
    "- **ClaimVerification**: Result for a single claim (VERIFIED, UNSUPPORTED, HALLUCINATION)\n",
    "- **VerificationResult**: Complete verification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 - Verification models\n",
    "\n",
    "class ClaimVerification(BaseModel):\n",
    "    \"\"\"Verification result for a single claim.\"\"\"\n",
    "    claim: str\n",
    "    status: str                    # VERIFIED, UNSUPPORTED, HALLUCINATION\n",
    "    source_chunk_id: Optional[str] = None\n",
    "    source_text: Optional[str] = None\n",
    "    page: Optional[int] = None\n",
    "    reason: Optional[str] = None\n",
    "\n",
    "\n",
    "class VerificationResult(BaseModel):\n",
    "    \"\"\"Complete verification result.\"\"\"\n",
    "    verified: bool                 # True if all claims pass\n",
    "    total_claims: int\n",
    "    verified_count: int\n",
    "    claims: list[ClaimVerification]\n",
    "    hallucinations: list[str] = []\n",
    "    unsupported: list[str] = []\n",
    "\n",
    "\n",
    "print(\"âœ… Verification models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: PDF Extraction\n",
    "\n",
    "### 4.1 Helper Functions\n",
    "\n",
    "Define helper functions for:\n",
    "- **compute_sha256**: Calculate file hash for provenance\n",
    "- **detect_section**: Guess which section of the annual report a chunk is from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 - Helper functions\n",
    "\n",
    "def compute_sha256(file_path: Path) -> str:\n",
    "    \"\"\"Compute SHA256 hash of a file for provenance tracking.\"\"\"\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(chunk)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "\n",
    "def detect_section(text: str) -> str:\n",
    "    \"\"\"Detect which section of the annual report this text is from.\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    if any(term in text_lower for term in [\"remuneration\", \"compensation\", \"executive pay\", \"kmp\", \"key management\"]):\n",
    "        return \"Remuneration Report\"\n",
    "    elif any(term in text_lower for term in [\"director\", \"board\", \"chairman\", \"governance\", \"committee\"]):\n",
    "        return \"Directors Report\"\n",
    "    elif any(term in text_lower for term in [\"related party\", \"transactions with\"]):\n",
    "        return \"Related Party Disclosures\"\n",
    "    elif any(term in text_lower for term in [\"financial statements\", \"balance sheet\", \"income statement\"]):\n",
    "        return \"Financial Statements\"\n",
    "    elif any(term in text_lower for term in [\"risk\", \"material risk\"]):\n",
    "        return \"Risk Management\"\n",
    "    elif any(term in text_lower for term in [\"sustainability\", \"environment\", \"climate\", \"emissions\", \"safety\"]):\n",
    "        return \"Sustainability\"\n",
    "    else:\n",
    "        return \"General\"\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 PDF Extraction Function\n",
    "\n",
    "Main function to extract text from a PDF and split into chunks:\n",
    "\n",
    "1. Open PDF with PyMuPDF\n",
    "2. Extract text from each page\n",
    "3. Split into chunks of ~1000 characters\n",
    "4. Create chunk IDs with format: `bhp_2019_p087_c003`\n",
    "5. Detect section for each chunk\n",
    "6. Calculate SHA256 hash for provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 - PDF extraction function\n",
    "\n",
    "def extract_pdf_chunks(\n",
    "    pdf_path: Path, \n",
    "    company: str, \n",
    "    year: int,\n",
    "    chunk_size: int = 1000,\n",
    "    chunk_overlap: int = 200\n",
    ") -> tuple[PDFSource, list[DocumentChunk]]:\n",
    "    \"\"\"\n",
    "    Extract text from a PDF and split into chunks with page citations.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        company: Company code (e.g., \"BHP\")\n",
    "        year: Financial year\n",
    "        chunk_size: Target characters per chunk\n",
    "        chunk_overlap: Overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (PDFSource metadata, list of DocumentChunks)\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create source metadata\n",
    "    source = PDFSource(\n",
    "        filename=pdf_path.name,\n",
    "        company=company,\n",
    "        year=year,\n",
    "        sha256_hash=compute_sha256(pdf_path),\n",
    "        total_pages=len(doc),\n",
    "        file_path=str(pdf_path)\n",
    "    )\n",
    "    \n",
    "    chunks = []\n",
    "    chunk_counter = 0\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        text = page.get_text()\n",
    "        \n",
    "        if not text.strip():\n",
    "            continue\n",
    "        \n",
    "        # Split page text into chunks\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            end = start + chunk_size\n",
    "            chunk_text = text[start:end]\n",
    "            \n",
    "            # Try to break at sentence boundary\n",
    "            if end < len(text):\n",
    "                last_period = chunk_text.rfind('.')\n",
    "                if last_period > chunk_size // 2:\n",
    "                    chunk_text = chunk_text[:last_period + 1]\n",
    "                    end = start + last_period + 1\n",
    "            \n",
    "            if chunk_text.strip():\n",
    "                # Create unique chunk ID\n",
    "                chunk_id = f\"{company.lower()}_{year}_p{page_num + 1:03d}_c{chunk_counter:03d}\"\n",
    "                \n",
    "                chunks.append(DocumentChunk(\n",
    "                    chunk_id=chunk_id,\n",
    "                    content=chunk_text.strip(),\n",
    "                    company=company,\n",
    "                    year=year,\n",
    "                    page=page_num + 1,  # 1-indexed\n",
    "                    section=detect_section(chunk_text),\n",
    "                    source_file=str(pdf_path)\n",
    "                ))\n",
    "                chunk_counter += 1\n",
    "            \n",
    "            start = end - chunk_overlap\n",
    "    \n",
    "    doc.close()\n",
    "    return source, chunks\n",
    "\n",
    "\n",
    "print(\"âœ… PDF extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Extract All PDFs\n",
    "\n",
    "Process all PDF files and build the chunk database.\n",
    "\n",
    "**This cell takes ~1-2 minutes** to process all 5 PDFs.\n",
    "\n",
    "Output:\n",
    "- `PDF_SOURCES`: Dict of PDFSource objects (metadata)\n",
    "- `ALL_CHUNKS`: Dict of DocumentChunk objects (searchable text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 - Extract all PDFs\n",
    "\n",
    "print(\"ðŸ“„ Extracting text from PDFs...\")\n",
    "print(\"   (This takes ~1-2 minutes for 5 large PDFs)\\n\")\n",
    "\n",
    "PDF_SOURCES: dict[str, PDFSource] = {}\n",
    "ALL_CHUNKS: dict[str, DocumentChunk] = {}\n",
    "\n",
    "for pdf_info in PDF_FILES:\n",
    "    pdf_path = ASSETS_DIR / pdf_info[\"filename\"]\n",
    "    \n",
    "    if not pdf_path.exists():\n",
    "        print(f\"   âš ï¸ Skipping {pdf_info['filename']} - not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"   ðŸ“– Processing {pdf_info['filename']}...\", end=\" \", flush=True)\n",
    "    \n",
    "    source, chunks = extract_pdf_chunks(\n",
    "        pdf_path,\n",
    "        company=pdf_info[\"company\"],\n",
    "        year=pdf_info[\"year\"],\n",
    "        chunk_size=CONFIG[\"chunk_size\"],\n",
    "        chunk_overlap=CONFIG[\"chunk_overlap\"]\n",
    "    )\n",
    "    \n",
    "    PDF_SOURCES[pdf_info[\"filename\"]] = source\n",
    "    for chunk in chunks:\n",
    "        ALL_CHUNKS[chunk.chunk_id] = chunk\n",
    "    \n",
    "    print(f\"{len(chunks)} chunks from {source.total_pages} pages\")\n",
    "\n",
    "print(f\"\\nâœ… Extraction complete!\")\n",
    "print(f\"   Total chunks: {len(ALL_CHUNKS):,}\")\n",
    "print(f\"   Total PDFs: {len(PDF_SOURCES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Inspect Extracted Chunks\n",
    "\n",
    "View sample chunks to verify extraction worked correctly.\n",
    "\n",
    "We'll look at:\n",
    "- Section distribution (how many chunks per section)\n",
    "- Sample remuneration chunks (most relevant for governance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 - Inspect extracted chunks\n",
    "\n",
    "# Count chunks by section\n",
    "section_counts = {}\n",
    "for chunk in ALL_CHUNKS.values():\n",
    "    section = chunk.section\n",
    "    section_counts[section] = section_counts.get(section, 0) + 1\n",
    "\n",
    "print(\"ðŸ“Š Chunks by section:\")\n",
    "for section, count in sorted(section_counts.items(), key=lambda x: -x[1]):\n",
    "    print(f\"   {section}: {count:,}\")\n",
    "\n",
    "# Show sample remuneration chunks\n",
    "print(\"\\nðŸ“‹ Sample Remuneration chunks:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "rem_chunks = [c for c in ALL_CHUNKS.values() if c.section == \"Remuneration Report\"][:3]\n",
    "for chunk in rem_chunks:\n",
    "    print(f\"\\nChunk ID: {chunk.chunk_id}\")\n",
    "    print(f\"Source: {chunk.company} {chunk.year} AR, Page {chunk.page}\")\n",
    "    print(f\"Content: {chunk.content[:200]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Search Tools\n",
    "\n",
    "### 5.1 Main Search Tool\n",
    "\n",
    "The `search_annual_reports` tool searches across all extracted chunks:\n",
    "\n",
    "- Keyword matching with scoring\n",
    "- Filter by company, year, section\n",
    "- Returns top results with citations\n",
    "\n",
    "**Important:** This is what agents use to find information in the PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 - Main search tool\n",
    "\n",
    "def _search_annual_reports(\n",
    "    query: str, \n",
    "    company: str = \"BHP\",\n",
    "    year: int = None,\n",
    "    section: str = None,\n",
    "    max_results: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Core search logic (not decorated).\"\"\"\n",
    "    query_terms = [t.lower() for t in query.split() if len(t) > 2]\n",
    "    results = []\n",
    "    \n",
    "    for chunk_id, chunk in ALL_CHUNKS.items():\n",
    "        if chunk.company.upper() != company.upper():\n",
    "            continue\n",
    "        if year and chunk.year != year:\n",
    "            continue\n",
    "        if section and section.lower() not in chunk.section.lower():\n",
    "            continue\n",
    "        \n",
    "        content_lower = chunk.content.lower()\n",
    "        score = 0\n",
    "        for term in query_terms:\n",
    "            if term in content_lower:\n",
    "                score += 2\n",
    "                score += content_lower.count(term) * 0.5\n",
    "        \n",
    "        if score > 0:\n",
    "            results.append((score, chunk))\n",
    "    \n",
    "    results.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    if not results:\n",
    "        return f\"No results found for '{query}' in {company} {year or 'all years'}\"\n",
    "    \n",
    "    formatted = [f\"Found {len(results)} results. Top {min(max_results, len(results))}:\\n\"]\n",
    "    for score, chunk in results[:max_results]:\n",
    "        content = chunk.content[:600] + \"...\" if len(chunk.content) > 600 else chunk.content\n",
    "        formatted.append(f\"\"\"\n",
    "---\n",
    "**[{chunk.company} {chunk.year} AR, Page {chunk.page}]**\n",
    "Section: {chunk.section}\n",
    "\n",
    "{content}\n",
    "\n",
    "[Chunk ID: {chunk.chunk_id}]\n",
    "\"\"\")\n",
    "    \n",
    "    return \"\\n\".join(formatted)\n",
    "\n",
    "\n",
    "# Wrap for agents\n",
    "@function_tool\n",
    "def search_annual_reports(\n",
    "    query: str, \n",
    "    company: str = \"BHP\",\n",
    "    year: int = None,\n",
    "    section: str = None,\n",
    "    max_results: int = 5\n",
    ") -> str:\n",
    "    \"\"\"Search annual reports. Returns passages with citations.\"\"\"\n",
    "    return _search_annual_reports(query, company, year, section, max_results)\n",
    "\n",
    "\n",
    "print(\"âœ… search_annual_reports tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Additional Tools\n",
    "\n",
    "Helper tools for the agents:\n",
    "\n",
    "- **get_chunk_by_id**: Retrieve a specific chunk (for verification)\n",
    "- **list_available_years**: Show what years are available\n",
    "- **get_section_summary**: Get chunks from a specific section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 - Additional tools\n",
    "\n",
    "def _get_chunk_by_id(chunk_id: str) -> str:\n",
    "    if chunk_id not in ALL_CHUNKS:\n",
    "        return f\"ERROR: Chunk ID '{chunk_id}' not found.\"\n",
    "    chunk = ALL_CHUNKS[chunk_id]\n",
    "    return f\"\"\"\n",
    "**Chunk ID:** {chunk.chunk_id}\n",
    "**Source:** {chunk.company} {chunk.year} AR, Page {chunk.page}\n",
    "**Section:** {chunk.section}\n",
    "\n",
    "**Content:**\n",
    "{chunk.content}\n",
    "\"\"\"\n",
    "\n",
    "@function_tool\n",
    "def get_chunk_by_id(chunk_id: str) -> str:\n",
    "    \"\"\"Retrieve a chunk by ID.\"\"\"\n",
    "    return _get_chunk_by_id(chunk_id)\n",
    "\n",
    "\n",
    "def _list_available_years(company: str = \"BHP\") -> str:\n",
    "    year_counts = {}\n",
    "    for chunk in ALL_CHUNKS.values():\n",
    "        if chunk.company.upper() == company.upper():\n",
    "            year_counts[chunk.year] = year_counts.get(chunk.year, 0) + 1\n",
    "    if not year_counts:\n",
    "        return f\"No documents for {company}\"\n",
    "    return f\"Available: {sorted(year_counts.keys())}\"\n",
    "\n",
    "@function_tool\n",
    "def list_available_years(company: str = \"BHP\") -> str:\n",
    "    \"\"\"List available years.\"\"\"\n",
    "    return _list_available_years(company)\n",
    "\n",
    "\n",
    "def _get_section_summary(section: str, company: str = \"BHP\", year: int = None, max_chunks: int = 3) -> str:\n",
    "    matching = [c for c in ALL_CHUNKS.values() \n",
    "                if c.company.upper() == company.upper() \n",
    "                and section.lower() in c.section.lower()\n",
    "                and (year is None or c.year == year)]\n",
    "    if not matching:\n",
    "        return f\"No '{section}' chunks found\"\n",
    "    result = f\"Found {len(matching)}. Sample:\\n\"\n",
    "    for c in matching[:max_chunks]:\n",
    "        result += f\"\\n[{c.year} Page {c.page}] {c.content[:300]}...\\n[Chunk ID: {c.chunk_id}]\\n\"\n",
    "    return result\n",
    "\n",
    "@function_tool\n",
    "def get_section_summary(section: str, company: str = \"BHP\", year: int = None, max_chunks: int = 3) -> str:\n",
    "    \"\"\"Get chunks from a section.\"\"\"\n",
    "    return _get_section_summary(section, company, year, max_chunks)\n",
    "\n",
    "print(\"âœ… Additional tools defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Test Search Tool\n",
    "\n",
    "Test the search tool to make sure it's finding relevant content.\n",
    "\n",
    "We'll search for CEO remuneration information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 - Test search tool\n",
    "\n",
    "print(\"ðŸ” Test search: 'CEO total remuneration pay'\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result = _search_annual_reports(\n",
    "    query=\"CEO total remuneration pay\",\n",
    "    company=\"BHP\",\n",
    "    max_results=3\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Agent Definitions\n",
    "\n",
    "### 6.1 Clarifier Agent\n",
    "\n",
    "The Clarifier Agent:\n",
    "- Asks clarifying questions about the research query\n",
    "- Identifies companies and years mentioned\n",
    "- Refines the query with sensible defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 - Clarifier Agent\n",
    "\n",
    "CLARIFIER_INSTRUCTIONS = \"\"\"\n",
    "You are a governance research assistant specialising in ASX-listed companies.\n",
    "\n",
    "Given a research query, your job is to:\n",
    "1. Generate 3 clarifying questions that would help focus the research\n",
    "2. Identify the companies mentioned or implied\n",
    "3. Identify the time period (years) to analyse\n",
    "4. Determine the governance focus areas (remuneration, board, related parties, etc.)\n",
    "5. Provide a refined query with sensible defaults assumed\n",
    "\n",
    "AVAILABLE DATA: BHP Annual Reports for years 2016, 2017, 2018, 2019, 2020.\n",
    "\n",
    "If no years specified, default to 2019 and 2020 (most recent).\n",
    "If no company specified, default to BHP.\n",
    "\n",
    "Be concise and practical.\n",
    "\"\"\"\n",
    "\n",
    "clarifier_agent = Agent(\n",
    "    name=\"ClarifierAgent\",\n",
    "    instructions=CLARIFIER_INSTRUCTIONS,\n",
    "    model=CONFIG[\"default_model\"],\n",
    "    output_type=ClarifyingQuestions,\n",
    ")\n",
    "\n",
    "print(\"âœ… Clarifier Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Remuneration Analyst Agent\n",
    "\n",
    "The Analyst Agent:\n",
    "- Searches the annual reports using the tools\n",
    "- Extracts specific findings about executive remuneration\n",
    "- **MUST cite every finding** with a chunk_id\n",
    "\n",
    "**Critical:** This agent can only use information from the search tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 - Remuneration Analyst Agent\n",
    "\n",
    "REMUNERATION_ANALYST_INSTRUCTIONS = \"\"\"\n",
    "You analyse BHP annual reports for executive remuneration.\n",
    "\n",
    "RULES:\n",
    "1. Use search_annual_reports to find information\n",
    "2. Every finding MUST have a chunk_id from the search results\n",
    "3. Stop after finding 3-5 good findings\n",
    "\n",
    "WORKFLOW:\n",
    "1. Search for \"CEO remuneration salary total\" \n",
    "2. Extract findings with chunk_id citations\n",
    "3. Return your AnalystReport\n",
    "\n",
    "DO NOT keep searching indefinitely. After 2-3 searches, compile your findings.\n",
    "\"\"\"\n",
    "\n",
    "remuneration_analyst = Agent(\n",
    "    name=\"RemunerationAnalyst\",\n",
    "    instructions=REMUNERATION_ANALYST_INSTRUCTIONS,\n",
    "    tools=[search_annual_reports, get_chunk_by_id, list_available_years, get_section_summary],\n",
    "    model=CONFIG[\"default_model\"],\n",
    "    output_type=AnalystReport,\n",
    ")\n",
    "\n",
    "print(\"âœ… Remuneration Analyst Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Writer Agent\n",
    "\n",
    "The Writer Agent:\n",
    "- Takes findings from the analyst\n",
    "- Synthesises them into a professional report\n",
    "- **MUST cite every claim** with [Chunk ID: xxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 - Writer Agent\n",
    "\n",
    "WRITER_INSTRUCTIONS = \"\"\"\n",
    "You are a senior governance report writer.\n",
    "\n",
    "Your job is to synthesise analyst findings into a professional report.\n",
    "\n",
    "CRITICAL CONSTRAINTS:\n",
    "1. Use ONLY information from the provided findings\n",
    "2. Do NOT add any external knowledge\n",
    "3. EVERY factual claim MUST include [Chunk ID: xxx] citation\n",
    "4. If something isn't in the findings, say \"Not available in source documents\"\n",
    "\n",
    "FORBIDDEN:\n",
    "- \"Generally, companies...\" (external knowledge)\n",
    "- \"It is common practice...\" (external knowledge)\n",
    "- Any claim without [Chunk ID: xxx] citation\n",
    "\n",
    "REQUIRED FORMAT:\n",
    "\"The CEO total remuneration was $X [Chunk ID: bhp_2019_p087_c003].\"\n",
    "\n",
    "REPORT STRUCTURE:\n",
    "1. Executive Summary (2-3 sentences with citations)\n",
    "2. Key Findings (bullet points with citations)\n",
    "3. Detailed Analysis (paragraphs with citations)\n",
    "4. Red Flags (if any)\n",
    "5. Recommendations for Further Review\n",
    "\n",
    "Write in professional, clear language.\n",
    "\"\"\"\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=WRITER_INSTRUCTIONS,\n",
    "    model=CONFIG[\"default_model\"],\n",
    "    output_type=ReportData,\n",
    ")\n",
    "\n",
    "print(\"âœ… Writer Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Verifier Agent\n",
    "\n",
    "The Verifier Agent:\n",
    "- Checks every claim in the report\n",
    "- Verifies the cited chunk_id exists\n",
    "- Confirms the claim matches the source\n",
    "\n",
    "Uses the stronger model (gpt-4o) for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 - Verifier Agent\n",
    "\n",
    "VERIFIER_INSTRUCTIONS = \"\"\"\n",
    "You are a verification agent ensuring forensic integrity of governance reports.\n",
    "\n",
    "Your job is to verify that EVERY factual claim:\n",
    "1. Has a citation [Chunk ID: xxx]\n",
    "2. The chunk_id exists (use get_chunk_by_id to check)\n",
    "3. The claim accurately reflects the source\n",
    "\n",
    "For each claim, assign status:\n",
    "- VERIFIED: Has valid citation that supports the claim\n",
    "- UNSUPPORTED: Citation exists but doesn't support claim\n",
    "- HALLUCINATION: No citation or invalid chunk_id\n",
    "\n",
    "Be STRICT. This is for legal/regulatory use.\n",
    "\n",
    "Output:\n",
    "- verified: true only if ALL claims are VERIFIED\n",
    "- List each claim with its status\n",
    "- List any hallucinations\n",
    "- List any unsupported claims\n",
    "\"\"\"\n",
    "\n",
    "verifier_agent = Agent(\n",
    "    name=\"VerifierAgent\",\n",
    "    instructions=VERIFIER_INSTRUCTIONS,\n",
    "    tools=[get_chunk_by_id],\n",
    "    model=CONFIG[\"strong_model\"],  # Use stronger model for verification\n",
    "    output_type=VerificationResult,\n",
    ")\n",
    "\n",
    "print(\"âœ… Verifier Agent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Test the Analyst Agent\n",
    "\n",
    "### 7.1 Run Analyst Test\n",
    "\n",
    "Test the remuneration analyst on a simple query.\n",
    "\n",
    "**Note:** `max_turns=25` allows the agent more iterations to search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 - Run analyst test\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST: Remuneration Analyst Agent\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "analyst_query = \"\"\"Search for CEO remuneration information in the BHP 2019 and 2020 annual reports.\n",
    "Find the total pay figures and any year-on-year changes.\"\"\"\n",
    "\n",
    "print(f\"Query: {analyst_query}\\n\")\n",
    "\n",
    "with trace(\"Analyst Test\"):\n",
    "    result = await Runner.run(\n",
    "        remuneration_analyst, \n",
    "        analyst_query,\n",
    "        max_turns=CONFIG[\"max_turns\"]  # Allow more turns\n",
    "    )\n",
    "    analysis = result.final_output_as(AnalystReport)\n",
    "\n",
    "print(f\"\\nðŸ“Š Analyst: {analysis.analyst_name}\")\n",
    "print(f\"\\nðŸ“ Summary: {analysis.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Display Analyst Findings\n",
    "\n",
    "Show the detailed findings with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 - Display analyst findings\n",
    "\n",
    "print(f\"\\nðŸ” Findings ({len(analysis.findings)}):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, finding in enumerate(analysis.findings, 1):\n",
    "    print(f\"\\nðŸ“Œ Finding {i}:\")\n",
    "    print(f\"   Statement: {finding.finding}\")\n",
    "    print(f\"   Evidence: {finding.evidence[:200]}...\" if len(finding.evidence) > 200 else f\"   Evidence: {finding.evidence}\")\n",
    "    print(f\"   Citation: [Chunk ID: {finding.chunk_id}], Page {finding.page}\")\n",
    "    print(f\"   Confidence: {finding.confidence}\")\n",
    "\n",
    "if analysis.red_flags:\n",
    "    print(f\"\\nðŸš© Red Flags:\")\n",
    "    for flag in analysis.red_flags:\n",
    "        print(f\"   - {flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Finding 1 manually\n",
    "chunk_id = \"bhp_2019_p152_c1033\"\n",
    "print(_get_chunk_by_id(chunk_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8: Full Research Pipeline\n",
    "\n",
    "### 8.1 Research Manager Class\n",
    "\n",
    "The Research Manager orchestrates the full pipeline:\n",
    "\n",
    "1. **Clarify** â†’ Refine the query\n",
    "2. **Analyse** â†’ Extract findings with citations\n",
    "3. **Write** â†’ Create report\n",
    "4. **Verify** â†’ Check all citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 - Research Manager class\n",
    "\n",
    "class GovernanceResearchManager:\n",
    "    \"\"\"\n",
    "    Orchestrates the full governance research pipeline:\n",
    "    Clarify â†’ Analyse â†’ Write â†’ Verify\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_turns = CONFIG[\"max_turns\"]\n",
    "        self.chunks_retrieved = []\n",
    "    \n",
    "    async def run(self, query: str):\n",
    "        \"\"\"Run the full pipeline. Yields status updates.\"\"\"\n",
    "        trace_id = gen_trace_id()\n",
    "        \n",
    "        with trace(\"Governance Research\", trace_id=trace_id):\n",
    "            yield f\"ðŸ”— Trace: https://platform.openai.com/traces/{trace_id}\"\n",
    "            \n",
    "            # Step 1: Clarify\n",
    "            yield \"\\nðŸ’­ Step 1: Clarifying query...\"\n",
    "            clarification = await self._clarify(query)\n",
    "            yield f\"   âœ… Refined: {clarification.refined_query[:80]}...\"\n",
    "            yield f\"   Years: {clarification.identified_years}\"\n",
    "            yield f\"   Focus: {clarification.focus_areas}\"\n",
    "            \n",
    "            # Step 2: Analyse\n",
    "            yield \"\\nðŸ” Step 2: Analyst searching reports...\"\n",
    "            findings = await self._analyse(clarification)\n",
    "            yield f\"   âœ… Found {len(findings)} findings\"\n",
    "            \n",
    "            # Step 3: Write\n",
    "            yield \"\\nðŸ“ Step 3: Writing report...\"\n",
    "            report = await self._write(clarification.refined_query, findings)\n",
    "            yield \"   âœ… Report drafted\"\n",
    "            \n",
    "            # Step 4: Verify\n",
    "            yield \"\\nðŸ”¬ Step 4: Verifying citations...\"\n",
    "            verification = await self._verify(report)\n",
    "            \n",
    "            if verification.verified:\n",
    "                yield f\"   âœ… PASSED: {verification.verified_count}/{verification.total_claims} claims verified\"\n",
    "            else:\n",
    "                yield f\"   âš ï¸ ISSUES: {len(verification.hallucinations)} hallucinations, {len(verification.unsupported)} unsupported\"\n",
    "            \n",
    "            yield \"\\nâœ… Research complete!\"\n",
    "            \n",
    "            # Return results\n",
    "            yield {\n",
    "                \"query\": query,\n",
    "                \"refined_query\": clarification.refined_query,\n",
    "                \"trace_id\": trace_id,\n",
    "                \"report\": report,\n",
    "                \"verification\": verification,\n",
    "                \"findings\": findings,\n",
    "                \"sources\": list(PDF_SOURCES.values()),\n",
    "                \"chunks_used\": self.chunks_retrieved,\n",
    "            }\n",
    "    \n",
    "    async def _clarify(self, query: str) -> ClarifyingQuestions:\n",
    "        \"\"\"Step 1: Clarify the query.\"\"\"\n",
    "        result = await Runner.run(\n",
    "            clarifier_agent, \n",
    "            f\"Query: {query}\",\n",
    "            max_turns=5\n",
    "        )\n",
    "        return result.final_output_as(ClarifyingQuestions)\n",
    "    \n",
    "    async def _analyse(self, clarification: ClarifyingQuestions) -> list[AnalystFinding]:\n",
    "        \"\"\"Step 2: Run the analyst.\"\"\"\n",
    "        years = clarification.identified_years or [2019, 2020]\n",
    "        focus = clarification.focus_areas or [\"remuneration\"]\n",
    "        \n",
    "        analyst_prompt = f\"\"\"Search the BHP annual reports for {', '.join(map(str, years))}.\n",
    "        Focus on: {', '.join(focus)}\n",
    "        \n",
    "        Find specific information and cite every finding with chunk_id.\"\"\"\n",
    "        \n",
    "        result = await Runner.run(\n",
    "            remuneration_analyst, \n",
    "            analyst_prompt,\n",
    "            max_turns=self.max_turns\n",
    "        )\n",
    "        analysis = result.final_output_as(AnalystReport)\n",
    "        \n",
    "        # Track chunks used\n",
    "        for f in analysis.findings:\n",
    "            if f.chunk_id not in self.chunks_retrieved:\n",
    "                self.chunks_retrieved.append(f.chunk_id)\n",
    "        \n",
    "        return analysis.findings\n",
    "    \n",
    "    async def _write(self, query: str, findings: list[AnalystFinding]) -> ReportData:\n",
    "        \"\"\"Step 3: Write the report.\"\"\"\n",
    "        findings_text = \"\\n\\n\".join([\n",
    "            f\"Finding: {f.finding}\\n\"\n",
    "            f\"Evidence: {f.evidence}\\n\"\n",
    "            f\"Citation: [Chunk ID: {f.chunk_id}], Page {f.page}\\n\"\n",
    "            f\"Confidence: {f.confidence}\"\n",
    "            for f in findings\n",
    "        ])\n",
    "        \n",
    "        prompt = f\"\"\"Query: {query}\n",
    "\n",
    "Analyst Findings:\n",
    "{findings_text}\n",
    "\n",
    "Write a report using ONLY these findings. Cite every claim with [Chunk ID: xxx].\"\"\"\n",
    "        \n",
    "        result = await Runner.run(writer_agent, prompt, max_turns=5)\n",
    "        return result.final_output_as(ReportData)\n",
    "    \n",
    "    async def _verify(self, report: ReportData) -> VerificationResult:\n",
    "        \"\"\"Step 4: Verify the report.\"\"\"\n",
    "        prompt = f\"\"\"Verify this report. Check each claim has a valid [Chunk ID: xxx] citation.\n",
    "Use get_chunk_by_id to verify chunk_ids exist.\n",
    "\n",
    "Report:\n",
    "{report.markdown_report}\n",
    "\n",
    "Claims made: {report.claims_made}\"\"\"\n",
    "        \n",
    "        result = await Runner.run(\n",
    "            verifier_agent, \n",
    "            prompt,\n",
    "            max_turns=self.max_turns\n",
    "        )\n",
    "        return result.final_output_as(VerificationResult)\n",
    "\n",
    "\n",
    "print(\"âœ… GovernanceResearchManager defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Run Full Pipeline\n",
    "\n",
    "Execute the complete research pipeline.\n",
    "\n",
    "**This takes 1-3 minutes** depending on API response times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 - Run full pipeline\n",
    "\n",
    "manager = GovernanceResearchManager()\n",
    "\n",
    "query = \"Analyse BHP executive remuneration trends from 2018 to 2020\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GOVERNANCE RESEARCH PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Query: {query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "output = None\n",
    "async for update in manager.run(query):\n",
    "    if isinstance(update, str):\n",
    "        print(update)\n",
    "    else:\n",
    "        output = update\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Display Report\n",
    "\n",
    "Show the final report with verification status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3 - Display report\n",
    "\n",
    "if output:\n",
    "    print(\"\\nðŸ“Š EXECUTIVE SUMMARY\")\n",
    "    print(\"-\" * 40)\n",
    "    print(output[\"report\"].short_summary)\n",
    "    \n",
    "    print(\"\\nðŸ“‹ VERIFICATION STATUS\")\n",
    "    print(\"-\" * 40)\n",
    "    v = output[\"verification\"]\n",
    "    status = \"âœ… PASSED\" if v.verified else \"âš ï¸ ISSUES FOUND\"\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Claims verified: {v.verified_count}/{v.total_claims}\")\n",
    "    \n",
    "    if v.hallucinations:\n",
    "        print(f\"\\nâš ï¸ Hallucinations: {v.hallucinations}\")\n",
    "    if v.unsupported:\n",
    "        print(f\"\\nâš ï¸ Unsupported: {v.unsupported}\")\n",
    "    \n",
    "    print(\"\\nðŸ“„ FULL REPORT\")\n",
    "    print(\"-\" * 40)\n",
    "    display(Markdown(output[\"report\"].markdown_report))\n",
    "else:\n",
    "    print(\"âŒ No output - check for errors above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Provenance Trail\n",
    "\n",
    "Display the complete audit trail:\n",
    "- PDF sources with SHA256 hashes\n",
    "- Chunks retrieved\n",
    "- Trace link for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.4 - Provenance trail\n",
    "\n",
    "if output:\n",
    "    print(\"\\nðŸ”’ PROVENANCE TRAIL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nðŸ“ PDF Sources:\")\n",
    "    for source in output[\"sources\"]:\n",
    "        print(f\"   â€¢ {source.filename}\")\n",
    "        print(f\"     Year: {source.year}, Pages: {source.total_pages}\")\n",
    "        print(f\"     SHA256: {source.sha256_hash[:40]}...\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Ž Chunks Used ({len(output['chunks_used'])}):\")\n",
    "    for chunk_id in output['chunks_used'][:10]:\n",
    "        if chunk_id in ALL_CHUNKS:\n",
    "            c = ALL_CHUNKS[chunk_id]\n",
    "            print(f\"   â€¢ {chunk_id} (Page {c.page}, {c.section})\")\n",
    "    if len(output['chunks_used']) > 10:\n",
    "        print(f\"   ... and {len(output['chunks_used']) - 10} more\")\n",
    "    \n",
    "    print(f\"\\nðŸ”— Trace: https://platform.openai.com/traces/{output['trace_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Summary\n",
    "\n",
    "### What We Built\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|--------|\n",
    "| PDF Extraction | PyMuPDF extracts text with page numbers |\n",
    "| Chunking | ~1000 char chunks with 200 char overlap |\n",
    "| Search Tool | Keyword search with scoring |\n",
    "| Clarifier Agent | Refines query, identifies scope |\n",
    "| Analyst Agent | Extracts findings with citations |\n",
    "| Writer Agent | Creates report with mandatory citations |\n",
    "| Verifier Agent | Checks all claims are supported |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Add vector search (embeddings) for better retrieval\n",
    "2. Add Cohere reranking\n",
    "3. Build Gradio UI with PDF viewer\n",
    "4. Add supplementary web search (ASIC, ASX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 - Final summary\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸŽ‰ NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "You've built a governance research agent with:\n",
    "\n",
    "âœ… PDF extraction from {len(PDF_SOURCES)} BHP annual reports\n",
    "âœ… {len(ALL_CHUNKS):,} searchable chunks with page citations\n",
    "âœ… Citation enforcement [Chunk ID: xxx] on every claim\n",
    "âœ… Verification agent to catch hallucinations\n",
    "âœ… SHA256 hashes for forensic provenance\n",
    "\n",
    "Source documents: BHP Annual Reports 2016-2020\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
