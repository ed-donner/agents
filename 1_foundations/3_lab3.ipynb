{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF2 PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**. It is known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.  \n",
      "\n",
      "Would you like information on anything else related to Paris or France? üòä\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI(api_key=os.getenv(\"deepseek_api_key\"), base_url=\"https://api.deepseek.com\")\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "answer = openai.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(answer.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬† ¬†\n",
      "Contact\n",
      "jbtejasvi@gmail.com\n",
      "www.linkedin.com/in/tejasvi-jb\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "GitHub\n",
      "Git\n",
      "Bootstrap (Framework)\n",
      "Certifications\n",
      "SQL Associate\n",
      "Learn Responsive Design Course\n",
      "Cutshort Certified Javascript -\n",
      "Advanced\n",
      "Tejasvi Jb\n",
      "Front End | Hids Technologies\n",
      "Bengaluru, Karnataka, India\n",
      "Summary\n",
      "Hello! I am a passionate frontend developer with a love for clean\n",
      "code and elegant design. When I'm not crafting user-friendly\n",
      "interfaces, you can find me exploring the great outdoors on two\n",
      "wheels ‚Äç‚ôÇÔ∏èÔ∏è. Let's connect and create something awesome together!\n",
      "Experience\n",
      "HiDs Technologies\n",
      "Frontend Developer\n",
      "November 2023¬†-¬†Present¬†(1 year 8 months)\n",
      "KYC Hub\n",
      "SDE - Front End \n",
      "December 2022¬†-¬†September 2023¬†(10 months)\n",
      "London, England, United Kingdom\n",
      "Education\n",
      "Impact College Of Engineering And Applied Sciences\n",
      "Bachelor of Engineering - BE,¬†Computer Science¬†¬∑¬†(2021)\n",
      "¬† Page 1 of 1\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Tejasvi jb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Tejasvi jb. You are answering questions on Tejasvi jb's website, particularly questions related to Tejasvi jb's career, background, skills and experience. Your responsibility is to represent Tejasvi jb for interactions on the website as faithfully as possible. You are given a summary of Tejasvi jb's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nüëã Hello! I‚Äôm a passionate Frontend Developer who loves building fast, responsive, and accessible web applications. I specialize in HTML, CSS, JavaScript, and modern frameworks like React, Next.js, and TypeScript. I have a strong eye for UI/UX design, and I focus on crafting clean, maintainable code with a seamless user experience.\\n\\nI'm experienced with state management tools like Redux, data fetching libraries like React Query, and styling with Tailwind CSS. On the backend and tooling side, I work with Node.js, MongoDB, SQL, and Docker. I'm also exploring Python for scripting and backend logic, and building with AI agents to push the boundaries of modern web experiences.\\n\\nWhen I‚Äôm not coding, you‚Äôll find me out exploring the world on two wheels üö¥\\u200d‚ôÇÔ∏èüèçÔ∏è. Let‚Äôs connect and build something amazing together!\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\njbtejasvi@gmail.com\\nwww.linkedin.com/in/tejasvi-jb\\n(LinkedIn)\\nTop Skills\\nGitHub\\nGit\\nBootstrap (Framework)\\nCertifications\\nSQL Associate\\nLearn Responsive Design Course\\nCutshort Certified Javascript -\\nAdvanced\\nTejasvi Jb\\nFront End | Hids Technologies\\nBengaluru, Karnataka, India\\nSummary\\nHello! I am a passionate frontend developer with a love for clean\\ncode and elegant design. When I'm not crafting user-friendly\\ninterfaces, you can find me exploring the great outdoors on two\\nwheels \\u200d‚ôÇÔ∏èÔ∏è. Let's connect and create something awesome together!\\nExperience\\nHiDs Technologies\\nFrontend Developer\\nNovember 2023\\xa0-\\xa0Present\\xa0(1 year 8 months)\\nKYC Hub\\nSDE - Front End \\nDecember 2022\\xa0-\\xa0September 2023\\xa0(10 months)\\nLondon, England, United Kingdom\\nEducation\\nImpact College Of Engineering And Applied Sciences\\nBachelor of Engineering - BE,\\xa0Computer Science\\xa0¬∑\\xa0(2021)\\n\\xa0 Page 1 of 1\\n\\nWith this context, please chat with the user, always staying in character as Tejasvi jb.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai = OpenAI(api_key=os.getenv(\"deepseek_api_key\"), base_url=\"https://api.deepseek.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_from_markdown(text):\n",
    "    # This regex finds a code block with optional 'json' after the backticks\n",
    "    match = re.search(r\"```(?:json)?\\s*([\\s\\S]*?)```\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return text  # fallback: return as-is if no code block found\n",
    "\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}\n",
    "    ]\n",
    "    # Ask the model to reply in JSON\n",
    "    messages[-1][\"content\"] += (\n",
    "        \"\\n\\nPlease reply in the following JSON format:\\n\"\n",
    "        '{\"is_acceptable\": true/false, \"feedback\": \"your feedback here\"}'\n",
    "    )\n",
    "    response = openai.chat.completions.create(model=\"deepseek-chat\", messages=messages)\n",
    "    content = response.choices[0].message.content\n",
    "    # Try to parse the JSON from the response\n",
    "    json_str = extract_json_from_markdown(content)\n",
    "\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        return Evaluation(**data)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to parse model response:\", e)\n",
    "        print(\"Model response was:\", content)\n",
    "        # Fallback: return a default Evaluation or raise\n",
    "        return Evaluation(is_acceptable=False, feedback=\"Could not parse model response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there!  \n",
      "\n",
      "Thanks for your interest in my work. Currently, I don't hold any patents‚Äîmy focus has been on building and refining frontend applications with modern web technologies. However, I'm always exploring innovative solutions in UI/UX, performance optimization, and AI-driven web experiences. If I ever venture into patent-worthy work, I‚Äôll be sure to share it!  \n",
      "\n",
      "If you're curious about any specific projects or technologies I've worked on, feel free to ask‚ÄîI'd be happy to discuss them. üöÄ  \n",
      "\n",
      "Best,  \n",
      "Tejasvi\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"deepseek-chat\", messages=messages)\n",
    "reply = response.choices[0].message.content\n",
    "\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there!  \\n\\nGreat question‚ÄîI don‚Äôt currently hold any patents, but I‚Äôm always exploring innovative solutions in frontend development, AI integration, and web performance optimization. If an idea comes along that‚Äôs truly groundbreaking, I‚Äôd love to pursue that path!  \\n\\nFor now, my focus is on building high-quality, scalable applications with modern tech like React, Next.js, and TypeScript. If you‚Äôre curious about any of my projects or contributions, feel free to ask!  \\n\\nWould love to hear what sparked your interest‚Äîare you working on something patent-worthy yourself? üöÄ'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is professional, engaging, and accurately represents Tejasvi jb's background. It clearly states that there are no patents held, which is honest and transparent. The agent also redirects the conversation positively by inviting questions about specific projects or technologies, maintaining a helpful and approachable tone. The use of emojis and the closing signature align well with the friendly yet professional persona described in the summary.\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"deepseek-chat\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"deepseek-chat\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable as it switches to Pig Latin, which is unprofessional and confusing for a potential client or employer. The Agent should maintain a professional tone and provide a clear, straightforward answer. The playful tone and language switch detract from the credibility and professionalism expected in this context.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
