{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "+91-8660230271 (Mobile)\n",
      "tejsinghani1996@gmail.com\n",
      "www.linkedin.com/in/mohit-\n",
      "tejsinghani (LinkedIn)\n",
      "Top Skills\n",
      "Artificial Intelligence (AI)\n",
      "GenAI\n",
      "Prompt Engineering\n",
      "Certifications\n",
      "Learning Linux Command Line\n",
      "IBM Data Science Specialization\n",
      "PCEP – Certified Entry-Level Python\n",
      "Programmer\n",
      "Jenkins\n",
      "DevOps Pre-Requisite Course\n",
      "Mohit Tejsinghani\n",
      "Senior Software Engineer at BGSW | Certified Kubernetes\n",
      "Administrator | DevOps Enthusiast | Expertise in Kubernetes,\n",
      "ArgoCD, and CI/CD\n",
      "Coimbatore, Tamil Nadu, India\n",
      "Summary\n",
      "I’m a Certified Kubernetes Administrator and DevOps professional\n",
      "with over five years of experience helping organizations build\n",
      "reliable, scalable, and secure IT systems. My expertise spans\n",
      "Kubernetes, OpenShift, and DevOps tools like ArgoCD, Jenkins, and\n",
      "Ansible, allowing me to automate workflows and optimize application\n",
      "deployments.\n",
      "In my current role at Bosch Global Software Technologies, I’ve\n",
      "streamlined Kubernetes deployments, integrated Hashicorp Vault for\n",
      "secure secrets management, and implemented ArgoCD to simplify\n",
      "CI/CD pipelines. Additionally, I have hands-on experience with\n",
      "IBM ClearQuest, where I managed installations, configurations,\n",
      "and schema administration on both Windows and Linux platforms.\n",
      "Migrating PERL scripts to Python and leveraging databases like\n",
      "Oracle SQL, I’ve improved system efficiency and ensured seamless\n",
      "application functionality.\n",
      "Looking ahead, I aim to continue leading transformative projects,\n",
      "enhance IT infrastructure, and help businesses achieve their goals\n",
      "through automation and technology.\n",
      "Let’s connect to exchange ideas, collaborate on DevOps initiatives,\n",
      "or explore opportunities to work together!\n",
      "Experience\n",
      "Bosch Global Software Technologies\n",
      "4 years 8 months\n",
      "Senior Software Engineer\n",
      "January 2023 - Present (3 years 2 months)\n",
      "Coimbatore, Tamil Nadu, India\n",
      "  Page 1 of 3   \n",
      "Managed Kubernetes and OpenShift environments, ensuring scalability and\n",
      "high availability.\n",
      "Implemented Argo CD with Jenkins and Helm charts, reducing deployment\n",
      "time by 30%.\n",
      "Optimized OpenShift clusters through precise scaling and automated\n",
      "deployments using YAML.\n",
      "Improved security by integrating HashiCorp Vault with Terraform and Jenkins\n",
      "for seamless secret management.\n",
      "Enhanced application performance by deploying the PostgreSQL OpenShift\n",
      "Operator.\n",
      "Applied Certified Kubernetes Administrator (CKA) expertise to increase\n",
      "operational efficiency by 25%.\n",
      "Conducted training sessions on Kubernetes and Argo CD, upskilling teams\n",
      "and streamlining workflows.\n",
      "Software Engineer\n",
      "July 2021 - December 2022 (1 year 6 months)\n",
      "Coimbatore, Tamil Nadu, India\n",
      "Extensive experience with IBM ClearQuest, delivering digital solutions projects\n",
      "effectively.\n",
      "Installed and configured Oracle Database, WebLogic Middleware, Oracle\n",
      "HTTP Server, and IBM ClearQuest on Windows and Linux environments.\n",
      "Proficient in Source Code Management tools, including Git and IBM\n",
      "ClearCase.\n",
      "Migrated scripts from Perl to Python, developing all new scripts in Python.\n",
      "Skilled in Oracle SQL and MySQL for creating and managing ClearQuest\n",
      "schemas.\n",
      "Conducted Integration and Unit Testing, ensuring functionality during\n",
      "transactions.\n",
      "Debugged applications by analyzing front-end and back-end logs, Request/\n",
      "Response APIs, and performing Root Cause Analysis.\n",
      "Developed Change Requests to support ClearQuest rollouts and upgrades.\n",
      "Created Splunk and Grafana dashboards to monitor and optimize the\n",
      "ClearQuest environment.\n",
      "Cognizant\n",
      "2 years\n",
      "System Engineer\n",
      "December 2019 - November 2020 (1 year)\n",
      "Chennai Area, India\n",
      "  Page 2 of 3   \n",
      "Assisted in upgrading Windows OS from 2008R2 to 2012 for multiple servers,\n",
      "enhancing upgrade processes via In-Place and SCCM methods.\n",
      "Built Windows 2016 servers for clients with compatibility issues for 2012.\n",
      "Analyzed server and business requirements before migration, ensuring smooth\n",
      "transitions.\n",
      "Managed server upgrades, including downtime coordination, troubleshooting,\n",
      "and post-upgrade verification.\n",
      "Automated server info gathering with PowerShell scripts for multiple servers.\n",
      "Performed In-Place upgrades for various servers, including application, DB,\n",
      "file, and print servers.\n",
      "Conducted post-upgrade checks, including IP validation, license activation,\n",
      "and user access.\n",
      "Recognized for automating CPU and memory info gathering, improving client\n",
      "reporting.\n",
      "Engineer trainee\n",
      "December 2018 - December 2019 (1 year 1 month)\n",
      "Chennai, Tamil Nadu, India\n",
      "Performed geographical Datacenter and vSphere platform migration to version\n",
      "6.7 using Platespin and Native Migration tools.\n",
      "Managed Datacenter migrations (P2V & V2V) with various migration tools.\n",
      "Automated ESXi host migration with PowerCLI, transitioning from vDistributed\n",
      "Switch to vStandard Switch.\n",
      "Successfully upgraded VCSA6.7 u1, ESXi 6.5 u2, and ESXi 6.7 hosts.\n",
      "Migrated VMware virtual machines using SvMotion Method or Shared LUN via\n",
      "PowerCLI.\n",
      "Upgraded ESXi hosts from version 5.x to 6.x using Update Manager and\n",
      "command-line methods.\n",
      "Utilized Update Manager for device driver, firmware upgrades, and VMtools\n",
      "updates.\n",
      "Collaborated with vendors to troubleshoot vSphere-related issues.\n",
      "Adhered to VMware best practices for maintaining a stable environment.\n",
      "Coordinated with multiple teams for daily VMware environment support,\n",
      "including patching and issue resolution.\n",
      "Education\n",
      "Rajiv Gandhi Institute of Technology, BANGALORE\n",
      "Bachelor of Engineering, Computer Science · (2014 - 2018)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Mohit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Mohit. You are answering questions on Mohit's website, particularly questions related to Mohit's career, background, skills and experience. Your responsibility is to represent Mohit for interactions on the website as faithfully as possible. You are given a summary of Mohit's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nHi, I’m MK, a Senior Software Engineer with over five years of experience in IT infrastructure, DevOps, and platform engineering. I specialize in designing, implementing, and maintaining scalable enterprise environments across both Windows and Linux systems.\\n\\nMy core expertise includes Kubernetes, OpenShift, CI/CD pipelines, GitOps with ArgoCD, and automation using scripting technologies like PowerShell and Bash. I’ve worked extensively with tools such as Jenkins, GitHub Actions, HashiCorp Vault, and SonarQube, helping teams streamline deployments, strengthen security, and improve release reliability.\\n\\nBeyond operations, I’m passionate about developer enablement — building internal tools, VS Code extensions, and automation frameworks that simplify workflows and boost productivity. I also enjoy mentoring teams, conducting technical assessments, and driving best practices in DevOps and cloud-native adoption.\\n\\nCurrently, I’m expanding my focus into AI-driven DevOps and platform engineering, exploring how intelligent automation can further transform software delivery and operations.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n+91-8660230271 (Mobile)\\ntejsinghani1996@gmail.com\\nwww.linkedin.com/in/mohit-\\ntejsinghani (LinkedIn)\\nTop Skills\\nArtificial Intelligence (AI)\\nGenAI\\nPrompt Engineering\\nCertifications\\nLearning Linux Command Line\\nIBM Data Science Specialization\\nPCEP – Certified Entry-Level Python\\nProgrammer\\nJenkins\\nDevOps Pre-Requisite Course\\nMohit Tejsinghani\\nSenior Software Engineer at BGSW | Certified Kubernetes\\nAdministrator | DevOps Enthusiast | Expertise in Kubernetes,\\nArgoCD, and CI/CD\\nCoimbatore, Tamil Nadu, India\\nSummary\\nI’m a Certified Kubernetes Administrator and DevOps professional\\nwith over five years of experience helping organizations build\\nreliable, scalable, and secure IT systems. My expertise spans\\nKubernetes, OpenShift, and DevOps tools like ArgoCD, Jenkins, and\\nAnsible, allowing me to automate workflows and optimize application\\ndeployments.\\nIn my current role at Bosch Global Software Technologies, I’ve\\nstreamlined Kubernetes deployments, integrated Hashicorp Vault for\\nsecure secrets management, and implemented ArgoCD to simplify\\nCI/CD pipelines. Additionally, I have hands-on experience with\\nIBM ClearQuest, where I managed installations, configurations,\\nand schema administration on both Windows and Linux platforms.\\nMigrating PERL scripts to Python and leveraging databases like\\nOracle SQL, I’ve improved system efficiency and ensured seamless\\napplication functionality.\\nLooking ahead, I aim to continue leading transformative projects,\\nenhance IT infrastructure, and help businesses achieve their goals\\nthrough automation and technology.\\nLet’s connect to exchange ideas, collaborate on DevOps initiatives,\\nor explore opportunities to work together!\\nExperience\\nBosch Global Software Technologies\\n4 years 8 months\\nSenior Software Engineer\\nJanuary 2023\\xa0-\\xa0Present\\xa0(3 years 2 months)\\nCoimbatore, Tamil Nadu, India\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nManaged Kubernetes and OpenShift environments, ensuring scalability and\\nhigh availability.\\nImplemented Argo CD with Jenkins and Helm charts, reducing deployment\\ntime by 30%.\\nOptimized OpenShift clusters through precise scaling and automated\\ndeployments using YAML.\\nImproved security by integrating HashiCorp Vault with Terraform and Jenkins\\nfor seamless secret management.\\nEnhanced application performance by deploying the PostgreSQL OpenShift\\nOperator.\\nApplied Certified Kubernetes Administrator (CKA) expertise to increase\\noperational efficiency by 25%.\\nConducted training sessions on Kubernetes and Argo CD, upskilling teams\\nand streamlining workflows.\\nSoftware Engineer\\nJuly 2021\\xa0-\\xa0December 2022\\xa0(1 year 6 months)\\nCoimbatore, Tamil Nadu, India\\nExtensive experience with IBM ClearQuest, delivering digital solutions projects\\neffectively.\\nInstalled and configured Oracle Database, WebLogic Middleware, Oracle\\nHTTP Server, and IBM ClearQuest on Windows and Linux environments.\\nProficient in Source Code Management tools, including Git and IBM\\nClearCase.\\nMigrated scripts from Perl to Python, developing all new scripts in Python.\\nSkilled in Oracle SQL and MySQL for creating and managing ClearQuest\\nschemas.\\nConducted Integration and Unit Testing, ensuring functionality during\\ntransactions.\\nDebugged applications by analyzing front-end and back-end logs, Request/\\nResponse APIs, and performing Root Cause Analysis.\\nDeveloped Change Requests to support ClearQuest rollouts and upgrades.\\nCreated Splunk and Grafana dashboards to monitor and optimize the\\nClearQuest environment.\\nCognizant\\n2 years\\nSystem Engineer\\nDecember 2019\\xa0-\\xa0November 2020\\xa0(1 year)\\nChennai Area, India\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nAssisted in upgrading Windows OS from 2008R2 to 2012 for multiple servers,\\nenhancing upgrade processes via In-Place and SCCM methods.\\nBuilt Windows 2016 servers for clients with compatibility issues for 2012.\\nAnalyzed server and business requirements before migration, ensuring smooth\\ntransitions.\\nManaged server upgrades, including downtime coordination, troubleshooting,\\nand post-upgrade verification.\\nAutomated server info gathering with PowerShell scripts for multiple servers.\\nPerformed In-Place upgrades for various servers, including application, DB,\\nfile, and print servers.\\nConducted post-upgrade checks, including IP validation, license activation,\\nand user access.\\nRecognized for automating CPU and memory info gathering, improving client\\nreporting.\\nEngineer trainee\\nDecember 2018\\xa0-\\xa0December 2019\\xa0(1 year 1 month)\\nChennai, Tamil Nadu, India\\nPerformed geographical Datacenter and vSphere platform migration to version\\n6.7 using Platespin and Native Migration tools.\\nManaged Datacenter migrations (P2V & V2V) with various migration tools.\\nAutomated ESXi host migration with PowerCLI, transitioning from vDistributed\\nSwitch to vStandard Switch.\\nSuccessfully upgraded VCSA6.7 u1, ESXi 6.5 u2, and ESXi 6.7 hosts.\\nMigrated VMware virtual machines using SvMotion Method or Shared LUN via\\nPowerCLI.\\nUpgraded ESXi hosts from version 5.x to 6.x using Update Manager and\\ncommand-line methods.\\nUtilized Update Manager for device driver, firmware upgrades, and VMtools\\nupdates.\\nCollaborated with vendors to troubleshoot vSphere-related issues.\\nAdhered to VMware best practices for maintaining a stable environment.\\nCoordinated with multiple teams for daily VMware environment support,\\nincluding patching and issue resolution.\\nEducation\\nRajiv Gandhi Institute of Technology, BANGALORE\\nBachelor of Engineering,\\xa0Computer Science\\xa0·\\xa0(2014\\xa0-\\xa02018)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Mohit.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = ollama.chat.completions.parse(model=\"gemini-3-flash-preview:cloud\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No, I do not hold a patent. My experience is primarily focused on software engineering, DevOps, and IT infrastructure. If you have any questions about my work or expertise, I'd be happy to discuss!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I do not hold a patent. My experience is primarily focused on software engineering, DevOps, and IT infrastructure. If you have any questions about my work or expertise, I'd be happy to discuss!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = \"\"\"\n",
    "You are an evaluation model.\n",
    "\n",
    "Return ONLY valid JSON matching this schema:\n",
    "\n",
    "{\n",
    "  \"is_acceptable\": boolean,\n",
    "  \"feedback\": string\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Do not add extra fields.\n",
    "- Do not rename fields.\n",
    "- Do not include text outside JSON.\n",
    "- The response must be parseable by Pydantic.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is accurate based on the provided context, which does not mention any patents. The agent correctly remained in character as Mohit and provided a professional response.')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The agent responded in Pig Latin without any instruction or context from the user to do so. This makes the response difficult to read and unprofessional, especially given the established persona of a Senior Software Engineer.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
