{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE API Key exists and begins AIzaSyAJ\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"GOOGLE API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"GOOGLE API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "#openai = OpenAI()\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 = 4\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"}]\n"
     ]
    }
   ],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the next number in the sequence: 2, 5, 16, 65, 326, ?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next number in the sequence is **1,957**.\n",
      "\n",
      "**Here is the pattern:**\n",
      "Each number in the sequence is multiplied by its position number (starting with 2) and then 1 is added to the result.\n",
      "\n",
      "*   2 × **2** + 1 = 5\n",
      "*   5 × **3** + 1 = 16\n",
      "*   16 × **4** + 1 = 65\n",
      "*   65 × **5** + 1 = 326\n",
      "*   326 × **6** + 1 = **1,957**\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The next number in the sequence is **1,957**.\n",
       "\n",
       "**Here is the pattern:**\n",
       "Each number in the sequence is multiplied by its position number (starting with 2) and then 1 is added to the result.\n",
       "\n",
       "*   2 × **2** + 1 = 5\n",
       "*   5 × **3** + 1 = 16\n",
       "*   16 × **4** + 1 = 65\n",
       "*   65 × **5** + 1 = 326\n",
       "*   326 × **6** + 1 = **1,957**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Autonomous supply chain orchestration and real-time logistics remediation.\n",
      "Pain_Point:A significant pain point in autonomous supply chain orchestration is **The Remediation Latency Gap in Multi-Tier Exceptions.**\n",
      "\n",
      "While the industry has largely solved \"visibility\" (knowing where a shipment is), it has failed to solve \"prescriptive action\" across fragmented silos.\n",
      "\n",
      "### The Pain Point: \"The Manual War Room\"\n",
      "In the current landscape, when a \"black swan\" or even a \"grey swan\" event occurs (e.g., a port strike, a Tier-2 supplier factory fire, or a sudden demand spike), the system typically generates an **alert.** \n",
      "\n",
      "However, the **remediation**—the actual fixing of the problem—remains a grueling, manual process involving \"War Rooms.\" Logistics managers must:\n",
      "1.  Check the TMS (Transportation Management System) for alternative routes.\n",
      "2.  Check the ERP (Enterprise Resource Planning) to see which customer orders are prioritized.\n",
      "3.  Check the WMS (Warehouse Management System) for labor availability to handle an expedited shipment.\n",
      "4.  Send dozens of emails/calls to 3PLs (Third-party logistics) to negotiate spot rates for a reroute.\n",
      "\n",
      "**The result:** By the time a human coordinates these four silos, the \"window of opportunity\" to fix the problem cheaply has closed, and the company is forced into expensive, last-minute air freight or suffers a production line shutdown.\n",
      "\n",
      "---\n",
      "\n",
      "### Why this is Ripe for an \"Agentic Solution\"\n",
      "\n",
      "Traditional automation (RPA or basic AI) fails here because these tasks are not linear; they require **reasoning, trade-off analysis, and cross-platform negotiation.**\n",
      "\n",
      "An **Agentic Orchestrator** doesn't just \"alert\"; it \"acts.\" Here is how an Agentic solution transforms this:\n",
      "\n",
      "#### 1. Autonomous Trade-off Reasoning\n",
      "Unlike a standard algorithm, an AI Agent can weigh conflicting KPIs. \n",
      "*   *The Scenario:* A shipment is 48 hours late. \n",
      "*   *The Agent's Logic:* \"If I expedite this via air, it costs $5,000 extra (hitting the logistics budget). However, if I do nothing, the factory line stops, costing $50,000 in lost productivity (hitting the operations budget). Based on the CFO’s current mandates on margin preservation, I will choose the $5,000 expedite.\"\n",
      "\n",
      "#### 2. Inter-Agent Negotiation (The \"Agentic Mesh\")\n",
      "Instead of a human calling five carriers for a spot rate, the **Shipper Agent** communicates directly with **Carrier Agents**.\n",
      "*   The Shipper Agent sends a \"Request for Remediation\" to a network of carrier bots.\n",
      "*   They negotiate price and ETA in milliseconds.\n",
      "*   The Agent executes the booking and updates the manifest without human intervention.\n",
      "\n",
      "#### 3. Closing the \"Feedback Loop\" Silo\n",
      "The biggest issue in supply chains is that the Logistics team often doesn't know what the Sales team promised. \n",
      "*   An Agentic solution can \"read\" the latest contract terms in the CLM (Contract Lifecycle Management) and prioritize shipments for the customers with the highest \"Service Level Agreement\" (SLA) penalties.\n",
      "\n",
      "### The \"Agentic\" Opportunity\n",
      "The goal is to move from **Human-in-the-loop** (where the human does the work) to **Human-on-the-loop** (where the agent presents the solved solution and the human hits \"Approve,\" or the agent acts autonomously within a pre-set \"authority limit\").\n",
      "\n",
      "**The Value Prop:** Reducing \"Mean Time to Recover\" (MTTR) from 24 hours to 24 seconds. This prevents the \"bullwhip effect\" where a small delay in the beginning of the chain creates a catastrophe at the end.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "This proposal outlines a comprehensive Agentic AI solution called **AetherSentry**, designed to eliminate the \"Manual War Room\" by transitioning from reactive visibility to autonomous, cross-silo remediation.\n",
       "\n",
       "---\n",
       "\n",
       "# Project Name: AetherSentry\n",
       "**Tagline:** Moving Supply Chains from \"Informed\" to \"Self-Healing.\"\n",
       "\n",
       "## 1. The Core Architecture: The \"Agentic Mesh\"\n",
       "Unlike traditional software that connects systems via rigid APIs, AetherSentry deploys a **Swarm of Specialized Agents** that inhabit different layers of the supply chain. These agents possess \"Tool-Use\" capabilities, meaning they don't just read data; they execute actions within your existing software stack (SAP, Oracle, BlueYonder, etc.).\n",
       "\n",
       "### The Agent Roster:\n",
       "*   **The Strategist (Orchestrator Agent):** Holds the \"Business Intent.\" It understands high-level KPIs (e.g., \"Minimize CO2,\" \"Protect Tier-1 Customer Margins,\" or \"Prioritize Q4 Revenue\").\n",
       "*   **The Diplomats (Procurement Agents):** Programmed to negotiate. They live in the \"External Mesh,\" interacting with Carrier and Supplier APIs/Agents to secure spot rates and capacity.\n",
       "*   **The Analysts (Silo Agents):** One for the ERP, one for the TMS, and one for the WMS. They translate raw data into \"Actionable State\" for the Strategist.\n",
       "*   **The Jurist (Contract Agent):** Scans CLM (Contract Lifecycle Management) and SLAs to calculate the legal and financial penalty of any given delay.\n",
       "\n",
       "---\n",
       "\n",
       "## 2. The Solution: \"Autonomous Remediation Loops\"\n",
       "AetherSentry solves the **Remediation Latency Gap** through a three-step autonomous loop:\n",
       "\n",
       "### Phase I: Impact Simulation (The \"Reasoning\" Step)\n",
       "When a \"Grey Swan\" (e.g., a 48-hour port delay) is detected, the **Strategist Agent** triggers a simulation.\n",
       "*   **The Silo Agents** report: \"Factory A will run out of parts in 12 hours. Warehouse B has labor scheduled for a shipment that won't arrive.\"\n",
       "*   **The Jurist Agent** reports: \"Delaying this shipment triggers a $10k penalty with Amazon, but only a $2k penalty with a local distributor.\"\n",
       "*   **The Strategist** calculates the \"Total Cost of Disruption\" vs. the \"Total Cost of Remediation.\"\n",
       "\n",
       "### Phase II: Autonomous Multi-Party Negotiation\n",
       "Instead of a human making calls, the **Diplomat Agent** executes a \"Parallel Tender\":\n",
       "1.  It broadcasts a \"Remediation Request\" to a pre-approved network of carrier bots.\n",
       "2.  It uses **Reinforcement Learning** to negotiate: \"I need this moved from port to factory in 6 hours. My ceiling price is $4,000. Do I have a taker?\"\n",
       "3.  It evaluates offers based on both price and the carrier's historical reliability (Real-time Trust Score).\n",
       "\n",
       "### Phase III: The Execution & Update\n",
       "Once a solution is found:\n",
       "*   The **TMS Agent** books the new route.\n",
       "*   The **ERP Agent** re-prioritizes the production schedule.\n",
       "*   The **WMS Agent** sends a notification to the warehouse floor to cancel the morning labor shift and reschedule for the evening.\n",
       "*   The **Customer Agent** sends a proactive, personalized update to the affected clients.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Key Feature: \"Governance via Guardrails\"\n",
       "To move from **Human-in-the-loop** to **Human-on-the-loop**, AetherSentry uses a **Delegated Authority Matrix**:\n",
       "*   **Level 1 (Autonomous):** If the remediation cost is <$5,000 and protects an SLA, the Agent acts and sends a summary report.\n",
       "*   **Level 2 (Collaborative):** If the cost is $5,000–$50,000, the Agent prepares the top 3 options (with trade-off analysis) and sends a \"One-Click Approval\" notification to the Manager's mobile.\n",
       "*   **Level 3 (Escalation):** If the event is a \"Black Swan\" (e.g., total port closure), the Agent initializes the digital \"War Room,\" prepopulating it with all relevant data, alternative routes, and financial impact assessments so humans can start at the \"Decision Step\" rather than the \"Data Gathering Step.\"\n",
       "\n",
       "---\n",
       "\n",
       "## 4. The Value Proposition (The \"So What?\")\n",
       "\n",
       "| Metric | Traditional \"War Room\" | AetherSentry Agentic Solution |\n",
       "| :--- | :--- | :--- |\n",
       "| **Mean Time to Recover (MTTR)** | 12 – 24 Hours | < 60 Seconds |\n",
       "| **Data Collection** | Manual (Excel, Phone, Email) | Instantaneous (Agentic Mesh) |\n",
       "| **Decision Logic** | Emotional / Intuitive | Probabilistic / KPI-Driven |\n",
       "| **Cost of Remediation** | High (Last minute/Panic) | Optimized (Negotiated/Bidded) |\n",
       "| **Human Effort** | 100% Manual Coordination | Exception-only Oversight |\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Implementation Roadmap: The \"Crawl-Walk-Run\" Agent Strategy\n",
       "\n",
       "1.  **Crawl (The Shadow Agent):** Deploy AetherSentry in \"Read-Only\" mode. It observes human remediation and generates \"What I would have done\" reports to build trust and tune the reasoning engine.\n",
       "2.  **Walk (The Assistant):** The Agent handles data gathering and provides the \"One-Click Approval\" options for all exceptions.\n",
       "3.  **Run (The Orchestrator):** Full autonomous remediation within pre-set financial guardrails. The system only alerts humans when a conflict occurs that violates core business constraints.\n",
       "\n",
       "**Summary:** AetherSentry doesn't just tell you the ship is late; it has already rerouted the cargo, updated the factory schedule, and negotiated the discount with the customer before you've even finished your morning coffee."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Please, pick a business area tha might be worth exploring for an Agentic AI oportunity.Respond only with the bussines idea.\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "print(f\"Business {business_idea}\")\n",
    "\n",
    "messages = [{\"role\":\"user\", \"content\": f\"Present a pain-point in the industry {business_idea} - something that might be ripe for an Agentic Solution\"}]\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "pain_point=response.choices[0].message.content\n",
    "print(f\"Pain_Point:{pain_point}\")\n",
    "messages = [{\"role\":\"user\", \"content\": f\"Propose a Agentic AI Solution to the business idea: {business_idea}, using the pain-point: {pain_point}\"}]\n",
    "\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages\n",
    ")\n",
    "resultado=response.choices[0].message.content\n",
    "display(Markdown(resultado))\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
