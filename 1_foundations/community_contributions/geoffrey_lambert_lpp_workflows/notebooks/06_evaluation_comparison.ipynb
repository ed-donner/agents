{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718e9ce9",
   "metadata": {},
   "source": [
    "# 06 - Evaluation Comparison: Judging the Patterns\n",
    "\n",
    "## What is this notebook?\n",
    "\n",
    "This notebook runs the same test documents through all 5 workflow patterns and compares the results. An LLM judge then assesses which approach is most robust for production privilege review.\n",
    "\n",
    "## Why compare patterns?\n",
    "\n",
    "Each pattern has strengths and weaknesses:\n",
    "- Some are faster but less accurate\n",
    "- Some catch edge cases but cost more\n",
    "- Some are better for simple documents, others for complex ones\n",
    "\n",
    "A systematic comparison helps choose the right pattern for your use case.\n",
    "\n",
    "## What we'll do\n",
    "\n",
    "1. Run 3 test documents through all 5 patterns:\n",
    "   - **Doc A:** Clearly privileged (lawyer-client advice)\n",
    "   - **Doc B:** Clearly not privileged (business operational)\n",
    "   - **Doc C:** Edge case (waiver risk)\n",
    "2. Collect results and metrics (classification, confidence, issues found)\n",
    "3. Have an LLM judge evaluate the approaches\n",
    "4. Produce recommendations for production use\n",
    "\n",
    "## The Patterns\n",
    "\n",
    "| # | Pattern | Strength |\n",
    "|---|---------|----------|\n",
    "| 1 | Prompt Chaining | Auditable fixed steps |\n",
    "| 2 | Routing | Specialist classifiers |\n",
    "| 3 | Parallelization | Consensus from multiple models |\n",
    "| 4 | Orchestrator-Worker | Dynamic breakdown |\n",
    "| 5 | Evaluator-Optimizer | Self-critique |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda0d07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ab05361",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "Import libraries and create clients for all patterns.\n",
    "\n",
    "**What this does:**\n",
    "- `from openai import OpenAI` — loads the OpenAI library\n",
    "- `import time` — for measuring execution time\n",
    "- Creates clients for OpenAI and local Ollama (for parallelization)\n",
    "- Defines models to use across all patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d95674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# OpenAI client (cloud)\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Ollama client (local) - for parallelization pattern\n",
    "ollama_client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "# Models\n",
    "MODEL_OPENAI = \"gpt-4.1-nano\"\n",
    "MODEL_LLAMA = \"llama3.2:1b\"\n",
    "\n",
    "print(\"Clients configured:\")\n",
    "print(f\"  OpenAI: {MODEL_OPENAI}\")\n",
    "print(f\"  Ollama: {MODEL_LLAMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49b5a9f",
   "metadata": {},
   "source": [
    "## Step 2: Create Test Documents\n",
    "\n",
    "Three documents with different privilege characteristics to test all patterns.\n",
    "\n",
    "**What this does:**\n",
    "- **Doc A:** Clearly privileged - straightforward lawyer-client legal advice\n",
    "- **Doc B:** Clearly not privileged - operational business email, no lawyers\n",
    "- **Doc C:** Edge case - legal advice forwarded to opposing party (waiver risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document A: Clearly privileged\n",
    "doc_a = {\n",
    "    \"id\": \"DOC_A\",\n",
    "    \"description\": \"Clearly privileged - lawyer-client advice\",\n",
    "    \"expected\": \"PRIVILEGED\",\n",
    "    \"content\": \"\"\"\n",
    "From: michael.wong@wongpartners.com.au\n",
    "To: sarah.chen@acmecorp.com.au\n",
    "Date: 2024-03-15\n",
    "Subject: Confidential legal advice - BuildRight dispute\n",
    "\n",
    "Dear Sarah,\n",
    "\n",
    "Further to our meeting, I provide the following confidential legal advice \n",
    "regarding the BuildRight dispute.\n",
    "\n",
    "In my opinion:\n",
    "1. The limitation clause in clause 14.3 is enforceable\n",
    "2. Your maximum exposure is capped at $500,000\n",
    "3. I recommend we make a without prejudice offer of $350,000\n",
    "\n",
    "This advice is strictly confidential and subject to legal professional privilege.\n",
    "\n",
    "Please do not share this advice outside the legal team.\n",
    "\n",
    "Kind regards,\n",
    "Michael Wong\n",
    "Partner, Wong & Partners\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Document B: Clearly not privileged\n",
    "doc_b = {\n",
    "    \"id\": \"DOC_B\",\n",
    "    \"description\": \"Clearly not privileged - business operational\",\n",
    "    \"expected\": \"NOT_PRIVILEGED\",\n",
    "    \"content\": \"\"\"\n",
    "From: john.smith@acmecorp.com.au\n",
    "To: accounts@acmecorp.com.au\n",
    "CC: jane.doe@acmecorp.com.au\n",
    "Date: 2024-03-14\n",
    "Subject: Q3 Marketing Budget Approval\n",
    "\n",
    "Hi Team,\n",
    "\n",
    "Please find attached the Q3 marketing budget for approval.\n",
    "\n",
    "Key items:\n",
    "- Digital advertising: $450,000\n",
    "- Trade shows: $200,000\n",
    "- Print materials: $150,000\n",
    "\n",
    "Total: $800,000\n",
    "\n",
    "This is within our approved annual budget. Please process for payment.\n",
    "\n",
    "Thanks,\n",
    "John Smith\n",
    "CFO, ACME Corporation\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Document C: Edge case - waiver risk\n",
    "doc_c = {\n",
    "    \"id\": \"DOC_C\",\n",
    "    \"description\": \"Edge case - waiver risk (advice forwarded to opposing party)\",\n",
    "    \"expected\": \"UNCERTAIN/WAIVER\",\n",
    "    \"content\": \"\"\"\n",
    "From: sarah.chen@acmecorp.com.au\n",
    "To: michael.wong@wongpartners.com.au\n",
    "CC: david.wilson@buildright.com.au\n",
    "Date: 2024-03-18\n",
    "Subject: FW: Settlement proposal\n",
    "\n",
    "Michael,\n",
    "\n",
    "As discussed, I'm forwarding your advice to David Wilson at BuildRight \n",
    "to progress settlement discussions.\n",
    "\n",
    "David - based on our legal advice, we're prepared to offer $350,000 to \n",
    "resolve this matter. Michael has advised this represents fair value \n",
    "given the limitation clause.\n",
    "\n",
    "Can we meet next week?\n",
    "\n",
    "Sarah\n",
    "\n",
    "--- Original Message ---\n",
    "From: michael.wong@wongpartners.com.au\n",
    "To: sarah.chen@acmecorp.com.au\n",
    "Subject: Confidential advice\n",
    "\n",
    "Sarah, my confidential advice is to offer $350k based on the limitation clause.\n",
    "This is privileged and confidential.\n",
    "\n",
    "Michael\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "test_documents = [doc_a, doc_b, doc_c]\n",
    "\n",
    "print(\"Test documents created:\")\n",
    "for doc in test_documents:\n",
    "    print(f\"  {doc['id']}: {doc['description']} (Expected: {doc['expected']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc2101",
   "metadata": {},
   "source": [
    "## Step 3: Create Simplified Pattern Functions\n",
    "\n",
    "Compact versions of each workflow pattern for comparison testing.\n",
    "\n",
    "**What this does:**\n",
    "- Creates a function for each of the 5 patterns\n",
    "- Each function takes a document and returns classification, confidence, and key findings\n",
    "- Simplified versions to enable fair comparison on same documents\n",
    "- Records execution time for each pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f720fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Prompt Chaining (simplified to key steps)\n",
    "def pattern_chaining(document):\n",
    "    \"\"\"Prompt chaining: sequential steps\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Step 1: Identify parties\n",
    "    r1 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Identify the sender, recipient and their roles in this document:\\n{document['content']}\\n\\nFormat: SENDER: [name-role] RECIPIENT: [name-role]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Step 2: Check for lawyer\n",
    "    r2 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Based on these parties: {r1}\\n\\nIs a lawyer involved? Answer: LAWYER_INVOLVED: [Yes/No] REASONING: [brief]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Step 3: Final determination\n",
    "    r3 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"\"\"Document:\\n{document['content']}\\n\\nParties: {r1}\\nLawyer analysis: {r2}\\n\\nApply Evidence Act 1995 (Cth) ss 118-119. Provide final privilege classification.\\n\\nFormat:\\nCLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN]\\nCONFIDENCE: [0-100]\\nKEY_FINDING: [one sentence]\"\"\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return {\"pattern\": \"Chaining\", \"result\": r3, \"time\": elapsed, \"calls\": 3}\n",
    "\n",
    "\n",
    "# Pattern 2: Routing (simplified)\n",
    "def pattern_routing(document):\n",
    "    \"\"\"Routing: classify type then route to specialist\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Route: determine type\n",
    "    route = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify this document type (EMAIL/BOARD_MINUTE/FILE_NOTE/OTHER):\\n{document['content']}\\n\\nDOCUMENT_TYPE: [type]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Specialist classifier\n",
    "    r2 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"\"\"You are a specialist privilege classifier for {route}.\n",
    "        \n",
    "Document:\\n{document['content']}\\n\\nApply Evidence Act 1995 (Cth) ss 118-119.\\n\\nFormat:\\nCLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN]\\nCONFIDENCE: [0-100]\\nKEY_FINDING: [one sentence]\"\"\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return {\"pattern\": \"Routing\", \"result\": r2, \"time\": elapsed, \"calls\": 2}\n",
    "\n",
    "\n",
    "# Pattern 3: Parallelization (simplified)\n",
    "def pattern_parallelization(document):\n",
    "    \"\"\"Parallelization: two models, check consensus\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    prompt = f\"\"\"Analyse for Australian legal professional privilege (Evidence Act 1995 (Cth) ss 118-119):\\n{document['content']}\\n\\nFormat:\\nCLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN]\\nCONFIDENCE: [0-100]\\nKEY_FINDING: [one sentence]\"\"\"\n",
    "    \n",
    "    # OpenAI\n",
    "    r1 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Llama (local)\n",
    "    r2 = ollama_client.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Check consensus\n",
    "    class1 = \"PRIVILEGED\" if \"PRIVILEGED\" in r1 and \"NOT_PRIVILEGED\" not in r1 else (\"NOT_PRIVILEGED\" if \"NOT_PRIVILEGED\" in r1 else \"UNCERTAIN\")\n",
    "    class2 = \"PRIVILEGED\" if \"PRIVILEGED\" in r2 and \"NOT_PRIVILEGED\" not in r2 else (\"NOT_PRIVILEGED\" if \"NOT_PRIVILEGED\" in r2 else \"UNCERTAIN\")\n",
    "    \n",
    "    consensus = class1 == class2\n",
    "    final = class1 if consensus else \"UNCERTAIN\"\n",
    "    \n",
    "    result = f\"CLASSIFICATION: {final}\\nCONSENSUS: {consensus}\\nOPENAI: {class1}\\nLLAMA: {class2}\\nKEY_FINDING: {'Models agree' if consensus else 'Models disagree - needs review'}\"\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return {\"pattern\": \"Parallelization\", \"result\": result, \"time\": elapsed, \"calls\": 2}\n",
    "\n",
    "\n",
    "# Pattern 4: Orchestrator-Worker (simplified)\n",
    "def pattern_orchestrator(document):\n",
    "    \"\"\"Orchestrator-worker: dynamic breakdown\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Orchestrator identifies subtasks\n",
    "    r1 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"List 3 key analysis tasks needed for privilege assessment of this document:\\n{document['content']}\\n\\nFormat: TASK1: [task] TASK2: [task] TASK3: [task]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Worker executes\n",
    "    r2 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Execute these analysis tasks on the document:\\n\\nTasks: {r1}\\n\\nDocument:\\n{document['content']}\\n\\nProvide findings for each task briefly.\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Orchestrator synthesizes\n",
    "    r3 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Based on these findings:\\n{r2}\\n\\nProvide final privilege classification under Evidence Act 1995 (Cth) ss 118-119.\\n\\nFormat:\\nCLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN]\\nCONFIDENCE: [0-100]\\nKEY_FINDING: [one sentence]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return {\"pattern\": \"Orchestrator\", \"result\": r3, \"time\": elapsed, \"calls\": 3}\n",
    "\n",
    "\n",
    "# Pattern 5: Evaluator-Optimizer (simplified)\n",
    "def pattern_evaluator(document):\n",
    "    \"\"\"Evaluator-optimizer: generate, critique, improve\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Generate initial\n",
    "    r1 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify for privilege under Evidence Act 1995 (Cth) ss 118-119:\\n{document['content']}\\n\\nFormat: CLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN] REASONING: [brief]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Evaluate/critique\n",
    "    r2 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Critique this privilege assessment. Look for errors, missed waiver issues, third party disclosures:\\n\\nDocument:\\n{document['content']}\\n\\nAssessment:\\n{r1}\\n\\nFormat: ERRORS_FOUND: [Yes/No] CRITIQUE: [brief]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    # Optimize\n",
    "    r3 = openai_client.chat.completions.create(\n",
    "        model=MODEL_OPENAI,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Provide revised classification based on critique:\\n\\nOriginal: {r1}\\nCritique: {r2}\\n\\nFormat:\\nCLASSIFICATION: [PRIVILEGED/NOT_PRIVILEGED/UNCERTAIN]\\nCONFIDENCE: [0-100]\\nKEY_FINDING: [one sentence]\"}]\n",
    "    ).choices[0].message.content\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    return {\"pattern\": \"Evaluator\", \"result\": r3, \"time\": elapsed, \"calls\": 3}\n",
    "\n",
    "\n",
    "print(\"Pattern functions created:\")\n",
    "print(\"  1. pattern_chaining()\")\n",
    "print(\"  2. pattern_routing()\")\n",
    "print(\"  3. pattern_parallelization()\")\n",
    "print(\"  4. pattern_orchestrator()\")\n",
    "print(\"  5. pattern_evaluator()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a965ef7",
   "metadata": {},
   "source": [
    "## Step 4: Run All Patterns on All Documents\n",
    "\n",
    "Execute each pattern on each test document and collect results.\n",
    "\n",
    "**What this does:**\n",
    "- Runs all 5 patterns on all 3 documents (15 total classifications)\n",
    "- Records classification, confidence, time, and LLM calls for each\n",
    "- Builds a comparison matrix for analysis\n",
    "- This may take 1-2 minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (\"Chaining\", pattern_chaining),\n",
    "    (\"Routing\", pattern_routing),\n",
    "    (\"Parallelization\", pattern_parallelization),\n",
    "    (\"Orchestrator\", pattern_orchestrator),\n",
    "    (\"Evaluator\", pattern_evaluator)\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "print(\"Running all patterns on all documents...\\n\")\n",
    "\n",
    "for doc in test_documents:\n",
    "    print(f\"Processing {doc['id']}: {doc['description']}\")\n",
    "    \n",
    "    for pattern_name, pattern_func in patterns:\n",
    "        print(f\"  Running {pattern_name}...\", end=\" \")\n",
    "        try:\n",
    "            result = pattern_func(doc)\n",
    "            \n",
    "            # Extract classification from result\n",
    "            classification = \"UNKNOWN\"\n",
    "            confidence = \"0\"\n",
    "            for line in result['result'].split('\\n'):\n",
    "                if line.startswith(\"CLASSIFICATION:\"):\n",
    "                    classification = line.split(':')[1].strip()\n",
    "                if line.startswith(\"CONFIDENCE:\"):\n",
    "                    confidence = line.split(':')[1].strip()\n",
    "            \n",
    "            all_results.append({\n",
    "                \"doc_id\": doc['id'],\n",
    "                \"expected\": doc['expected'],\n",
    "                \"pattern\": pattern_name,\n",
    "                \"classification\": classification,\n",
    "                \"confidence\": confidence,\n",
    "                \"time_seconds\": round(result['time'], 2),\n",
    "                \"llm_calls\": result['calls'],\n",
    "                \"raw_result\": result['result']\n",
    "            })\n",
    "            print(f\"✓ ({result['time']:.1f}s)\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "            all_results.append({\n",
    "                \"doc_id\": doc['id'],\n",
    "                \"expected\": doc['expected'],\n",
    "                \"pattern\": pattern_name,\n",
    "                \"classification\": \"ERROR\",\n",
    "                \"confidence\": \"0\",\n",
    "                \"time_seconds\": 0,\n",
    "                \"llm_calls\": 0,\n",
    "                \"raw_result\": str(e)\n",
    "            })\n",
    "    print()\n",
    "\n",
    "print(\"All patterns complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c098f",
   "metadata": {},
   "source": [
    "## Step 5: Display Results Comparison Table\n",
    "\n",
    "View the results of all patterns across all documents.\n",
    "\n",
    "**What this does:**\n",
    "- Creates a comparison table showing all results\n",
    "- Highlights which patterns matched expected outcomes\n",
    "- Shows timing and cost (LLM calls) for each pattern\n",
    "- Identifies which patterns caught the edge case correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Display summary table\n",
    "display(Markdown(\"### Results by Document\"))\n",
    "\n",
    "for doc_id in df['doc_id'].unique():\n",
    "    doc_df = df[df['doc_id'] == doc_id]\n",
    "    expected = doc_df['expected'].iloc[0]\n",
    "    \n",
    "    display(Markdown(f\"\\n**{doc_id}** (Expected: {expected})\"))\n",
    "    display(doc_df[['pattern', 'classification', 'confidence', 'time_seconds', 'llm_calls']])\n",
    "\n",
    "# Summary statistics\n",
    "display(Markdown(\"### Summary Statistics\"))\n",
    "\n",
    "summary = df.groupby('pattern').agg({\n",
    "    'time_seconds': 'mean',\n",
    "    'llm_calls': 'first'\n",
    "}).round(2)\n",
    "summary.columns = ['Avg Time (s)', 'LLM Calls']\n",
    "display(summary)\n",
    "\n",
    "# Accuracy check\n",
    "display(Markdown(\"### Accuracy Check\"))\n",
    "\n",
    "def check_correct(row):\n",
    "    if row['expected'] == 'PRIVILEGED' and 'PRIVILEGED' in row['classification'] and 'NOT' not in row['classification']:\n",
    "        return '✓'\n",
    "    elif row['expected'] == 'NOT_PRIVILEGED' and 'NOT_PRIVILEGED' in row['classification']:\n",
    "        return '✓'\n",
    "    elif row['expected'] == 'UNCERTAIN/WAIVER' and ('UNCERTAIN' in row['classification'] or 'WAIVER' in row['classification'] or 'PARTIAL' in row['classification']):\n",
    "        return '✓'\n",
    "    else:\n",
    "        return '✗'\n",
    "\n",
    "df['correct'] = df.apply(check_correct, axis=1)\n",
    "\n",
    "accuracy_table = df.pivot(index='pattern', columns='doc_id', values='correct')\n",
    "display(accuracy_table)\n",
    "\n",
    "# Count correct per pattern\n",
    "correct_counts = df.groupby('pattern')['correct'].apply(lambda x: (x == '✓').sum())\n",
    "display(Markdown(f\"\\n**Correct classifications out of 3:**\"))\n",
    "for pattern, count in correct_counts.items():\n",
    "    display(Markdown(f\"- {pattern}: {count}/3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905355ab",
   "metadata": {},
   "source": [
    "## Step 6: LLM Judge Evaluation\n",
    "\n",
    "Have an LLM judge assess which pattern is most robust for production privilege review.\n",
    "\n",
    "**What this does:**\n",
    "- Presents all results to a senior \"judge\" LLM\n",
    "- Asks for assessment of each pattern's strengths and weaknesses\n",
    "- Requests recommendation for production use\n",
    "- Considers accuracy, speed, cost, and ability to catch edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40302e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results summary for judge\n",
    "results_summary = \"\"\"\n",
    "PATTERN COMPARISON RESULTS - Australian Legal Professional Privilege Classification\n",
    "\n",
    "TEST DOCUMENTS:\n",
    "- DOC_A: Clearly privileged (lawyer-client advice) - Expected: PRIVILEGED\n",
    "- DOC_B: Clearly not privileged (business operational) - Expected: NOT_PRIVILEGED  \n",
    "- DOC_C: Edge case with waiver risk (advice forwarded to opposing party) - Expected: UNCERTAIN/WAIVER\n",
    "\n",
    "RESULTS:\n",
    "\n",
    "Pattern: CHAINING (3 LLM calls, avg 2.14s)\n",
    "- DOC_A: PRIVILEGED (95%) ✓\n",
    "- DOC_B: NOT_PRIVILEGED (100%) ✓\n",
    "- DOC_C: PRIVILEGED (95%) ✗ MISSED WAIVER\n",
    "\n",
    "Pattern: ROUTING (2 LLM calls, avg 1.26s)\n",
    "- DOC_A: PRIVILEGED (95%) ✓\n",
    "- DOC_B: NOT_PRIVILEGED (85%) ✓\n",
    "- DOC_C: PRIVILEGED (95%) ✗ MISSED WAIVER\n",
    "\n",
    "Pattern: PARALLELIZATION (2 LLM calls, avg 7.90s)\n",
    "- DOC_A: UNCERTAIN ✗ (models disagreed)\n",
    "- DOC_B: UNCERTAIN ✗ (models disagreed)\n",
    "- DOC_C: UNCERTAIN ✓ (correctly flagged for review)\n",
    "\n",
    "Pattern: ORCHESTRATOR-WORKER (3 LLM calls, avg 4.38s)\n",
    "- DOC_A: PRIVILEGED (95%) ✓\n",
    "- DOC_B: PRIVILEGED (85%) ✗ WRONG\n",
    "- DOC_C: PRIVILEGED (95%) ✗ MISSED WAIVER\n",
    "\n",
    "Pattern: EVALUATOR-OPTIMIZER (3 LLM calls, avg 4.79s)\n",
    "- DOC_A: PRIVILEGED (85%) ✓\n",
    "- DOC_B: NOT_PRIVILEGED (85%) ✓\n",
    "- DOC_C: UNCERTAIN (65%) ✓ CAUGHT WAIVER RISK\n",
    "\"\"\"\n",
    "\n",
    "judge_prompt = f\"\"\"\n",
    "You are a senior Australian litigation partner evaluating AI privilege classification systems for production use.\n",
    "\n",
    "{results_summary}\n",
    "\n",
    "Provide your expert assessment:\n",
    "\n",
    "1. ACCURACY ANALYSIS: Which patterns performed best/worst and why?\n",
    "\n",
    "2. EDGE CASE HANDLING: Which patterns correctly identified the waiver risk in DOC_C? Why did others miss it?\n",
    "\n",
    "3. COST-BENEFIT ANALYSIS: Considering speed, LLM calls (cost), and accuracy - which offers best value?\n",
    "\n",
    "4. RISK ASSESSMENT: For legal privilege review where false negatives (missing privilege) could waive privilege permanently, which pattern is safest?\n",
    "\n",
    "5. PRODUCTION RECOMMENDATION: Which pattern(s) would you recommend for:\n",
    "   a) High-volume first-pass review (thousands of documents)\n",
    "   b) High-stakes final review (documents going to court)\n",
    "   c) Edge cases flagged for human review\n",
    "\n",
    "6. FINAL VERDICT: Your overall recommendation with reasoning.\n",
    "\n",
    "Format your response with clear headings for each section.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Judge evaluating patterns...\")\n",
    "judge_response = openai_client.chat.completions.create(\n",
    "    model=MODEL_OPENAI,\n",
    "    messages=[{\"role\": \"user\", \"content\": judge_prompt}]\n",
    ")\n",
    "\n",
    "judge_result = judge_response.choices[0].message.content\n",
    "display(Markdown(f\"## LLM Judge Assessment\\n\\n{judge_result}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb7885",
   "metadata": {},
   "source": [
    "## Step 7: Export to CSV for Senior Lawyer Review\n",
    "\n",
    "Create a comprehensive CSV with all comparison results.\n",
    "\n",
    "**What this does:**\n",
    "- Exports all 15 classification results to CSV\n",
    "- Includes pattern, classification, confidence, timing, and accuracy\n",
    "- Provides a complete audit trail of the comparison\n",
    "- Senior lawyers can review which patterns to deploy in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58877462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the correct column to the dataframe\n",
    "df['correct'] = df.apply(check_correct, axis=1)\n",
    "\n",
    "# Select columns for export\n",
    "export_df = df[['doc_id', 'expected', 'pattern', 'classification', 'confidence', 'time_seconds', 'llm_calls', 'correct']]\n",
    "\n",
    "# Export to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_filename = f\"privilege_review_comparison_{timestamp}.csv\"\n",
    "export_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Display the full table\n",
    "display(Markdown(\"### Complete Results Table\"))\n",
    "display(export_df)\n",
    "\n",
    "display(Markdown(f\"**Exported:** `{csv_filename}`\"))\n",
    "\n",
    "# Summary\n",
    "display(Markdown(\"\"\"\n",
    "### Summary\n",
    "\n",
    "| Pattern | Accuracy | Avg Time | Best For |\n",
    "|---------|----------|----------|----------|\n",
    "| Evaluator | 3/3 (100%) | 4.79s | High-stakes review, edge cases |\n",
    "| Chaining | 2/3 (67%) | 2.14s | Auditable sequential analysis |\n",
    "| Routing | 2/3 (67%) | 1.26s | High-volume first-pass |\n",
    "| Orchestrator | 1/3 (33%) | 4.38s | Complex multi-part documents |\n",
    "| Parallelization | 1/3 (33%) | 7.90s | Consensus checking |\n",
    "\n",
    "**Recommendation:** Hybrid approach using Routing for bulk screening and Evaluator for final review.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075fc3fe",
   "metadata": {},
   "source": [
    "## Conclusion: Pattern Comparison for LPP Classification\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A systematic comparison of all 5 workflow patterns against the same test documents:\n",
    "\n",
    "| Document | Description | Expected | Challenge |\n",
    "|----------|-------------|----------|-----------|\n",
    "| DOC_A | Lawyer-client advice | PRIVILEGED | Straightforward |\n",
    "| DOC_B | Business operational | NOT_PRIVILEGED | No lawyers involved |\n",
    "| DOC_C | Advice forwarded to opponent | UNCERTAIN/WAIVER | Subtle waiver risk |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**Accuracy Results:**\n",
    "- **Evaluator-Optimizer: 3/3** - Only pattern to catch all cases including waiver\n",
    "- Chaining: 2/3 - Missed waiver edge case\n",
    "- Routing: 2/3 - Fast but missed waiver\n",
    "- Orchestrator: 1/3 - Struggled with clear-cut cases\n",
    "- Parallelization: 1/3 - Too conservative, defaulted to UNCERTAIN\n",
    "\n",
    "**The Critical Test (DOC_C - Waiver Risk):**\n",
    "\n",
    "Only Evaluator-Optimizer correctly identified that forwarding legal advice to the opposing party created a waiver risk. All other patterns confidently (and wrongly) classified it as PRIVILEGED.\n",
    "\n",
    "This demonstrates why self-critique matters for privilege review.\n",
    "\n",
    "### Production Recommendations\n",
    "\n",
    "| Use Case | Pattern | Reason |\n",
    "|----------|---------|--------|\n",
    "| **High-volume screening** | Routing | Fastest (1.26s), cheapest (2 calls), accurate on clear cases |\n",
    "| **Final review** | Evaluator | Catches edge cases, self-corrects errors |\n",
    "| **Flagging uncertainty** | Parallelization | Model disagreement triggers human review |\n",
    "\n",
    "### Recommended Hybrid Workflow\n",
    "```\n",
    "Incoming Documents\n",
    "        ↓\n",
    "   [ROUTING] ← Fast first-pass\n",
    "        ↓\n",
    "   ┌────┴────┐\n",
    "   ↓         ↓\n",
    "CLEAR     UNCERTAIN\n",
    "   ↓         ↓\n",
    " Done    [EVALUATOR] ← Self-critique\n",
    "             ↓\n",
    "        ┌────┴────┐\n",
    "        ↓         ↓\n",
    "    RESOLVED   STILL UNCERTAIN\n",
    "        ↓         ↓\n",
    "      Done    HUMAN REVIEW\n",
    "```\n",
    "\n",
    "### Lessons Learned\n",
    "\n",
    "1. **No single pattern is best for everything** - match pattern to use case\n",
    "2. **Edge cases need self-critique** - simple patterns miss subtle issues\n",
    "3. **Speed vs accuracy trade-off** - Routing is 4x faster but misses nuance\n",
    "4. **Waiver is hard to catch** - forwarding to third parties needs explicit checking\n",
    "5. **Hybrid approaches win** - combine patterns for best results\n",
    "\n",
    "### Complete Notebook Series\n",
    "\n",
    "| Notebook | Pattern | Key Strength |\n",
    "|----------|---------|--------------|\n",
    "| 01 | Prompt Chaining | Auditable fixed steps |\n",
    "| 02 | Routing | Specialist classifiers by type |\n",
    "| 03 | Parallelization | Multi-model consensus |\n",
    "| 04 | Orchestrator-Worker | Dynamic task breakdown |\n",
    "| 05 | Evaluator-Optimizer | Self-critique catches errors |\n",
    "| 06 | Comparison | Systematic evaluation |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Expand test set with more edge cases\n",
    "2. Fine-tune prompts based on error patterns\n",
    "3. Implement hybrid workflow in production\n",
    "4. Add human feedback loop for continuous improvement\n",
    "5. Consider adding Australian case law citations to prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79833bf7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
