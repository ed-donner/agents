{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4o-mini, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded: sk-proj-...\n",
      "ü§ñ Step 1: Finding business area...\n",
      "‚úÖ Business area identified: Healthcare diagnostics support systems - These sys...\n",
      "ü§ñ Step 2: Identifying pain-points...\n",
      "‚úÖ Pain-points identified\n",
      "ü§ñ Step 3: Proposing solution...\n",
      "‚úÖ Solution proposed\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üéØ Business Area"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Healthcare diagnostics support systems - These systems can leverage Agentic AI to analyze medical data and assist healthcare professionals in providing faster, more accurate diagnoses, ultimately improving patient outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ‚ö†Ô∏è Pain-Point"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Critical Pain-point in Healthcare Diagnostics Support Systems\n",
       "\n",
       "**1. Data Overload and Integration Challenges:**\n",
       "   - **Persistence:** Healthcare professionals are inundated with vast amounts of patient data from various sources (labs, imaging, EHRs), making it difficult to integrate and analyze effectively. This complexity often leads to information overload.\n",
       "   - **Workarounds:** Many healthcare providers rely on manual reviews or specific software tools that may not interact well with other systems, leading to fragmented insights.\n",
       "\n",
       "**2. Delayed Diagnoses:**\n",
       "   - **Persistence:** The process of cross-referencing and analyzing diagnostic data can be time-consuming, leading to delays in treatment initiation. High workloads and limited staffing exacerbate this issue.\n",
       "   - **Workarounds:** Clinicians often prioritize patient cases based on immediate need, which can lead to an inefficient triage process without automated prioritization based on data analysis.\n",
       "\n",
       "**3. Variability in Diagnostic Accuracy:**\n",
       "   - **Persistence:** Diagnostics can often be subject to human error, interpretation biases, and variability in clinical judgment. This variability can stem from differences in training and experience levels among healthcare professionals.\n",
       "   - **Workarounds:** Teams may implement peer reviews or second opinions for critical cases, which requires additional time and resources, but still does not guarantee consistent accuracy or speed.\n",
       "\n",
       "**4. Limited Predictive Analytics:**\n",
       "   - **Persistence:** Existing diagnostic support systems often focus on past data rather than predictive modeling, hindering proactive healthcare measures. This lack of advanced analytics can delay effective interventions.\n",
       "   - **Workarounds:** Healthcare systems may implement basic risk stratification tools, but these are often simplistic and do not leverage machine learning capabilities, thus falling short of optimizing patient outcomes.\n",
       "\n",
       "**5. High Costs of Diagnostic Errors:**\n",
       "   - **Persistence:** Misdiagnosis or delayed diagnoses lead to significant costs, both financially and in terms of patient care, but the high stakes can result in cautiousness or hesitation from practitioners.\n",
       "   - **Workarounds:** Some hospitals invest in specialized training programs to reduce errors, though the scalability of such initiatives remains limited, and they do not address systemic inefficiencies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ü§ñ Agentic AI Solution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Proposed Agentic AI Solution for Healthcare Diagnostics Support Systems\n",
       "\n",
       "#### Core Agent Role and Objective:\n",
       "**Role:** The Agentic AI will act as a real-time diagnostic support assistant that aggregates, analyzes, and synthesizes patient data from multiple sources, providing actionable insights to healthcare professionals.  \n",
       "**Objective:** Improve diagnosis speed and accuracy by delivering critical insights from integrated patient data, facilitating timely interventions while minimizing clinician workload.\n",
       "\n",
       "#### Key Tools/Actions:\n",
       "1. **Data Integration API:**\n",
       "   - Develop an API to seamlessly connect with Electronic Health Records (EHRs), lab systems, imaging tools, and wearables to aggregate patient data in real time.\n",
       "\n",
       "2. **Natural Language Processing (NLP):**\n",
       "   - Implement NLP algorithms to analyze clinical notes and unstructured data, enhancing the comprehensive understanding of patient history and symptoms.\n",
       "\n",
       "3. **Machine Learning Models:**\n",
       "   - Utilize predictive analytics via ML models trained on historical data to identify potential diagnoses and treatment plans based on patterns of similar cases.\n",
       "\n",
       "4. **Dashboard Interface:**\n",
       "   - Create a user-friendly dashboard for clinicians that summarizes critical insights, automates risk stratification, and highlights abnormal test results for efficient decision-making.\n",
       "\n",
       "5. **Automated Triage System:**\n",
       "   - Implement an automated triage system that prioritizes cases based on severity and risk, using data-driven algorithms to inform clinicians of urgent cases before clinical rounds.\n",
       "\n",
       "#### Required Data Sources and Guardrails:\n",
       "- **Data Sources:**\n",
       "  - EHRs (Electronic Health Records)\n",
       "  - Laboratory Information Systems (LIS)\n",
       "  - Imaging Systems (PACS)\n",
       "  - Natural language clinician notes\n",
       "  - Patient management systems\n",
       "  - Public health databases for comparative analysis\n",
       "\n",
       "- **Guardrails:**\n",
       "  - Ensure compliance with HIPAA and other data protection regulations.\n",
       "  - Implement robust data encryption and access control mechanisms to protect patient information.\n",
       "  - Establish model performance validation frameworks to periodically assess and refine AI accuracy.\n",
       "\n",
       "#### KPIs for Success:\n",
       "1. **Reduction in Time-to-Diagnosis:**\n",
       "   - Measure the average time from patient presentation to diagnosis pre- and post-implementation of the AI system.\n",
       "\n",
       "2. **Diagnostic Accuracy Improvement:**\n",
       "   - Track the rate of misdiagnosis and compare it to historical data to assess the AI system's impact.\n",
       "\n",
       "3. **User Adoption Rate:**\n",
       "   - Monitor the frequency of use of the AI dashboard and support tool by healthcare professionals.\n",
       "\n",
       "4. **Reduction in Workflow Interruptions:**\n",
       "   - Assess improvements in clinical workflow and staff workload, measured through staff surveys and clinical notes.\n",
       "\n",
       "5. **Return on Investment (ROI):**\n",
       "   - Calculate financial savings from reduced diagnostic errors and enhanced patient outcomes against the cost of implementing the AI solution.\n",
       "\n",
       "#### 2-Week MVP Scope:\n",
       "**Week 1:**\n",
       "- **User Research & Requirements Gathering:**\n",
       "  - Conduct interviews with healthcare professionals to understand their key pain points and requirements for the diagnostics support system.\n",
       "  \n",
       "- **System Architecture Design:**\n",
       "  - Develop architectural frameworks for data integration, visualization, and ML model structure.\n",
       "\n",
       "**Week 2:**\n",
       "- **Prototype Development:**\n",
       "  - Build prototypes for the data integration API and initial versions of the dashboard interface.\n",
       "  \n",
       "- **Basic Model Development:**\n",
       "  - Begin developing preliminary ML models using sample historical patient data to demonstrate predictive capabilities.\n",
       "\n",
       "- **Stakeholder Feedback:** \n",
       "  - Present initial findings and prototypes to a small group of clinicians for feedback and further refinement.\n",
       "\n",
       "By focusing on these areas in the MVP, we can deliver a compelling foundational layer for the Agentic AI solution that addresses critical pain points while ensuring scalability and adaptability for future enhancements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agentic AI opportunity exploration: 3-step LLM chain\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "\n",
    "# Ensure environment is loaded and openai client exists\n",
    "try:\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "    load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    openai  # type: ignore # noqa\n",
    "except NameError:\n",
    "    from openai import OpenAI\n",
    "    openai = OpenAI()\n",
    "\n",
    "# Check API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ùå OPENAI_API_KEY not found! Please check your .env file\")\n",
    "else:\n",
    "    print(f\"‚úÖ API Key loaded: {api_key[:8]}...\")\n",
    "\n",
    "try:\n",
    "    # 1) Pick a business area worth exploring\n",
    "    print(\"ü§ñ Step 1: Finding business area...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Pick one specific business area/industry that looks promising for an Agentic AI opportunity. \"\n",
    "            \"Be concrete (e.g., 'insurance claims processing' vs 'insurance'). \"\n",
    "            \"Return only the area name and one-sentence rationale.\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp1 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # More reliable model name\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    business_area = resp1.choices[0].message.content.strip()\n",
    "    print(f\"‚úÖ Business area identified: {business_area[:50]}...\")\n",
    "\n",
    "    # 2) Present a pain-point in that industry\n",
    "    print(\"ü§ñ Step 2: Identifying pain-points...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"In the area: {business_area}\\n\"\n",
    "            \"Identify the most critical pain-point that is challenging, costly, or slow today. \"\n",
    "            \"Explain briefly why it persists and what current workarounds look like. Return 3-5 bullets.\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp2 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    pain_points = resp2.choices[0].message.content.strip()\n",
    "    print(\"‚úÖ Pain-points identified\")\n",
    "\n",
    "    # 3) Propose an Agentic AI solution\n",
    "    print(\"ü§ñ Step 3: Proposing solution...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"Given the area: {business_area}\\n\"\n",
    "            f\"And these pain-points:\\n{pain_points}\\n\\n\"\n",
    "            \"Propose a concise Agentic AI solution. Include: \\n\"\n",
    "            \"- Core agent role and objective\\n\"\n",
    "            \"- Key tools/actions (APIs, automations)\\n\"\n",
    "            \"- Required data sources and guardrails\\n\"\n",
    "            \"- KPIs for success\\n\"\n",
    "            \"- A 2-week MVP scope\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp3 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    solution = resp3.choices[0].message.content.strip()\n",
    "    print(\"‚úÖ Solution proposed\")\n",
    "\n",
    "    # Render nicely\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    display(Markdown(\"## üéØ Business Area\"))\n",
    "    display(Markdown(business_area))\n",
    "\n",
    "    display(Markdown(\"\\n## ‚ö†Ô∏è Pain-Point\"))\n",
    "    display(Markdown(pain_points))\n",
    "\n",
    "    display(Markdown(\"\\n## ü§ñ Agentic AI Solution\"))\n",
    "    display(Markdown(solution))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"1. Make sure your .env file has OPENAI_API_KEY\")\n",
    "    print(\"2. Run the earlier cells to set up the environment\")\n",
    "    print(\"3. Check your internet connection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded: sk-proj-...\n",
      "ü§ñ Step 1: Finding business area...\n",
      "‚úÖ Business area identified: Personalized healthcare management. The rise in we...\n",
      "ü§ñ Step 2: Identifying pain-points...\n",
      "‚úÖ Pain-points identified\n",
      "ü§ñ Step 3: Proposing solution...\n",
      "‚úÖ Solution proposed\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üéØ Business Area"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Personalized healthcare management. The rise in wearable health technology and patient data analytics creates an opportunity for Agentic AI to provide tailored health recommendations and interventions, enhancing patient outcomes and engagement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ‚ö†Ô∏è Pain-Point"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Critical Pain Point: Integration of Wearable Health Data into Clinical Practice \n",
       "\n",
       "1. **Data Overload and Fragmentation**:  \n",
       "   - The sheer volume of data generated by various wearable health devices leads to information overload for healthcare providers. Each device presents its own data format, complicating the integration into a unified electronic health record (EHR) system, leading to fragmented insights. \n",
       "   - **Why It Persists**: The lack of standardized data formats and interoperability among different devices and systems continues to challenge seamless integration, resulting in reluctance from providers to act on data from wearables.\n",
       "\n",
       "2. **Limited Patient Engagement and Compliance**:  \n",
       "   - Patients often experience difficulty understanding how to utilize the insights from their wearables, leading to low engagement and compliance with health recommendations. Without guidance, patients may not interpret data accurately or take necessary actions to improve their health.\n",
       "   - **Why It Persists**: Many wearable devices are designed primarily for consumer use rather than clinical integration, leading to a gap in how information is conveyed and understood in a clinical context.\n",
       "\n",
       "3. **Inefficient Data Analytics for Personalized Interventions**:  \n",
       "   - Current clinical workflows do not efficiently incorporate real-time data from wearables into patient management strategies, making it challenging for healthcare providers to offer personalized health recommendations based on that data.\n",
       "   - **Why It Persists**: Healthcare providers often rely on outdated or siloed analytics tools that do not support real-time decision-making, along with resource constraints that limit the time available for analyzing patient data.\n",
       "\n",
       "4. **Reimbursement and Regulatory Barriers**:  \n",
       "   - There are ongoing challenges related to reimbursement models for the use of wearable technology in clinical practice, which affects healthcare providers' willingness to incorporate these tools into patient care plans.\n",
       "   - **Why It Persists**: Insurance coverage policies and regulatory frameworks are still catching up with technological advancements in wearable health technology, leading to uncertainties about their value in clinical settings.\n",
       "\n",
       "### Current Workarounds:\n",
       "- **Manual data entry and tracking**: Healthcare providers may resort to manually reviewing and entering data from wearables into EHRs, which is time-consuming and prone to error.\n",
       "- **Patient education initiatives**: Some practices offer workshops or written materials to help patients understand and engage with their wearable devices, though effectiveness can vary widely.\n",
       "- **Pilot programs**: Some healthcare systems are trialing integration of wearable data into their workflows on a limited basis to gather evidence on effectiveness and improve user engagement before broader implementation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## ü§ñ Agentic AI Solution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Agentic AI Solution Proposal: Wearable Health Data Integration & Patient Engagement\n",
       "\n",
       "#### Core Agent Role and Objective:\n",
       "**Role**: The Agentic AI will act as an Intelligent Health Advisor that seamlessly integrates wearable health data into clinical practice while enhancing patient engagement and compliance. \n",
       "\n",
       "**Objective**: To provide healthcare providers with actionable insights derived from real-time wearable data and to equip patients with personalized health recommendations that are easy to understand and implement.\n",
       "\n",
       "#### Key Tools/Actions:\n",
       "1. **APIs for Data Integration**:\n",
       "   - Develop APIs to standardize and aggregate data from various wearable devices into a common format, facilitating integration into Electronic Health Records (EHR).\n",
       "   - Use HL7 FHIR (Fast Healthcare Interoperability Resources) standards for establishing interoperability between wearables and clinical systems.\n",
       "\n",
       "2. **Automation of Data Insights**:\n",
       "   - Automate the continuous analysis of wearable data using machine learning algorithms to identify trends and flag anomalies in real-time.\n",
       "   - Create alert systems for healthcare providers that trigger notifications based on critical thresholds (e.g., abnormal heart rate, activity levels).\n",
       "\n",
       "3. **Patient Engagement Interface**:\n",
       "   - Design a user-friendly patient app that simplifies wearable data visualization and provides personalized, understandable health recommendations based on analyzed data.\n",
       "   - Include educational content and gamification elements to encourage higher patient engagement and compliance.\n",
       "\n",
       "4. **Feedback Loop Mechanism**:\n",
       "   - Implement a feedback mechanism within the app for both patients and providers to evaluate the effectiveness of recommendations, allowing for continuous improvement and optimization of AI algorithms.\n",
       "\n",
       "#### Required Data Sources and Guardrails:\n",
       "- **Data Sources**:\n",
       "   - Real-time data feeds from popular wearable devices (e.g., Fitbit, Apple Watch, Garmin) via established APIs.\n",
       "   - Patient health records and clinical data from EHR systems.\n",
       "\n",
       "- **Guardrails**:\n",
       "   - Ensure compliance with HIPAA and other healthcare regulations to protect patient information.\n",
       "   - Implement data encryption and secure access protocols to safeguard sensitive health data.\n",
       "   - Establish clear data use policies, allowing full transparency to patients regarding how their data is processed and utilized.\n",
       "\n",
       "#### KPIs for Success:\n",
       "1. **Integration Rate**: Percentage of wearable data successfully integrated into EHRs within participating healthcare systems.\n",
       "2. **Patient Engagement Metrics**: Monitoring active users of the patient app and their frequency of interaction with provided health recommendations.\n",
       "3. **Compliance Improvement**: Increase in adherence rates to health recommendations over time, measured through follow-up health outcomes.\n",
       "4. **Provider Satisfaction Score**: Collect feedback from providers on usability and the value of insights generated by the Agentic AI system.\n",
       "\n",
       "#### 2-Week MVP Scope:\n",
       "**Week 1:**\n",
       "- Kick-off meeting with stakeholders to define success metrics.\n",
       "- Research and identify top wearable devices for integration based on market share and clinical relevance.\n",
       "- Develop foundational APIs for basic data extraction and ingestion from one selected wearable device to an EHR prototype.\n",
       "- Begin building the user interface for the patient app focusing on initial data visualization elements (e.g., step counts, heart rate).\n",
       "\n",
       "**Week 2:**\n",
       "- Finalize integration of the selected wearable device data into a test EHR system, allowing for basic data viewing by healthcare providers.\n",
       "- Incorporate basic functionality into the patient app for customized health insights (e.g., ‚ÄúYou walked x steps today. Aim for y for better health!‚Äù).\n",
       "- Conduct user testing sessions with patients and providers for feedback on data presentation and engagement strategies.\n",
       "- Iterate on the user interface and backend analytics based on initial rounds of feedback.\n",
       "\n",
       "This MVP would lay the groundwork for future enhancements, including wider device support, deeper analytics for personalized recommendations, and more comprehensive patient education and support functionalities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agentic AI opportunity exploration: 3-step LLM chain\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "\n",
    "# Ensure environment is loaded and openai client exists\n",
    "try:\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "    load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    openai  # type: ignore # noqa\n",
    "except NameError:\n",
    "    from openai import OpenAI\n",
    "    openai = OpenAI()\n",
    "\n",
    "# Check API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ùå OPENAI_API_KEY not found! Please check your .env file\")\n",
    "else:\n",
    "    print(f\"‚úÖ API Key loaded: {api_key[:8]}...\")\n",
    "\n",
    "try:\n",
    "    # 1) Pick a business area worth exploring\n",
    "    print(\"ü§ñ Step 1: Finding business area...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Pick one specific business area/industry that looks promising for an Agentic AI opportunity. \"\n",
    "            \"Be concrete (e.g., 'insurance claims processing' vs 'insurance'). \"\n",
    "            \"Return only the area name and one-sentence rationale.\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp1 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # More reliable model name\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    business_area = resp1.choices[0].message.content.strip()\n",
    "    print(f\"‚úÖ Business area identified: {business_area[:50]}...\")\n",
    "\n",
    "    # 2) Present a pain-point in that industry\n",
    "    print(\"ü§ñ Step 2: Identifying pain-points...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"In the area: {business_area}\\n\"\n",
    "            \"Identify the most critical pain-point that is challenging, costly, or slow today. \"\n",
    "            \"Explain briefly why it persists and what current workarounds look like. Return 3-5 bullets.\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp2 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    pain_points = resp2.choices[0].message.content.strip()\n",
    "    print(\"‚úÖ Pain-points identified\")\n",
    "\n",
    "    # 3) Propose an Agentic AI solution\n",
    "    print(\"ü§ñ Step 3: Proposing solution...\")\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            f\"Given the area: {business_area}\\n\"\n",
    "            f\"And these pain-points:\\n{pain_points}\\n\\n\"\n",
    "            \"Propose a concise Agentic AI solution. Include: \\n\"\n",
    "            \"- Core agent role and objective\\n\"\n",
    "            \"- Key tools/actions (APIs, automations)\\n\"\n",
    "            \"- Required data sources and guardrails\\n\"\n",
    "            \"- KPIs for success\\n\"\n",
    "            \"- A 2-week MVP scope\"\n",
    "        ),\n",
    "    }]\n",
    "\n",
    "    resp3 = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    solution = resp3.choices[0].message.content.strip()\n",
    "    print(\"‚úÖ Solution proposed\")\n",
    "\n",
    "    # Render nicely\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    display(Markdown(\"## üéØ Business Area\"))\n",
    "    display(Markdown(business_area))\n",
    "\n",
    "    display(Markdown(\"\\n## ‚ö†Ô∏è Pain-Point\"))\n",
    "    display(Markdown(pain_points))\n",
    "\n",
    "    display(Markdown(\"\\n## ü§ñ Agentic AI Solution\"))\n",
    "    display(Markdown(solution))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"1. Make sure your .env file has OPENAI_API_KEY\")\n",
    "    print(\"2. Run the earlier cells to set up the environment\")\n",
    "    print(\"3. Check your internet connection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Business Area\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Commercial real estate lease negotiation automation‚Äîbecause it combines complex, high-value contracts with repetitive negotiation tasks ideal for autonomous AI agents."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Pain-Point\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Most Critical Pain-Point:**  \n",
       "*The prolonged and inefficient back-and-forth negotiation process caused by unstructured communication and customized lease terms.*\n",
       "\n",
       "**Why it Persists:**  \n",
       "- Commercial leases are highly complex, involving numerous custom clauses that vary widely by property, tenant needs, and jurisdiction, making standardization difficult.  \n",
       "- Negotiations rely heavily on manual review and revisions by legal teams and brokers, who interpret and propose changes through tracked changes and email threads, leading to delays.  \n",
       "- Lack of integration between parties‚Äô contract management systems results in fragmented workflows and information loss.\n",
       "\n",
       "**Current Workarounds:**  \n",
       "- Manual drafting and redlining in Word or PDF documents exchanged via email or specialized legal platforms like DocuSign or Adobe Sign.  \n",
       "- Use of clause libraries or standardized templates to speed up initial drafts, but with extensive manual tailoring afterward.  \n",
       "- Employing specialized commercial real estate brokers and legal counsel to manage negotiations, which increases cost and turnaround time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Agentic AI Solution\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Agentic AI Solution Proposal: Commercial Lease Negotiation Agent**\n",
       "\n",
       "---\n",
       "\n",
       "### Core Agent Role and Objective\n",
       "An autonomous AI agent that acts as a **digital lease negotiation facilitator**, capable of parsing lease proposals, suggesting clause modifications aligned with best practices and legal constraints, and autonomously managing negotiation workflows between landlord and tenant representatives to drastically reduce turnaround time.\n",
       "\n",
       "---\n",
       "\n",
       "### Key Tools / Actions\n",
       "- **Document Parsing & Clause Extraction APIs:** Use NLP models specialized in legal language to segment and understand lease clauses from Word/PDF documents (e.g., AWS Textract, Azure Form Recognizer, or custom fine-tuned transformers).\n",
       "- **Clause Comparison and Suggestion Engine:** Apply rule-based and ML models trained on commercial lease variations to identify differences and propose optimized or standardized clause alternatives.\n",
       "- **Automated Version Control & Change Tracking:** Integrate with versioning platforms and provide inline suggestions with accept/reject functionality remotely accessible by all parties.\n",
       "- **Workflow Automation & Integration:**  \n",
       "  - Connect with contract management platforms (e.g., DocuSign, Adobe Sign APIs) for seamless document transfers and signature flows.  \n",
       "  - Use email/chat automation (SMTP/IM APIs or Slack/Microsoft Teams integration) to notify users, collect feedback, and coordinate approvals.\n",
       "- **Compliance & Jurisdiction Validation:** Integrate legal databases and jurisdiction rule engines to flag problematic clauses or non-compliance before proposals are sent.\n",
       "\n",
       "---\n",
       "\n",
       "### Required Data Sources and Guardrails\n",
       "- **Data Sources:**  \n",
       "  - Historical lease agreements and negotiation logs (anonymized) for training and benchmarking.  \n",
       "  - Jurisdiction-specific legal regulations and guidelines for commercial leasing.  \n",
       "  - Clause libraries standardized by lease type and region.  \n",
       "  - Party-specific preferences and redline history.\n",
       "\n",
       "- **Guardrails:**  \n",
       "  - Human-in-the-loop checkpoints for critical clause modifications and final approvals to avoid legal risks.  \n",
       "  - Secure multi-party data access controls and encryption to maintain confidentiality.  \n",
       "  - Compliance validation modules to prevent illegal or non-standard proposing.  \n",
       "  - Audit trails and change logs automatically maintained to ensure transparency.\n",
       "\n",
       "---\n",
       "\n",
       "### KPIs for Success\n",
       "- **Negotiation Cycle Time Reduction:** % decrease in average time to reach agreement (targeting >50% faster).  \n",
       "- **Clause Standardization Rate:** Increase in share of clauses resolved without manual intervention.  \n",
       "- **User Satisfaction:** Broker/legal counsel rating of agent suggestions and overall workflow.  \n",
       "- **Error and Exception Rate:** Frequency of AI-generated proposals needing significant human corrections or flagged for compliance.  \n",
       "- **Adoption Rate:** Percentage of negotiations initiated/completed using the agent.\n",
       "\n",
       "---\n",
       "\n",
       "### 2-Week MVP Scope\n",
       "1. **Build core document ingestion and parsing pipeline:** Ingest Word/PDF lease drafts, extract and segment key clauses with high accuracy.  \n",
       "2. **Implement clause comparison UI:** Highlight differences between landlord and tenant proposals and enable inline suggestions for a small set of high-impact clauses (e.g., rent escalation, maintenance responsibilities).  \n",
       "3. **Basic automation of workflow notifications:** Send update emails to involved parties when the agent completes clause analysis or generates suggestions.  \n",
       "4. **Human review and approval interface:** Allow legal users to accept/reject agent recommendations.  \n",
       "5. **Set up minimal compliance guardrails:** Simple checklists or flagging for obvious jurisdictional mismatches or missing mandatory clauses.  \n",
       "\n",
       "---\n",
       "\n",
       "This MVP will validate feasibility of autonomous parsing and suggestion generation and establish a collaborative human-AI negotiation cycle that targets the key pain-point of structured communication with reduced manual overhead and delays."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Agentic AI opportunity exploration: 3-step LLM chain\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Ensure `openai` client exists even if earlier cells weren't run\n",
    "try:\n",
    "    openai  # type: ignore # noqa\n",
    "except NameError:  # pragma: no cover\n",
    "    from openai import OpenAI\n",
    "    openai = OpenAI()\n",
    "\n",
    "# 1) Pick a business area worth exploring\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": (\n",
    "        \"Pick one specific business area/industry that looks promising for an Agentic AI opportunity. \"\n",
    "        \"Be concrete (e.g., 'insurance claims processing' vs 'insurance'). \"\n",
    "        \"Return only the area name and one-sentence rationale.\"\n",
    "    ),\n",
    "}]\n",
    "\n",
    "resp1 = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "business_area = resp1.choices[0].message.content.strip()\n",
    "\n",
    "# 2) Present a pain-point in that industry\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": (\n",
    "        f\"In the area: {business_area}\\n\"\n",
    "        \"Identify the most critical pain-point that is challenging, costly, or slow today. \"\n",
    "        \"Explain briefly why it persists and what current workarounds look like. Return 3-5 bullets.\"\n",
    "    ),\n",
    "}]\n",
    "\n",
    "resp2 = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "pain_points = resp2.choices[0].message.content.strip()\n",
    "\n",
    "# 3) Propose an Agentic AI solution\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": (\n",
    "        f\"Given the area: {business_area}\\n\"\n",
    "        f\"And these pain-points:\\n{pain_points}\\n\\n\"\n",
    "        \"Propose a concise Agentic AI solution. Include: \\n\"\n",
    "        \"- Core agent role and objective\\n\"\n",
    "        \"- Key tools/actions (APIs, automations)\\n\"\n",
    "        \"- Required data sources and guardrails\\n\"\n",
    "        \"- KPIs for success\\n\"\n",
    "        \"- A 2-week MVP scope\"\n",
    "    ),\n",
    "}]\n",
    "\n",
    "resp3 = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "solution = resp3.choices[0].message.content.strip()\n",
    "\n",
    "# Render nicely\n",
    "display(Markdown(\"## Business Area\\n\"))\n",
    "display(Markdown(business_area))\n",
    "\n",
    "display(Markdown(\"\\n## Pain-Point\\n\"))\n",
    "display(Markdown(pain_points))\n",
    "\n",
    "display(Markdown(\"\\n## Agentic AI Solution\\n\"))\n",
    "display(Markdown(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If seven people meet and each shakes hands exactly once with every other person, how many handshakes occur in total?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the total number of handshakes when seven people each shake hands exactly once with every other person, we need to determine the number of unique pairs that can be made from 7 people.\n",
      "\n",
      "The formula for the number of ways to choose 2 people out of 7 (which represents a handshake between those two) is the combination:\n",
      "\n",
      "\\[\n",
      "\\binom{7}{2} = \\frac{7!}{2!(7-2)!} = \\frac{7 \\times 6}{2 \\times 1} = 21\n",
      "\\]\n",
      "\n",
      "**Therefore, the total number of handshakes is 21.**\n",
      "\n",
      "\\[\n",
      "\\boxed{21}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To find the total number of handshakes when seven people each shake hands exactly once with every other person, we need to determine the number of unique pairs that can be made from 7 people.\n",
       "\n",
       "The formula for the number of ways to choose 2 people out of 7 (which represents a handshake between those two) is the combination:\n",
       "\n",
       "\\[\n",
       "\\binom{7}{2} = \\frac{7!}{2!(7-2)!} = \\frac{7 \\times 6}{2 \\times 1} = 21\n",
       "\\]\n",
       "\n",
       "**Therefore, the total number of handshakes is 21.**\n",
       "\n",
       "\\[\n",
       "\\boxed{21}\n",
       "\\]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2901051077.py, line 7)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[152]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mresponse =\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Something here\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response =\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
