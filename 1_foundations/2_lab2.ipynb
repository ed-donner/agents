{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins sk-\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you could create a new ethical framework for the development and application of artificial intelligence, what key principles would you include to balance innovation with societal well-being, and how would you address potential conflicts between these principles?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a new ethical framework for the development and application of artificial intelligence (AI) requires a balanced approach that fosters innovation while ensuring societal well-being. Here are key principles to consider, along with strategies to address potential conflicts:\n",
       "\n",
       "### Key Principles:\n",
       "\n",
       "1. **Human-Centric Design**: \n",
       "   - AI systems should prioritize human needs, values, and rights. This involves co-creating technologies with diverse stakeholders, including users, communities, ethicists, and domain experts.\n",
       "\n",
       "2. **Transparency and Explainability**: \n",
       "   - AI systems must be transparent in their processes and decision-making mechanisms. Users and affected parties should understand how AI operates, the data it uses, and its outputs.\n",
       "\n",
       "3. **Accountability and Responsibility**: \n",
       "   - Clear lines of accountability must be established for AI developers and organizations. This includes mechanisms for redress when AI systems cause harm or discrimination.\n",
       "\n",
       "4. **Privacy and Data Protection**: \n",
       "   - The collection, use, and sharing of data should respect individual privacy rights and comply with relevant legal frameworks. Anonymization and user consent should be prioritized.\n",
       "\n",
       "5. **Equity and Inclusion**: \n",
       "   - AI development should actively aim to reduce inequalities and avoid reinforcing biases. This includes ensuring that underrepresented groups have a voice in the design and implementation phases.\n",
       "\n",
       "6. **Sustainability**: \n",
       "   - AI systems should be designed with environmental considerations in mind, striving to minimize energy consumption and support sustainable practices.\n",
       "\n",
       "7. **Safety and Security**: \n",
       "   - AI systems must be developed with robust safety measures in place to prevent unintended consequences, including malicious use. The systems should be resilient against attacks and able to operate safely in diverse conditions.\n",
       "\n",
       "8. **Promotion of Public Good**: \n",
       "   - AI should contribute positively to societal goals, such as enhancing healthcare, education, and public safety. Development should focus on applications that improve quality of life and social welfare.\n",
       "\n",
       "9. **Adaptive Governance**: \n",
       "   - The framework should include flexible governance structures that can evolve with the rapidly changing landscape of AI technology. Stakeholders should be able to adapt policies and regulations based on new information and societal impact.\n",
       "\n",
       "### Addressing Conflicts Between Principles:\n",
       "\n",
       "Conflicts may arise between innovation and these principles. Here are strategies to navigate such tensions:\n",
       "\n",
       "- **Stakeholder Engagement**: Regularly involve diverse stakeholders in the decision-making processes to identify potential conflicts early and collaboratively find solutions that balance competing interests.\n",
       "\n",
       "- **Ethical Review Boards**: Establish independent ethical review boards or advisory councils to assess and provide guidance on AI projects, weighing innovation against societal considerations.\n",
       "\n",
       "- **Iterative Development and Feedback Loops**: Use iterative design principles that allow for continuous testing, evaluation, and refinement of AI systems. Employ mechanisms for public feedback to ensure alignment with societal values.\n",
       "\n",
       "- **Regulatory Sandboxes**: Implement regulatory sandboxes that allow for controlled experimentation with new AI technologies. This encourages innovation while maintaining oversight to address ethical concerns.\n",
       "\n",
       "- **Conflict Resolution Frameworks**: Create specific frameworks for resolving conflicts between principles, such as prioritizing human rights in cases where innovation may infringe on individual freedoms.\n",
       "\n",
       "- **Quantitative and Qualitative Impact Assessments**: Utilize both quantitative metrics (like efficiency gains) and qualitative measures (like societal impact narratives) to evaluate the trade-offs between innovation and ethical principles.\n",
       "\n",
       "By embedding these principles and approaches into the developmental lifecycle of AI, a new ethical framework can promote responsible innovation that aligns with the well-being of society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# An Ethical Framework for AI Development\n",
       "\n",
       "If I were to create a new ethical framework for AI, I would center these key principles:\n",
       "\n",
       "## Core Principles\n",
       "\n",
       "**Beneficence Beyond Metrics:** AI should demonstrably improve human flourishing, not just optimize measurable outcomes.\n",
       "\n",
       "**Distributed Governance:** Decision-making authority should be shared across diverse stakeholders, preventing power concentration.\n",
       "\n",
       "**Epistemic Humility:** Systems should acknowledge uncertainty and the limits of their knowledge.\n",
       "\n",
       "**Reversibility:** Meaningful ability to undo harmful implementations and effects.\n",
       "\n",
       "**Contextual Alignment:** Ethical considerations must be culturally responsive while maintaining core human rights.\n",
       "\n",
       "## Addressing Conflicts\n",
       "\n",
       "When principles conflict, I would implement:\n",
       "\n",
       "1. A deliberative process prioritizing voices of the potentially most affected\n",
       "2. Tiered implementation allowing controlled testing before widespread deployment\n",
       "3. Independent oversight with substantive representation from marginalized communities\n",
       "4. Mandatory impact assessments at regular intervals\n",
       "\n",
       "The most challenging tension may be between innovation and precaution. I would address this through mandatory \"ethical sandboxes\" where technologies can be developed with appropriate safeguards while still enabling progress.\n",
       "\n",
       "What aspects of this framework do you find most compelling or problematic?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, if I could design a new ethical framework for AI development and application, I would focus on creating a system that is both innovative and deeply mindful of its societal impact. This framework would be built on several core principles and have mechanisms for resolving the inevitable conflicts between them.\n",
       "\n",
       "Here's a breakdown of the key principles and conflict resolution strategies:\n",
       "\n",
       "**I. Core Principles:**\n",
       "\n",
       "1.  **Human-Centeredness & Dignity:**\n",
       "\n",
       "    *   **Principle:** AI should be designed, developed, and deployed to serve humanity and enhance human well-being, autonomy, and dignity. It should prioritize human values and rights, not replace or diminish them.  AI should not be used in ways that dehumanize, exploit, or oppress individuals or groups.\n",
       "    *   **Operationalization:**  This principle translates to requiring human oversight in critical AI decision-making processes (especially in areas like justice, healthcare, and welfare), ensuring accessibility for all users (regardless of abilities), and proactively designing AI systems to protect privacy and prevent discrimination.\n",
       "\n",
       "2.  **Beneficence & Non-Maleficence (Do Good, Avoid Harm):**\n",
       "\n",
       "    *   **Principle:** AI development should actively seek to maximize benefits for society and minimize potential harms. This includes both direct harms (e.g., physical injury, biased decisions) and indirect harms (e.g., job displacement, erosion of social cohesion).\n",
       "    *   **Operationalization:** Mandate rigorous risk assessments throughout the AI lifecycle. This includes identifying potential unintended consequences, developing mitigation strategies, and continuously monitoring AI systems for emergent risks.  Promote the development of \"robust AI\" that is resilient to adversarial attacks and unexpected inputs.  Develop strategies for managing job displacement, potentially through retraining programs, universal basic income, or other social safety nets.\n",
       "\n",
       "3.  **Fairness, Justice, and Equity:**\n",
       "\n",
       "    *   **Principle:** AI systems should be developed and deployed in a manner that promotes fairness, justice, and equity for all individuals and groups, regardless of race, gender, socioeconomic status, or other protected characteristics.  Avoid perpetuating or amplifying existing biases.\n",
       "    *   **Operationalization:**  Require diverse and representative datasets for training AI models. Implement bias detection and mitigation techniques throughout the AI lifecycle. Establish clear accountability mechanisms for biased AI decisions.  Prioritize applications of AI that address societal inequalities.\n",
       "\n",
       "4.  **Transparency, Explainability, and Interpretability:**\n",
       "\n",
       "    *   **Principle:** AI systems should be as transparent and explainable as possible, allowing users and stakeholders to understand how they work, how they make decisions, and what data they use.  Interpretability should be prioritized when the consequences of AI decisions are significant.\n",
       "    *   **Operationalization:** Invest in research and development of explainable AI (XAI) techniques. Require documentation of AI system design, data sources, and algorithms. Provide clear and accessible explanations of AI decisions to affected individuals. Establish mechanisms for auditing AI systems to ensure transparency and accountability.\n",
       "\n",
       "5.  **Accountability and Responsibility:**\n",
       "\n",
       "    *   **Principle:**  Clear lines of accountability and responsibility should be established for the development, deployment, and use of AI systems. Individuals and organizations should be held responsible for the impacts of their AI systems.\n",
       "    *   **Operationalization:** Develop legal and regulatory frameworks that assign liability for AI-related harms. Establish independent AI oversight bodies to monitor and regulate AI development and deployment. Promote ethical AI training and education for all AI professionals. Establish whistleblowing protections for individuals who report unethical AI practices.\n",
       "\n",
       "6.  **Sustainability and Environmental Responsibility:**\n",
       "\n",
       "    *   **Principle:** The development and deployment of AI should be environmentally sustainable and contribute to a healthy planet.  Consider the energy consumption, resource utilization, and waste generation associated with AI systems.\n",
       "    *   **Operationalization:**  Promote the development of energy-efficient AI algorithms and hardware. Encourage the use of renewable energy sources to power AI infrastructure. Explore the use of AI to address environmental challenges, such as climate change and pollution.\n",
       "\n",
       "7.  **Participatory Governance and Public Deliberation:**\n",
       "\n",
       "    *   **Principle:**  The development and deployment of AI should be guided by broad public participation and deliberation.  Stakeholders from diverse backgrounds should have the opportunity to shape the ethical and societal implications of AI.\n",
       "    *   **Operationalization:**  Establish public forums and consultations to discuss AI policy and regulation. Support citizen science initiatives that involve the public in AI research and development. Promote media literacy and critical thinking skills to enable informed public discourse about AI.\n",
       "\n",
       "**II. Addressing Conflicts Between Principles:**\n",
       "\n",
       "The principles above are not always mutually consistent.  For instance, prioritizing innovation might sometimes conflict with ensuring fairness, or maximizing benefits might come at the expense of transparency.  Therefore, the framework needs to include mechanisms for navigating these conflicts:\n",
       "\n",
       "1.  **Prioritization Framework (Context-Specific):**  Instead of creating a rigid hierarchy, the framework should establish a process for prioritizing principles based on the specific context of the AI application. For example, in autonomous weapons systems, non-maleficence (avoiding harm) would likely take precedence over innovation speed.  This framework should be developed through public consultation and regularly reviewed.\n",
       "\n",
       "2.  **Ethical Impact Assessments (EIAs):** Mandate EIAs for all AI systems that have the potential for significant societal impact. These assessments would systematically analyze the potential ethical risks and benefits of the system, identify potential conflicts between principles, and propose mitigation strategies. The EIA process should involve diverse stakeholders and be transparent to the public.\n",
       "\n",
       "3.  **Multi-Criteria Decision Analysis (MCDA):**  Employ MCDA techniques to evaluate different AI design choices based on multiple ethical criteria. This can help to identify the trade-offs between different principles and to make more informed decisions.  This process should be transparent and documented.\n",
       "\n",
       "4.  **Ethical Review Boards (ERBs):** Establish independent ERBs to review and approve AI projects before they are deployed. These boards would be composed of experts from diverse fields (e.g., ethics, law, computer science, social science) and would have the authority to reject projects that are deemed ethically unacceptable.\n",
       "\n",
       "5.  **Adaptive Governance and Iterative Development:**  Recognize that the ethical implications of AI are constantly evolving. The framework should be designed to be adaptive and iterative, allowing for continuous learning and improvement based on real-world experience.  Regular reviews and updates should be conducted to ensure that the framework remains relevant and effective.\n",
       "\n",
       "6.  **\"Red Button\" Mechanisms:**  In certain high-stakes situations (e.g., autonomous weapons systems, AI-powered surveillance), incorporate mechanisms that allow for human intervention and override of AI decisions. This provides a safety net to prevent catastrophic outcomes.\n",
       "\n",
       "7.  **Emphasis on Education and Training:** Promote ethical AI education and training for all stakeholders, including developers, policymakers, and the general public. This will help to foster a culture of ethical AI development and use.\n",
       "\n",
       "**Key Considerations:**\n",
       "\n",
       "*   **Global Collaboration:**  AI development is a global endeavor. The ethical framework should be developed and implemented in collaboration with international organizations and stakeholders. Harmonization of ethical standards across different countries is crucial.\n",
       "*   **Dynamic Adaptation:**  The framework should be flexible and adaptable to address new challenges and opportunities as AI technology evolves. Regular reviews and updates are essential.\n",
       "*   **Enforcement Mechanisms:**  The framework needs to be backed by effective enforcement mechanisms, including legal and regulatory sanctions, to ensure compliance.\n",
       "\n",
       "By implementing this framework, we can strive to harness the immense potential of AI while mitigating its risks and ensuring that it serves humanity's best interests. The key is to foster a culture of ethical awareness, responsibility, and continuous learning throughout the AI ecosystem.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Creating a new ethical framework for AI development and application requires balancing innovation with societal well-being while addressing inevitable conflicts between principles. Below is a proposed framework with key principles and conflict-resolution strategies:\n",
       "\n",
       "### **Core Ethical Principles**  \n",
       "1. **Human-Centric Beneficence**  \n",
       "   - AI should prioritize human flourishing, ensuring that its development and deployment enhance well-being, equity, and dignity.  \n",
       "   - *Example:* AI in healthcare should focus on improving patient outcomes rather than just cost-cutting.  \n",
       "\n",
       "2. **Transparency & Explainability**  \n",
       "   - AI systems must be interpretable, with clear accountability for decisions. Users should understand how and why AI reaches conclusions.  \n",
       "   - *Example:* A loan-approval AI should provide reasons for rejections in understandable terms.  \n",
       "\n",
       "3. **Fairness & Non-Discrimination**  \n",
       "   - AI must actively mitigate biases in data and decision-making to prevent harm to marginalized groups.  \n",
       "   - *Example:* Facial recognition should be rigorously audited for racial/gender bias.  \n",
       "\n",
       "4. **Privacy & Autonomy**  \n",
       "   - AI should respect individual privacy, with strict data governance and user consent. People should retain control over their personal data.  \n",
       "   - *Example:* AI-driven surveillance should have legal safeguards against misuse.  \n",
       "\n",
       "5. **Robustness & Safety**  \n",
       "   - AI systems must be secure, reliable, and fail-safe to prevent unintended harm.  \n",
       "   - *Example:* Autonomous vehicles must have rigorous safety testing before deployment.  \n",
       "\n",
       "6. **Sustainability**  \n",
       "   - AI development should minimize environmental impact and support long-term ecological balance.  \n",
       "   - *Example:* Energy-efficient AI models should be prioritized over computationally wasteful ones.  \n",
       "\n",
       "7. **Democratic Governance & Accountability**  \n",
       "   - AI regulation should involve diverse stakeholders (governments, industry, civil society) to prevent monopolization and misuse.  \n",
       "   - *Example:* Public oversight boards for AI in policing.  \n",
       "\n",
       "### **Addressing Conflicts Between Principles**  \n",
       "1. **Innovation vs. Safety**  \n",
       "   - *Resolution:* Implement staged deployment (e.g., sandbox testing) where AI is rigorously evaluated before scaling.  \n",
       "\n",
       "2. **Privacy vs. Public Benefit**  \n",
       "   - *Resolution:* Use privacy-preserving techniques (e.g., federated learning, differential privacy) when AI requires sensitive data.  \n",
       "\n",
       "3. **Autonomy vs. Fairness**  \n",
       "   - *Resolution:* Allow opt-outs for AI decisions (e.g., human override in hiring algorithms) while ensuring fairness in defaults.  \n",
       "\n",
       "4. **Corporate Profit vs. Societal Good**  \n",
       "   - *Resolution:* Incentivize ethical AI through tax benefits for responsible deployments and penalties for harmful uses.  \n",
       "\n",
       "### **Implementation Mechanisms**  \n",
       "- **Ethical Impact Assessments (EIAs):** Mandatory audits before AI deployment.  \n",
       "- **Multi-Stakeholder Oversight:** Independent ethics boards with public representation.  \n",
       "- **Adaptive Regulation:** Policies that evolve with AI advancements.  \n",
       "\n",
       "### **Conclusion**  \n",
       "This framework seeks to foster innovation while safeguarding human rights and societal welfare. By embedding flexibility and accountability, it can adapt to emerging challenges while minimizing harm.  \n",
       "\n",
       "Would you refine any of these principles or suggest additional considerations?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "If I could create a new ethical framework for the development and application of artificial intelligence (AI), I would include the following key principles to balance innovation with societal well-being:\n",
       "\n",
       "**Principles:**\n",
       "\n",
       "1. **Responsible Innovation**: Encourage innovation while ensuring that AI development is guided by human values, social norms, and ethical considerations.\n",
       "2. **Transparency and Explainability**: Ensure that AI systems are transparent, explainable, and accountable, enabling users to understand how decisions are made and to trust the technology.\n",
       "3. **Human-Centered Design**: Develop AI systems that prioritize human well-being, dignity, and safety, and that are designed to augment human capabilities rather than replace them.\n",
       "4. **Data Protection and Privacy**: Establish robust data protection and privacy protocols to safeguard personal and sensitive information, and to prevent AI systems from perpetuating biases and discrimination.\n",
       "5. **Fairness, Equity, and Non-Discrimination**: Ensure that AI systems are fair, equitable, and free from biases, and that they do not perpetuate existing social and economic inequalities.\n",
       "6. **Accountability and Liability**: Establish clear lines of accountability and liability for AI-related decisions and actions, and provide mechanisms for redress and compensation in cases of harm or injury.\n",
       "7. **Environmental Sustainability**: Consider the environmental impacts of AI development and deployment, and strive to minimize waste, energy consumption, and e-waste generation.\n",
       "8. **Human Rights and Social Justice**: Ensure that AI systems respect and promote human rights, social justice, and the well-being of all individuals and communities, regardless of their background, culture, or socioeconomic status.\n",
       "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI systems to identify and mitigate potential risks, and to ensure that they remain aligned with human values and societal well-being.\n",
       "10. **Education, Awareness, and Literacy**: Foster education, awareness, and literacy about AI and its impacts, to empower individuals and communities to make informed decisions about AI adoption and use.\n",
       "\n",
       "**Addressing Conflicts:**\n",
       "\n",
       "To address potential conflicts between these principles, I would propose the following framework:\n",
       "\n",
       "1. **Principles Hierarchy**: Establish a hierarchy of principles, with human well-being and safety at the top, followed by transparency, accountability, and fairness, and then by principles related to innovation, environmental sustainability, and education.\n",
       "2. **Context-Dependent Balancing**: Balance competing principles in a context-dependent manner, taking into account the specific application, industry, or societal context in which the AI system is being developed or deployed.\n",
       "3. **Stakeholder Engagement**: Engage with diverse stakeholders, including experts, policymakers, civil society organizations, and affected communities, to ensure that AI development and deployment are inclusive, participatory, and responsive to societal needs and concerns.\n",
       "4. **Case-Based Reasoning**: Use case-based reasoning and scenario planning to identify potential conflicts and trade-offs between principles, and to develop context-specific guidelines and regulations.\n",
       "5. **Iterative Review and Revision**: Regularly review and revise the ethical framework to ensure that it remains relevant, effective, and aligned with evolving societal values and technological advancements.\n",
       "6. **Independent Review and Oversight**: Establish independent review and oversight mechanisms to ensure that AI development and deployment are subject to rigorous scrutiny and evaluation, and that principles are enforced in practice.\n",
       "7. **International Cooperation**: Foster international cooperation and collaboration to develop shared standards, guidelines, and regulatory frameworks for AI development and deployment, and to promote global consistency and harmonization.\n",
       "\n",
       "**Implementation:**\n",
       "\n",
       "To implement this ethical framework, I would propose the following steps:\n",
       "\n",
       "1. **Develop Guidelines and Regulations**: Develop guidelines, regulations, and standards for AI development and deployment, based on the principles outlined above.\n",
       "2. **Establish Oversight Mechanisms**: Establish independent oversight mechanisms, such as ethics review boards, to ensure that AI development and deployment comply with the principles and guidelines.\n",
       "3. **Provide Education and Training**: Provide education and training programs for AI developers, users, and stakeholders, to promote awareness, understanding, and literacy about AI and its impacts.\n",
       "4. **Support Research and Development**: Support research and development of AI systems that prioritize human well-being, safety, and dignity, and that are designed to address societal challenges and needs.\n",
       "5. **Facilitate Public Engagement**: Facilitate public engagement, participation, and debate about AI development and deployment, to ensure that societal concerns and values are taken into account.\n",
       "\n",
       "By following this framework, we can create a more ethical, responsible, and human-centered approach to AI development and deployment, one that balances innovation with societal well-being and promotes a future where AI is used for the betterment of humanity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'claude-3-7-sonnet-latest', 'gemini-2.0-flash', 'deepseek-chat', 'llama-3.3-70b-versatile']\n",
      "['Creating a new ethical framework for the development and application of artificial intelligence (AI) requires a balanced approach that fosters innovation while ensuring societal well-being. Here are key principles to consider, along with strategies to address potential conflicts:\\n\\n### Key Principles:\\n\\n1. **Human-Centric Design**: \\n   - AI systems should prioritize human needs, values, and rights. This involves co-creating technologies with diverse stakeholders, including users, communities, ethicists, and domain experts.\\n\\n2. **Transparency and Explainability**: \\n   - AI systems must be transparent in their processes and decision-making mechanisms. Users and affected parties should understand how AI operates, the data it uses, and its outputs.\\n\\n3. **Accountability and Responsibility**: \\n   - Clear lines of accountability must be established for AI developers and organizations. This includes mechanisms for redress when AI systems cause harm or discrimination.\\n\\n4. **Privacy and Data Protection**: \\n   - The collection, use, and sharing of data should respect individual privacy rights and comply with relevant legal frameworks. Anonymization and user consent should be prioritized.\\n\\n5. **Equity and Inclusion**: \\n   - AI development should actively aim to reduce inequalities and avoid reinforcing biases. This includes ensuring that underrepresented groups have a voice in the design and implementation phases.\\n\\n6. **Sustainability**: \\n   - AI systems should be designed with environmental considerations in mind, striving to minimize energy consumption and support sustainable practices.\\n\\n7. **Safety and Security**: \\n   - AI systems must be developed with robust safety measures in place to prevent unintended consequences, including malicious use. The systems should be resilient against attacks and able to operate safely in diverse conditions.\\n\\n8. **Promotion of Public Good**: \\n   - AI should contribute positively to societal goals, such as enhancing healthcare, education, and public safety. Development should focus on applications that improve quality of life and social welfare.\\n\\n9. **Adaptive Governance**: \\n   - The framework should include flexible governance structures that can evolve with the rapidly changing landscape of AI technology. Stakeholders should be able to adapt policies and regulations based on new information and societal impact.\\n\\n### Addressing Conflicts Between Principles:\\n\\nConflicts may arise between innovation and these principles. Here are strategies to navigate such tensions:\\n\\n- **Stakeholder Engagement**: Regularly involve diverse stakeholders in the decision-making processes to identify potential conflicts early and collaboratively find solutions that balance competing interests.\\n\\n- **Ethical Review Boards**: Establish independent ethical review boards or advisory councils to assess and provide guidance on AI projects, weighing innovation against societal considerations.\\n\\n- **Iterative Development and Feedback Loops**: Use iterative design principles that allow for continuous testing, evaluation, and refinement of AI systems. Employ mechanisms for public feedback to ensure alignment with societal values.\\n\\n- **Regulatory Sandboxes**: Implement regulatory sandboxes that allow for controlled experimentation with new AI technologies. This encourages innovation while maintaining oversight to address ethical concerns.\\n\\n- **Conflict Resolution Frameworks**: Create specific frameworks for resolving conflicts between principles, such as prioritizing human rights in cases where innovation may infringe on individual freedoms.\\n\\n- **Quantitative and Qualitative Impact Assessments**: Utilize both quantitative metrics (like efficiency gains) and qualitative measures (like societal impact narratives) to evaluate the trade-offs between innovation and ethical principles.\\n\\nBy embedding these principles and approaches into the developmental lifecycle of AI, a new ethical framework can promote responsible innovation that aligns with the well-being of society.', '# An Ethical Framework for AI Development\\n\\nIf I were to create a new ethical framework for AI, I would center these key principles:\\n\\n## Core Principles\\n\\n**Beneficence Beyond Metrics:** AI should demonstrably improve human flourishing, not just optimize measurable outcomes.\\n\\n**Distributed Governance:** Decision-making authority should be shared across diverse stakeholders, preventing power concentration.\\n\\n**Epistemic Humility:** Systems should acknowledge uncertainty and the limits of their knowledge.\\n\\n**Reversibility:** Meaningful ability to undo harmful implementations and effects.\\n\\n**Contextual Alignment:** Ethical considerations must be culturally responsive while maintaining core human rights.\\n\\n## Addressing Conflicts\\n\\nWhen principles conflict, I would implement:\\n\\n1. A deliberative process prioritizing voices of the potentially most affected\\n2. Tiered implementation allowing controlled testing before widespread deployment\\n3. Independent oversight with substantive representation from marginalized communities\\n4. Mandatory impact assessments at regular intervals\\n\\nThe most challenging tension may be between innovation and precaution. I would address this through mandatory \"ethical sandboxes\" where technologies can be developed with appropriate safeguards while still enabling progress.\\n\\nWhat aspects of this framework do you find most compelling or problematic?', 'Okay, if I could design a new ethical framework for AI development and application, I would focus on creating a system that is both innovative and deeply mindful of its societal impact. This framework would be built on several core principles and have mechanisms for resolving the inevitable conflicts between them.\\n\\nHere\\'s a breakdown of the key principles and conflict resolution strategies:\\n\\n**I. Core Principles:**\\n\\n1.  **Human-Centeredness & Dignity:**\\n\\n    *   **Principle:** AI should be designed, developed, and deployed to serve humanity and enhance human well-being, autonomy, and dignity. It should prioritize human values and rights, not replace or diminish them.  AI should not be used in ways that dehumanize, exploit, or oppress individuals or groups.\\n    *   **Operationalization:**  This principle translates to requiring human oversight in critical AI decision-making processes (especially in areas like justice, healthcare, and welfare), ensuring accessibility for all users (regardless of abilities), and proactively designing AI systems to protect privacy and prevent discrimination.\\n\\n2.  **Beneficence & Non-Maleficence (Do Good, Avoid Harm):**\\n\\n    *   **Principle:** AI development should actively seek to maximize benefits for society and minimize potential harms. This includes both direct harms (e.g., physical injury, biased decisions) and indirect harms (e.g., job displacement, erosion of social cohesion).\\n    *   **Operationalization:** Mandate rigorous risk assessments throughout the AI lifecycle. This includes identifying potential unintended consequences, developing mitigation strategies, and continuously monitoring AI systems for emergent risks.  Promote the development of \"robust AI\" that is resilient to adversarial attacks and unexpected inputs.  Develop strategies for managing job displacement, potentially through retraining programs, universal basic income, or other social safety nets.\\n\\n3.  **Fairness, Justice, and Equity:**\\n\\n    *   **Principle:** AI systems should be developed and deployed in a manner that promotes fairness, justice, and equity for all individuals and groups, regardless of race, gender, socioeconomic status, or other protected characteristics.  Avoid perpetuating or amplifying existing biases.\\n    *   **Operationalization:**  Require diverse and representative datasets for training AI models. Implement bias detection and mitigation techniques throughout the AI lifecycle. Establish clear accountability mechanisms for biased AI decisions.  Prioritize applications of AI that address societal inequalities.\\n\\n4.  **Transparency, Explainability, and Interpretability:**\\n\\n    *   **Principle:** AI systems should be as transparent and explainable as possible, allowing users and stakeholders to understand how they work, how they make decisions, and what data they use.  Interpretability should be prioritized when the consequences of AI decisions are significant.\\n    *   **Operationalization:** Invest in research and development of explainable AI (XAI) techniques. Require documentation of AI system design, data sources, and algorithms. Provide clear and accessible explanations of AI decisions to affected individuals. Establish mechanisms for auditing AI systems to ensure transparency and accountability.\\n\\n5.  **Accountability and Responsibility:**\\n\\n    *   **Principle:**  Clear lines of accountability and responsibility should be established for the development, deployment, and use of AI systems. Individuals and organizations should be held responsible for the impacts of their AI systems.\\n    *   **Operationalization:** Develop legal and regulatory frameworks that assign liability for AI-related harms. Establish independent AI oversight bodies to monitor and regulate AI development and deployment. Promote ethical AI training and education for all AI professionals. Establish whistleblowing protections for individuals who report unethical AI practices.\\n\\n6.  **Sustainability and Environmental Responsibility:**\\n\\n    *   **Principle:** The development and deployment of AI should be environmentally sustainable and contribute to a healthy planet.  Consider the energy consumption, resource utilization, and waste generation associated with AI systems.\\n    *   **Operationalization:**  Promote the development of energy-efficient AI algorithms and hardware. Encourage the use of renewable energy sources to power AI infrastructure. Explore the use of AI to address environmental challenges, such as climate change and pollution.\\n\\n7.  **Participatory Governance and Public Deliberation:**\\n\\n    *   **Principle:**  The development and deployment of AI should be guided by broad public participation and deliberation.  Stakeholders from diverse backgrounds should have the opportunity to shape the ethical and societal implications of AI.\\n    *   **Operationalization:**  Establish public forums and consultations to discuss AI policy and regulation. Support citizen science initiatives that involve the public in AI research and development. Promote media literacy and critical thinking skills to enable informed public discourse about AI.\\n\\n**II. Addressing Conflicts Between Principles:**\\n\\nThe principles above are not always mutually consistent.  For instance, prioritizing innovation might sometimes conflict with ensuring fairness, or maximizing benefits might come at the expense of transparency.  Therefore, the framework needs to include mechanisms for navigating these conflicts:\\n\\n1.  **Prioritization Framework (Context-Specific):**  Instead of creating a rigid hierarchy, the framework should establish a process for prioritizing principles based on the specific context of the AI application. For example, in autonomous weapons systems, non-maleficence (avoiding harm) would likely take precedence over innovation speed.  This framework should be developed through public consultation and regularly reviewed.\\n\\n2.  **Ethical Impact Assessments (EIAs):** Mandate EIAs for all AI systems that have the potential for significant societal impact. These assessments would systematically analyze the potential ethical risks and benefits of the system, identify potential conflicts between principles, and propose mitigation strategies. The EIA process should involve diverse stakeholders and be transparent to the public.\\n\\n3.  **Multi-Criteria Decision Analysis (MCDA):**  Employ MCDA techniques to evaluate different AI design choices based on multiple ethical criteria. This can help to identify the trade-offs between different principles and to make more informed decisions.  This process should be transparent and documented.\\n\\n4.  **Ethical Review Boards (ERBs):** Establish independent ERBs to review and approve AI projects before they are deployed. These boards would be composed of experts from diverse fields (e.g., ethics, law, computer science, social science) and would have the authority to reject projects that are deemed ethically unacceptable.\\n\\n5.  **Adaptive Governance and Iterative Development:**  Recognize that the ethical implications of AI are constantly evolving. The framework should be designed to be adaptive and iterative, allowing for continuous learning and improvement based on real-world experience.  Regular reviews and updates should be conducted to ensure that the framework remains relevant and effective.\\n\\n6.  **\"Red Button\" Mechanisms:**  In certain high-stakes situations (e.g., autonomous weapons systems, AI-powered surveillance), incorporate mechanisms that allow for human intervention and override of AI decisions. This provides a safety net to prevent catastrophic outcomes.\\n\\n7.  **Emphasis on Education and Training:** Promote ethical AI education and training for all stakeholders, including developers, policymakers, and the general public. This will help to foster a culture of ethical AI development and use.\\n\\n**Key Considerations:**\\n\\n*   **Global Collaboration:**  AI development is a global endeavor. The ethical framework should be developed and implemented in collaboration with international organizations and stakeholders. Harmonization of ethical standards across different countries is crucial.\\n*   **Dynamic Adaptation:**  The framework should be flexible and adaptable to address new challenges and opportunities as AI technology evolves. Regular reviews and updates are essential.\\n*   **Enforcement Mechanisms:**  The framework needs to be backed by effective enforcement mechanisms, including legal and regulatory sanctions, to ensure compliance.\\n\\nBy implementing this framework, we can strive to harness the immense potential of AI while mitigating its risks and ensuring that it serves humanity\\'s best interests. The key is to foster a culture of ethical awareness, responsibility, and continuous learning throughout the AI ecosystem.\\n', 'Creating a new ethical framework for AI development and application requires balancing innovation with societal well-being while addressing inevitable conflicts between principles. Below is a proposed framework with key principles and conflict-resolution strategies:\\n\\n### **Core Ethical Principles**  \\n1. **Human-Centric Beneficence**  \\n   - AI should prioritize human flourishing, ensuring that its development and deployment enhance well-being, equity, and dignity.  \\n   - *Example:* AI in healthcare should focus on improving patient outcomes rather than just cost-cutting.  \\n\\n2. **Transparency & Explainability**  \\n   - AI systems must be interpretable, with clear accountability for decisions. Users should understand how and why AI reaches conclusions.  \\n   - *Example:* A loan-approval AI should provide reasons for rejections in understandable terms.  \\n\\n3. **Fairness & Non-Discrimination**  \\n   - AI must actively mitigate biases in data and decision-making to prevent harm to marginalized groups.  \\n   - *Example:* Facial recognition should be rigorously audited for racial/gender bias.  \\n\\n4. **Privacy & Autonomy**  \\n   - AI should respect individual privacy, with strict data governance and user consent. People should retain control over their personal data.  \\n   - *Example:* AI-driven surveillance should have legal safeguards against misuse.  \\n\\n5. **Robustness & Safety**  \\n   - AI systems must be secure, reliable, and fail-safe to prevent unintended harm.  \\n   - *Example:* Autonomous vehicles must have rigorous safety testing before deployment.  \\n\\n6. **Sustainability**  \\n   - AI development should minimize environmental impact and support long-term ecological balance.  \\n   - *Example:* Energy-efficient AI models should be prioritized over computationally wasteful ones.  \\n\\n7. **Democratic Governance & Accountability**  \\n   - AI regulation should involve diverse stakeholders (governments, industry, civil society) to prevent monopolization and misuse.  \\n   - *Example:* Public oversight boards for AI in policing.  \\n\\n### **Addressing Conflicts Between Principles**  \\n1. **Innovation vs. Safety**  \\n   - *Resolution:* Implement staged deployment (e.g., sandbox testing) where AI is rigorously evaluated before scaling.  \\n\\n2. **Privacy vs. Public Benefit**  \\n   - *Resolution:* Use privacy-preserving techniques (e.g., federated learning, differential privacy) when AI requires sensitive data.  \\n\\n3. **Autonomy vs. Fairness**  \\n   - *Resolution:* Allow opt-outs for AI decisions (e.g., human override in hiring algorithms) while ensuring fairness in defaults.  \\n\\n4. **Corporate Profit vs. Societal Good**  \\n   - *Resolution:* Incentivize ethical AI through tax benefits for responsible deployments and penalties for harmful uses.  \\n\\n### **Implementation Mechanisms**  \\n- **Ethical Impact Assessments (EIAs):** Mandatory audits before AI deployment.  \\n- **Multi-Stakeholder Oversight:** Independent ethics boards with public representation.  \\n- **Adaptive Regulation:** Policies that evolve with AI advancements.  \\n\\n### **Conclusion**  \\nThis framework seeks to foster innovation while safeguarding human rights and societal welfare. By embedding flexibility and accountability, it can adapt to emerging challenges while minimizing harm.  \\n\\nWould you refine any of these principles or suggest additional considerations?', 'If I could create a new ethical framework for the development and application of artificial intelligence (AI), I would include the following key principles to balance innovation with societal well-being:\\n\\n**Principles:**\\n\\n1. **Responsible Innovation**: Encourage innovation while ensuring that AI development is guided by human values, social norms, and ethical considerations.\\n2. **Transparency and Explainability**: Ensure that AI systems are transparent, explainable, and accountable, enabling users to understand how decisions are made and to trust the technology.\\n3. **Human-Centered Design**: Develop AI systems that prioritize human well-being, dignity, and safety, and that are designed to augment human capabilities rather than replace them.\\n4. **Data Protection and Privacy**: Establish robust data protection and privacy protocols to safeguard personal and sensitive information, and to prevent AI systems from perpetuating biases and discrimination.\\n5. **Fairness, Equity, and Non-Discrimination**: Ensure that AI systems are fair, equitable, and free from biases, and that they do not perpetuate existing social and economic inequalities.\\n6. **Accountability and Liability**: Establish clear lines of accountability and liability for AI-related decisions and actions, and provide mechanisms for redress and compensation in cases of harm or injury.\\n7. **Environmental Sustainability**: Consider the environmental impacts of AI development and deployment, and strive to minimize waste, energy consumption, and e-waste generation.\\n8. **Human Rights and Social Justice**: Ensure that AI systems respect and promote human rights, social justice, and the well-being of all individuals and communities, regardless of their background, culture, or socioeconomic status.\\n9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI systems to identify and mitigate potential risks, and to ensure that they remain aligned with human values and societal well-being.\\n10. **Education, Awareness, and Literacy**: Foster education, awareness, and literacy about AI and its impacts, to empower individuals and communities to make informed decisions about AI adoption and use.\\n\\n**Addressing Conflicts:**\\n\\nTo address potential conflicts between these principles, I would propose the following framework:\\n\\n1. **Principles Hierarchy**: Establish a hierarchy of principles, with human well-being and safety at the top, followed by transparency, accountability, and fairness, and then by principles related to innovation, environmental sustainability, and education.\\n2. **Context-Dependent Balancing**: Balance competing principles in a context-dependent manner, taking into account the specific application, industry, or societal context in which the AI system is being developed or deployed.\\n3. **Stakeholder Engagement**: Engage with diverse stakeholders, including experts, policymakers, civil society organizations, and affected communities, to ensure that AI development and deployment are inclusive, participatory, and responsive to societal needs and concerns.\\n4. **Case-Based Reasoning**: Use case-based reasoning and scenario planning to identify potential conflicts and trade-offs between principles, and to develop context-specific guidelines and regulations.\\n5. **Iterative Review and Revision**: Regularly review and revise the ethical framework to ensure that it remains relevant, effective, and aligned with evolving societal values and technological advancements.\\n6. **Independent Review and Oversight**: Establish independent review and oversight mechanisms to ensure that AI development and deployment are subject to rigorous scrutiny and evaluation, and that principles are enforced in practice.\\n7. **International Cooperation**: Foster international cooperation and collaboration to develop shared standards, guidelines, and regulatory frameworks for AI development and deployment, and to promote global consistency and harmonization.\\n\\n**Implementation:**\\n\\nTo implement this ethical framework, I would propose the following steps:\\n\\n1. **Develop Guidelines and Regulations**: Develop guidelines, regulations, and standards for AI development and deployment, based on the principles outlined above.\\n2. **Establish Oversight Mechanisms**: Establish independent oversight mechanisms, such as ethics review boards, to ensure that AI development and deployment comply with the principles and guidelines.\\n3. **Provide Education and Training**: Provide education and training programs for AI developers, users, and stakeholders, to promote awareness, understanding, and literacy about AI and its impacts.\\n4. **Support Research and Development**: Support research and development of AI systems that prioritize human well-being, safety, and dignity, and that are designed to address societal challenges and needs.\\n5. **Facilitate Public Engagement**: Facilitate public engagement, participation, and debate about AI development and deployment, to ensure that societal concerns and values are taken into account.\\n\\nBy following this framework, we can create a more ethical, responsible, and human-centered approach to AI development and deployment, one that balances innovation with societal well-being and promotes a future where AI is used for the betterment of humanity.']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Creating a new ethical framework for the development and application of artificial intelligence (AI) requires a balanced approach that fosters innovation while ensuring societal well-being. Here are key principles to consider, along with strategies to address potential conflicts:\n",
      "\n",
      "### Key Principles:\n",
      "\n",
      "1. **Human-Centric Design**: \n",
      "   - AI systems should prioritize human needs, values, and rights. This involves co-creating technologies with diverse stakeholders, including users, communities, ethicists, and domain experts.\n",
      "\n",
      "2. **Transparency and Explainability**: \n",
      "   - AI systems must be transparent in their processes and decision-making mechanisms. Users and affected parties should understand how AI operates, the data it uses, and its outputs.\n",
      "\n",
      "3. **Accountability and Responsibility**: \n",
      "   - Clear lines of accountability must be established for AI developers and organizations. This includes mechanisms for redress when AI systems cause harm or discrimination.\n",
      "\n",
      "4. **Privacy and Data Protection**: \n",
      "   - The collection, use, and sharing of data should respect individual privacy rights and comply with relevant legal frameworks. Anonymization and user consent should be prioritized.\n",
      "\n",
      "5. **Equity and Inclusion**: \n",
      "   - AI development should actively aim to reduce inequalities and avoid reinforcing biases. This includes ensuring that underrepresented groups have a voice in the design and implementation phases.\n",
      "\n",
      "6. **Sustainability**: \n",
      "   - AI systems should be designed with environmental considerations in mind, striving to minimize energy consumption and support sustainable practices.\n",
      "\n",
      "7. **Safety and Security**: \n",
      "   - AI systems must be developed with robust safety measures in place to prevent unintended consequences, including malicious use. The systems should be resilient against attacks and able to operate safely in diverse conditions.\n",
      "\n",
      "8. **Promotion of Public Good**: \n",
      "   - AI should contribute positively to societal goals, such as enhancing healthcare, education, and public safety. Development should focus on applications that improve quality of life and social welfare.\n",
      "\n",
      "9. **Adaptive Governance**: \n",
      "   - The framework should include flexible governance structures that can evolve with the rapidly changing landscape of AI technology. Stakeholders should be able to adapt policies and regulations based on new information and societal impact.\n",
      "\n",
      "### Addressing Conflicts Between Principles:\n",
      "\n",
      "Conflicts may arise between innovation and these principles. Here are strategies to navigate such tensions:\n",
      "\n",
      "- **Stakeholder Engagement**: Regularly involve diverse stakeholders in the decision-making processes to identify potential conflicts early and collaboratively find solutions that balance competing interests.\n",
      "\n",
      "- **Ethical Review Boards**: Establish independent ethical review boards or advisory councils to assess and provide guidance on AI projects, weighing innovation against societal considerations.\n",
      "\n",
      "- **Iterative Development and Feedback Loops**: Use iterative design principles that allow for continuous testing, evaluation, and refinement of AI systems. Employ mechanisms for public feedback to ensure alignment with societal values.\n",
      "\n",
      "- **Regulatory Sandboxes**: Implement regulatory sandboxes that allow for controlled experimentation with new AI technologies. This encourages innovation while maintaining oversight to address ethical concerns.\n",
      "\n",
      "- **Conflict Resolution Frameworks**: Create specific frameworks for resolving conflicts between principles, such as prioritizing human rights in cases where innovation may infringe on individual freedoms.\n",
      "\n",
      "- **Quantitative and Qualitative Impact Assessments**: Utilize both quantitative metrics (like efficiency gains) and qualitative measures (like societal impact narratives) to evaluate the trade-offs between innovation and ethical principles.\n",
      "\n",
      "By embedding these principles and approaches into the developmental lifecycle of AI, a new ethical framework can promote responsible innovation that aligns with the well-being of society.\n",
      "Competitor: claude-3-7-sonnet-latest\n",
      "\n",
      "# An Ethical Framework for AI Development\n",
      "\n",
      "If I were to create a new ethical framework for AI, I would center these key principles:\n",
      "\n",
      "## Core Principles\n",
      "\n",
      "**Beneficence Beyond Metrics:** AI should demonstrably improve human flourishing, not just optimize measurable outcomes.\n",
      "\n",
      "**Distributed Governance:** Decision-making authority should be shared across diverse stakeholders, preventing power concentration.\n",
      "\n",
      "**Epistemic Humility:** Systems should acknowledge uncertainty and the limits of their knowledge.\n",
      "\n",
      "**Reversibility:** Meaningful ability to undo harmful implementations and effects.\n",
      "\n",
      "**Contextual Alignment:** Ethical considerations must be culturally responsive while maintaining core human rights.\n",
      "\n",
      "## Addressing Conflicts\n",
      "\n",
      "When principles conflict, I would implement:\n",
      "\n",
      "1. A deliberative process prioritizing voices of the potentially most affected\n",
      "2. Tiered implementation allowing controlled testing before widespread deployment\n",
      "3. Independent oversight with substantive representation from marginalized communities\n",
      "4. Mandatory impact assessments at regular intervals\n",
      "\n",
      "The most challenging tension may be between innovation and precaution. I would address this through mandatory \"ethical sandboxes\" where technologies can be developed with appropriate safeguards while still enabling progress.\n",
      "\n",
      "What aspects of this framework do you find most compelling or problematic?\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Okay, if I could design a new ethical framework for AI development and application, I would focus on creating a system that is both innovative and deeply mindful of its societal impact. This framework would be built on several core principles and have mechanisms for resolving the inevitable conflicts between them.\n",
      "\n",
      "Here's a breakdown of the key principles and conflict resolution strategies:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centeredness & Dignity:**\n",
      "\n",
      "    *   **Principle:** AI should be designed, developed, and deployed to serve humanity and enhance human well-being, autonomy, and dignity. It should prioritize human values and rights, not replace or diminish them.  AI should not be used in ways that dehumanize, exploit, or oppress individuals or groups.\n",
      "    *   **Operationalization:**  This principle translates to requiring human oversight in critical AI decision-making processes (especially in areas like justice, healthcare, and welfare), ensuring accessibility for all users (regardless of abilities), and proactively designing AI systems to protect privacy and prevent discrimination.\n",
      "\n",
      "2.  **Beneficence & Non-Maleficence (Do Good, Avoid Harm):**\n",
      "\n",
      "    *   **Principle:** AI development should actively seek to maximize benefits for society and minimize potential harms. This includes both direct harms (e.g., physical injury, biased decisions) and indirect harms (e.g., job displacement, erosion of social cohesion).\n",
      "    *   **Operationalization:** Mandate rigorous risk assessments throughout the AI lifecycle. This includes identifying potential unintended consequences, developing mitigation strategies, and continuously monitoring AI systems for emergent risks.  Promote the development of \"robust AI\" that is resilient to adversarial attacks and unexpected inputs.  Develop strategies for managing job displacement, potentially through retraining programs, universal basic income, or other social safety nets.\n",
      "\n",
      "3.  **Fairness, Justice, and Equity:**\n",
      "\n",
      "    *   **Principle:** AI systems should be developed and deployed in a manner that promotes fairness, justice, and equity for all individuals and groups, regardless of race, gender, socioeconomic status, or other protected characteristics.  Avoid perpetuating or amplifying existing biases.\n",
      "    *   **Operationalization:**  Require diverse and representative datasets for training AI models. Implement bias detection and mitigation techniques throughout the AI lifecycle. Establish clear accountability mechanisms for biased AI decisions.  Prioritize applications of AI that address societal inequalities.\n",
      "\n",
      "4.  **Transparency, Explainability, and Interpretability:**\n",
      "\n",
      "    *   **Principle:** AI systems should be as transparent and explainable as possible, allowing users and stakeholders to understand how they work, how they make decisions, and what data they use.  Interpretability should be prioritized when the consequences of AI decisions are significant.\n",
      "    *   **Operationalization:** Invest in research and development of explainable AI (XAI) techniques. Require documentation of AI system design, data sources, and algorithms. Provide clear and accessible explanations of AI decisions to affected individuals. Establish mechanisms for auditing AI systems to ensure transparency and accountability.\n",
      "\n",
      "5.  **Accountability and Responsibility:**\n",
      "\n",
      "    *   **Principle:**  Clear lines of accountability and responsibility should be established for the development, deployment, and use of AI systems. Individuals and organizations should be held responsible for the impacts of their AI systems.\n",
      "    *   **Operationalization:** Develop legal and regulatory frameworks that assign liability for AI-related harms. Establish independent AI oversight bodies to monitor and regulate AI development and deployment. Promote ethical AI training and education for all AI professionals. Establish whistleblowing protections for individuals who report unethical AI practices.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**\n",
      "\n",
      "    *   **Principle:** The development and deployment of AI should be environmentally sustainable and contribute to a healthy planet.  Consider the energy consumption, resource utilization, and waste generation associated with AI systems.\n",
      "    *   **Operationalization:**  Promote the development of energy-efficient AI algorithms and hardware. Encourage the use of renewable energy sources to power AI infrastructure. Explore the use of AI to address environmental challenges, such as climate change and pollution.\n",
      "\n",
      "7.  **Participatory Governance and Public Deliberation:**\n",
      "\n",
      "    *   **Principle:**  The development and deployment of AI should be guided by broad public participation and deliberation.  Stakeholders from diverse backgrounds should have the opportunity to shape the ethical and societal implications of AI.\n",
      "    *   **Operationalization:**  Establish public forums and consultations to discuss AI policy and regulation. Support citizen science initiatives that involve the public in AI research and development. Promote media literacy and critical thinking skills to enable informed public discourse about AI.\n",
      "\n",
      "**II. Addressing Conflicts Between Principles:**\n",
      "\n",
      "The principles above are not always mutually consistent.  For instance, prioritizing innovation might sometimes conflict with ensuring fairness, or maximizing benefits might come at the expense of transparency.  Therefore, the framework needs to include mechanisms for navigating these conflicts:\n",
      "\n",
      "1.  **Prioritization Framework (Context-Specific):**  Instead of creating a rigid hierarchy, the framework should establish a process for prioritizing principles based on the specific context of the AI application. For example, in autonomous weapons systems, non-maleficence (avoiding harm) would likely take precedence over innovation speed.  This framework should be developed through public consultation and regularly reviewed.\n",
      "\n",
      "2.  **Ethical Impact Assessments (EIAs):** Mandate EIAs for all AI systems that have the potential for significant societal impact. These assessments would systematically analyze the potential ethical risks and benefits of the system, identify potential conflicts between principles, and propose mitigation strategies. The EIA process should involve diverse stakeholders and be transparent to the public.\n",
      "\n",
      "3.  **Multi-Criteria Decision Analysis (MCDA):**  Employ MCDA techniques to evaluate different AI design choices based on multiple ethical criteria. This can help to identify the trade-offs between different principles and to make more informed decisions.  This process should be transparent and documented.\n",
      "\n",
      "4.  **Ethical Review Boards (ERBs):** Establish independent ERBs to review and approve AI projects before they are deployed. These boards would be composed of experts from diverse fields (e.g., ethics, law, computer science, social science) and would have the authority to reject projects that are deemed ethically unacceptable.\n",
      "\n",
      "5.  **Adaptive Governance and Iterative Development:**  Recognize that the ethical implications of AI are constantly evolving. The framework should be designed to be adaptive and iterative, allowing for continuous learning and improvement based on real-world experience.  Regular reviews and updates should be conducted to ensure that the framework remains relevant and effective.\n",
      "\n",
      "6.  **\"Red Button\" Mechanisms:**  In certain high-stakes situations (e.g., autonomous weapons systems, AI-powered surveillance), incorporate mechanisms that allow for human intervention and override of AI decisions. This provides a safety net to prevent catastrophic outcomes.\n",
      "\n",
      "7.  **Emphasis on Education and Training:** Promote ethical AI education and training for all stakeholders, including developers, policymakers, and the general public. This will help to foster a culture of ethical AI development and use.\n",
      "\n",
      "**Key Considerations:**\n",
      "\n",
      "*   **Global Collaboration:**  AI development is a global endeavor. The ethical framework should be developed and implemented in collaboration with international organizations and stakeholders. Harmonization of ethical standards across different countries is crucial.\n",
      "*   **Dynamic Adaptation:**  The framework should be flexible and adaptable to address new challenges and opportunities as AI technology evolves. Regular reviews and updates are essential.\n",
      "*   **Enforcement Mechanisms:**  The framework needs to be backed by effective enforcement mechanisms, including legal and regulatory sanctions, to ensure compliance.\n",
      "\n",
      "By implementing this framework, we can strive to harness the immense potential of AI while mitigating its risks and ensuring that it serves humanity's best interests. The key is to foster a culture of ethical awareness, responsibility, and continuous learning throughout the AI ecosystem.\n",
      "\n",
      "Competitor: deepseek-chat\n",
      "\n",
      "Creating a new ethical framework for AI development and application requires balancing innovation with societal well-being while addressing inevitable conflicts between principles. Below is a proposed framework with key principles and conflict-resolution strategies:\n",
      "\n",
      "### **Core Ethical Principles**  \n",
      "1. **Human-Centric Beneficence**  \n",
      "   - AI should prioritize human flourishing, ensuring that its development and deployment enhance well-being, equity, and dignity.  \n",
      "   - *Example:* AI in healthcare should focus on improving patient outcomes rather than just cost-cutting.  \n",
      "\n",
      "2. **Transparency & Explainability**  \n",
      "   - AI systems must be interpretable, with clear accountability for decisions. Users should understand how and why AI reaches conclusions.  \n",
      "   - *Example:* A loan-approval AI should provide reasons for rejections in understandable terms.  \n",
      "\n",
      "3. **Fairness & Non-Discrimination**  \n",
      "   - AI must actively mitigate biases in data and decision-making to prevent harm to marginalized groups.  \n",
      "   - *Example:* Facial recognition should be rigorously audited for racial/gender bias.  \n",
      "\n",
      "4. **Privacy & Autonomy**  \n",
      "   - AI should respect individual privacy, with strict data governance and user consent. People should retain control over their personal data.  \n",
      "   - *Example:* AI-driven surveillance should have legal safeguards against misuse.  \n",
      "\n",
      "5. **Robustness & Safety**  \n",
      "   - AI systems must be secure, reliable, and fail-safe to prevent unintended harm.  \n",
      "   - *Example:* Autonomous vehicles must have rigorous safety testing before deployment.  \n",
      "\n",
      "6. **Sustainability**  \n",
      "   - AI development should minimize environmental impact and support long-term ecological balance.  \n",
      "   - *Example:* Energy-efficient AI models should be prioritized over computationally wasteful ones.  \n",
      "\n",
      "7. **Democratic Governance & Accountability**  \n",
      "   - AI regulation should involve diverse stakeholders (governments, industry, civil society) to prevent monopolization and misuse.  \n",
      "   - *Example:* Public oversight boards for AI in policing.  \n",
      "\n",
      "### **Addressing Conflicts Between Principles**  \n",
      "1. **Innovation vs. Safety**  \n",
      "   - *Resolution:* Implement staged deployment (e.g., sandbox testing) where AI is rigorously evaluated before scaling.  \n",
      "\n",
      "2. **Privacy vs. Public Benefit**  \n",
      "   - *Resolution:* Use privacy-preserving techniques (e.g., federated learning, differential privacy) when AI requires sensitive data.  \n",
      "\n",
      "3. **Autonomy vs. Fairness**  \n",
      "   - *Resolution:* Allow opt-outs for AI decisions (e.g., human override in hiring algorithms) while ensuring fairness in defaults.  \n",
      "\n",
      "4. **Corporate Profit vs. Societal Good**  \n",
      "   - *Resolution:* Incentivize ethical AI through tax benefits for responsible deployments and penalties for harmful uses.  \n",
      "\n",
      "### **Implementation Mechanisms**  \n",
      "- **Ethical Impact Assessments (EIAs):** Mandatory audits before AI deployment.  \n",
      "- **Multi-Stakeholder Oversight:** Independent ethics boards with public representation.  \n",
      "- **Adaptive Regulation:** Policies that evolve with AI advancements.  \n",
      "\n",
      "### **Conclusion**  \n",
      "This framework seeks to foster innovation while safeguarding human rights and societal welfare. By embedding flexibility and accountability, it can adapt to emerging challenges while minimizing harm.  \n",
      "\n",
      "Would you refine any of these principles or suggest additional considerations?\n",
      "Competitor: llama-3.3-70b-versatile\n",
      "\n",
      "If I could create a new ethical framework for the development and application of artificial intelligence (AI), I would include the following key principles to balance innovation with societal well-being:\n",
      "\n",
      "**Principles:**\n",
      "\n",
      "1. **Responsible Innovation**: Encourage innovation while ensuring that AI development is guided by human values, social norms, and ethical considerations.\n",
      "2. **Transparency and Explainability**: Ensure that AI systems are transparent, explainable, and accountable, enabling users to understand how decisions are made and to trust the technology.\n",
      "3. **Human-Centered Design**: Develop AI systems that prioritize human well-being, dignity, and safety, and that are designed to augment human capabilities rather than replace them.\n",
      "4. **Data Protection and Privacy**: Establish robust data protection and privacy protocols to safeguard personal and sensitive information, and to prevent AI systems from perpetuating biases and discrimination.\n",
      "5. **Fairness, Equity, and Non-Discrimination**: Ensure that AI systems are fair, equitable, and free from biases, and that they do not perpetuate existing social and economic inequalities.\n",
      "6. **Accountability and Liability**: Establish clear lines of accountability and liability for AI-related decisions and actions, and provide mechanisms for redress and compensation in cases of harm or injury.\n",
      "7. **Environmental Sustainability**: Consider the environmental impacts of AI development and deployment, and strive to minimize waste, energy consumption, and e-waste generation.\n",
      "8. **Human Rights and Social Justice**: Ensure that AI systems respect and promote human rights, social justice, and the well-being of all individuals and communities, regardless of their background, culture, or socioeconomic status.\n",
      "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI systems to identify and mitigate potential risks, and to ensure that they remain aligned with human values and societal well-being.\n",
      "10. **Education, Awareness, and Literacy**: Foster education, awareness, and literacy about AI and its impacts, to empower individuals and communities to make informed decisions about AI adoption and use.\n",
      "\n",
      "**Addressing Conflicts:**\n",
      "\n",
      "To address potential conflicts between these principles, I would propose the following framework:\n",
      "\n",
      "1. **Principles Hierarchy**: Establish a hierarchy of principles, with human well-being and safety at the top, followed by transparency, accountability, and fairness, and then by principles related to innovation, environmental sustainability, and education.\n",
      "2. **Context-Dependent Balancing**: Balance competing principles in a context-dependent manner, taking into account the specific application, industry, or societal context in which the AI system is being developed or deployed.\n",
      "3. **Stakeholder Engagement**: Engage with diverse stakeholders, including experts, policymakers, civil society organizations, and affected communities, to ensure that AI development and deployment are inclusive, participatory, and responsive to societal needs and concerns.\n",
      "4. **Case-Based Reasoning**: Use case-based reasoning and scenario planning to identify potential conflicts and trade-offs between principles, and to develop context-specific guidelines and regulations.\n",
      "5. **Iterative Review and Revision**: Regularly review and revise the ethical framework to ensure that it remains relevant, effective, and aligned with evolving societal values and technological advancements.\n",
      "6. **Independent Review and Oversight**: Establish independent review and oversight mechanisms to ensure that AI development and deployment are subject to rigorous scrutiny and evaluation, and that principles are enforced in practice.\n",
      "7. **International Cooperation**: Foster international cooperation and collaboration to develop shared standards, guidelines, and regulatory frameworks for AI development and deployment, and to promote global consistency and harmonization.\n",
      "\n",
      "**Implementation:**\n",
      "\n",
      "To implement this ethical framework, I would propose the following steps:\n",
      "\n",
      "1. **Develop Guidelines and Regulations**: Develop guidelines, regulations, and standards for AI development and deployment, based on the principles outlined above.\n",
      "2. **Establish Oversight Mechanisms**: Establish independent oversight mechanisms, such as ethics review boards, to ensure that AI development and deployment comply with the principles and guidelines.\n",
      "3. **Provide Education and Training**: Provide education and training programs for AI developers, users, and stakeholders, to promote awareness, understanding, and literacy about AI and its impacts.\n",
      "4. **Support Research and Development**: Support research and development of AI systems that prioritize human well-being, safety, and dignity, and that are designed to address societal challenges and needs.\n",
      "5. **Facilitate Public Engagement**: Facilitate public engagement, participation, and debate about AI development and deployment, to ensure that societal concerns and values are taken into account.\n",
      "\n",
      "By following this framework, we can create a more ethical, responsible, and human-centered approach to AI development and deployment, one that balances innovation with societal well-being and promotes a future where AI is used for the betterment of humanity.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Creating a new ethical framework for the development and application of artificial intelligence (AI) requires a balanced approach that fosters innovation while ensuring societal well-being. Here are key principles to consider, along with strategies to address potential conflicts:\n",
      "\n",
      "### Key Principles:\n",
      "\n",
      "1. **Human-Centric Design**: \n",
      "   - AI systems should prioritize human needs, values, and rights. This involves co-creating technologies with diverse stakeholders, including users, communities, ethicists, and domain experts.\n",
      "\n",
      "2. **Transparency and Explainability**: \n",
      "   - AI systems must be transparent in their processes and decision-making mechanisms. Users and affected parties should understand how AI operates, the data it uses, and its outputs.\n",
      "\n",
      "3. **Accountability and Responsibility**: \n",
      "   - Clear lines of accountability must be established for AI developers and organizations. This includes mechanisms for redress when AI systems cause harm or discrimination.\n",
      "\n",
      "4. **Privacy and Data Protection**: \n",
      "   - The collection, use, and sharing of data should respect individual privacy rights and comply with relevant legal frameworks. Anonymization and user consent should be prioritized.\n",
      "\n",
      "5. **Equity and Inclusion**: \n",
      "   - AI development should actively aim to reduce inequalities and avoid reinforcing biases. This includes ensuring that underrepresented groups have a voice in the design and implementation phases.\n",
      "\n",
      "6. **Sustainability**: \n",
      "   - AI systems should be designed with environmental considerations in mind, striving to minimize energy consumption and support sustainable practices.\n",
      "\n",
      "7. **Safety and Security**: \n",
      "   - AI systems must be developed with robust safety measures in place to prevent unintended consequences, including malicious use. The systems should be resilient against attacks and able to operate safely in diverse conditions.\n",
      "\n",
      "8. **Promotion of Public Good**: \n",
      "   - AI should contribute positively to societal goals, such as enhancing healthcare, education, and public safety. Development should focus on applications that improve quality of life and social welfare.\n",
      "\n",
      "9. **Adaptive Governance**: \n",
      "   - The framework should include flexible governance structures that can evolve with the rapidly changing landscape of AI technology. Stakeholders should be able to adapt policies and regulations based on new information and societal impact.\n",
      "\n",
      "### Addressing Conflicts Between Principles:\n",
      "\n",
      "Conflicts may arise between innovation and these principles. Here are strategies to navigate such tensions:\n",
      "\n",
      "- **Stakeholder Engagement**: Regularly involve diverse stakeholders in the decision-making processes to identify potential conflicts early and collaboratively find solutions that balance competing interests.\n",
      "\n",
      "- **Ethical Review Boards**: Establish independent ethical review boards or advisory councils to assess and provide guidance on AI projects, weighing innovation against societal considerations.\n",
      "\n",
      "- **Iterative Development and Feedback Loops**: Use iterative design principles that allow for continuous testing, evaluation, and refinement of AI systems. Employ mechanisms for public feedback to ensure alignment with societal values.\n",
      "\n",
      "- **Regulatory Sandboxes**: Implement regulatory sandboxes that allow for controlled experimentation with new AI technologies. This encourages innovation while maintaining oversight to address ethical concerns.\n",
      "\n",
      "- **Conflict Resolution Frameworks**: Create specific frameworks for resolving conflicts between principles, such as prioritizing human rights in cases where innovation may infringe on individual freedoms.\n",
      "\n",
      "- **Quantitative and Qualitative Impact Assessments**: Utilize both quantitative metrics (like efficiency gains) and qualitative measures (like societal impact narratives) to evaluate the trade-offs between innovation and ethical principles.\n",
      "\n",
      "By embedding these principles and approaches into the developmental lifecycle of AI, a new ethical framework can promote responsible innovation that aligns with the well-being of society.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# An Ethical Framework for AI Development\n",
      "\n",
      "If I were to create a new ethical framework for AI, I would center these key principles:\n",
      "\n",
      "## Core Principles\n",
      "\n",
      "**Beneficence Beyond Metrics:** AI should demonstrably improve human flourishing, not just optimize measurable outcomes.\n",
      "\n",
      "**Distributed Governance:** Decision-making authority should be shared across diverse stakeholders, preventing power concentration.\n",
      "\n",
      "**Epistemic Humility:** Systems should acknowledge uncertainty and the limits of their knowledge.\n",
      "\n",
      "**Reversibility:** Meaningful ability to undo harmful implementations and effects.\n",
      "\n",
      "**Contextual Alignment:** Ethical considerations must be culturally responsive while maintaining core human rights.\n",
      "\n",
      "## Addressing Conflicts\n",
      "\n",
      "When principles conflict, I would implement:\n",
      "\n",
      "1. A deliberative process prioritizing voices of the potentially most affected\n",
      "2. Tiered implementation allowing controlled testing before widespread deployment\n",
      "3. Independent oversight with substantive representation from marginalized communities\n",
      "4. Mandatory impact assessments at regular intervals\n",
      "\n",
      "The most challenging tension may be between innovation and precaution. I would address this through mandatory \"ethical sandboxes\" where technologies can be developed with appropriate safeguards while still enabling progress.\n",
      "\n",
      "What aspects of this framework do you find most compelling or problematic?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Okay, if I could design a new ethical framework for AI development and application, I would focus on creating a system that is both innovative and deeply mindful of its societal impact. This framework would be built on several core principles and have mechanisms for resolving the inevitable conflicts between them.\n",
      "\n",
      "Here's a breakdown of the key principles and conflict resolution strategies:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centeredness & Dignity:**\n",
      "\n",
      "    *   **Principle:** AI should be designed, developed, and deployed to serve humanity and enhance human well-being, autonomy, and dignity. It should prioritize human values and rights, not replace or diminish them.  AI should not be used in ways that dehumanize, exploit, or oppress individuals or groups.\n",
      "    *   **Operationalization:**  This principle translates to requiring human oversight in critical AI decision-making processes (especially in areas like justice, healthcare, and welfare), ensuring accessibility for all users (regardless of abilities), and proactively designing AI systems to protect privacy and prevent discrimination.\n",
      "\n",
      "2.  **Beneficence & Non-Maleficence (Do Good, Avoid Harm):**\n",
      "\n",
      "    *   **Principle:** AI development should actively seek to maximize benefits for society and minimize potential harms. This includes both direct harms (e.g., physical injury, biased decisions) and indirect harms (e.g., job displacement, erosion of social cohesion).\n",
      "    *   **Operationalization:** Mandate rigorous risk assessments throughout the AI lifecycle. This includes identifying potential unintended consequences, developing mitigation strategies, and continuously monitoring AI systems for emergent risks.  Promote the development of \"robust AI\" that is resilient to adversarial attacks and unexpected inputs.  Develop strategies for managing job displacement, potentially through retraining programs, universal basic income, or other social safety nets.\n",
      "\n",
      "3.  **Fairness, Justice, and Equity:**\n",
      "\n",
      "    *   **Principle:** AI systems should be developed and deployed in a manner that promotes fairness, justice, and equity for all individuals and groups, regardless of race, gender, socioeconomic status, or other protected characteristics.  Avoid perpetuating or amplifying existing biases.\n",
      "    *   **Operationalization:**  Require diverse and representative datasets for training AI models. Implement bias detection and mitigation techniques throughout the AI lifecycle. Establish clear accountability mechanisms for biased AI decisions.  Prioritize applications of AI that address societal inequalities.\n",
      "\n",
      "4.  **Transparency, Explainability, and Interpretability:**\n",
      "\n",
      "    *   **Principle:** AI systems should be as transparent and explainable as possible, allowing users and stakeholders to understand how they work, how they make decisions, and what data they use.  Interpretability should be prioritized when the consequences of AI decisions are significant.\n",
      "    *   **Operationalization:** Invest in research and development of explainable AI (XAI) techniques. Require documentation of AI system design, data sources, and algorithms. Provide clear and accessible explanations of AI decisions to affected individuals. Establish mechanisms for auditing AI systems to ensure transparency and accountability.\n",
      "\n",
      "5.  **Accountability and Responsibility:**\n",
      "\n",
      "    *   **Principle:**  Clear lines of accountability and responsibility should be established for the development, deployment, and use of AI systems. Individuals and organizations should be held responsible for the impacts of their AI systems.\n",
      "    *   **Operationalization:** Develop legal and regulatory frameworks that assign liability for AI-related harms. Establish independent AI oversight bodies to monitor and regulate AI development and deployment. Promote ethical AI training and education for all AI professionals. Establish whistleblowing protections for individuals who report unethical AI practices.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**\n",
      "\n",
      "    *   **Principle:** The development and deployment of AI should be environmentally sustainable and contribute to a healthy planet.  Consider the energy consumption, resource utilization, and waste generation associated with AI systems.\n",
      "    *   **Operationalization:**  Promote the development of energy-efficient AI algorithms and hardware. Encourage the use of renewable energy sources to power AI infrastructure. Explore the use of AI to address environmental challenges, such as climate change and pollution.\n",
      "\n",
      "7.  **Participatory Governance and Public Deliberation:**\n",
      "\n",
      "    *   **Principle:**  The development and deployment of AI should be guided by broad public participation and deliberation.  Stakeholders from diverse backgrounds should have the opportunity to shape the ethical and societal implications of AI.\n",
      "    *   **Operationalization:**  Establish public forums and consultations to discuss AI policy and regulation. Support citizen science initiatives that involve the public in AI research and development. Promote media literacy and critical thinking skills to enable informed public discourse about AI.\n",
      "\n",
      "**II. Addressing Conflicts Between Principles:**\n",
      "\n",
      "The principles above are not always mutually consistent.  For instance, prioritizing innovation might sometimes conflict with ensuring fairness, or maximizing benefits might come at the expense of transparency.  Therefore, the framework needs to include mechanisms for navigating these conflicts:\n",
      "\n",
      "1.  **Prioritization Framework (Context-Specific):**  Instead of creating a rigid hierarchy, the framework should establish a process for prioritizing principles based on the specific context of the AI application. For example, in autonomous weapons systems, non-maleficence (avoiding harm) would likely take precedence over innovation speed.  This framework should be developed through public consultation and regularly reviewed.\n",
      "\n",
      "2.  **Ethical Impact Assessments (EIAs):** Mandate EIAs for all AI systems that have the potential for significant societal impact. These assessments would systematically analyze the potential ethical risks and benefits of the system, identify potential conflicts between principles, and propose mitigation strategies. The EIA process should involve diverse stakeholders and be transparent to the public.\n",
      "\n",
      "3.  **Multi-Criteria Decision Analysis (MCDA):**  Employ MCDA techniques to evaluate different AI design choices based on multiple ethical criteria. This can help to identify the trade-offs between different principles and to make more informed decisions.  This process should be transparent and documented.\n",
      "\n",
      "4.  **Ethical Review Boards (ERBs):** Establish independent ERBs to review and approve AI projects before they are deployed. These boards would be composed of experts from diverse fields (e.g., ethics, law, computer science, social science) and would have the authority to reject projects that are deemed ethically unacceptable.\n",
      "\n",
      "5.  **Adaptive Governance and Iterative Development:**  Recognize that the ethical implications of AI are constantly evolving. The framework should be designed to be adaptive and iterative, allowing for continuous learning and improvement based on real-world experience.  Regular reviews and updates should be conducted to ensure that the framework remains relevant and effective.\n",
      "\n",
      "6.  **\"Red Button\" Mechanisms:**  In certain high-stakes situations (e.g., autonomous weapons systems, AI-powered surveillance), incorporate mechanisms that allow for human intervention and override of AI decisions. This provides a safety net to prevent catastrophic outcomes.\n",
      "\n",
      "7.  **Emphasis on Education and Training:** Promote ethical AI education and training for all stakeholders, including developers, policymakers, and the general public. This will help to foster a culture of ethical AI development and use.\n",
      "\n",
      "**Key Considerations:**\n",
      "\n",
      "*   **Global Collaboration:**  AI development is a global endeavor. The ethical framework should be developed and implemented in collaboration with international organizations and stakeholders. Harmonization of ethical standards across different countries is crucial.\n",
      "*   **Dynamic Adaptation:**  The framework should be flexible and adaptable to address new challenges and opportunities as AI technology evolves. Regular reviews and updates are essential.\n",
      "*   **Enforcement Mechanisms:**  The framework needs to be backed by effective enforcement mechanisms, including legal and regulatory sanctions, to ensure compliance.\n",
      "\n",
      "By implementing this framework, we can strive to harness the immense potential of AI while mitigating its risks and ensuring that it serves humanity's best interests. The key is to foster a culture of ethical awareness, responsibility, and continuous learning throughout the AI ecosystem.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Creating a new ethical framework for AI development and application requires balancing innovation with societal well-being while addressing inevitable conflicts between principles. Below is a proposed framework with key principles and conflict-resolution strategies:\n",
      "\n",
      "### **Core Ethical Principles**  \n",
      "1. **Human-Centric Beneficence**  \n",
      "   - AI should prioritize human flourishing, ensuring that its development and deployment enhance well-being, equity, and dignity.  \n",
      "   - *Example:* AI in healthcare should focus on improving patient outcomes rather than just cost-cutting.  \n",
      "\n",
      "2. **Transparency & Explainability**  \n",
      "   - AI systems must be interpretable, with clear accountability for decisions. Users should understand how and why AI reaches conclusions.  \n",
      "   - *Example:* A loan-approval AI should provide reasons for rejections in understandable terms.  \n",
      "\n",
      "3. **Fairness & Non-Discrimination**  \n",
      "   - AI must actively mitigate biases in data and decision-making to prevent harm to marginalized groups.  \n",
      "   - *Example:* Facial recognition should be rigorously audited for racial/gender bias.  \n",
      "\n",
      "4. **Privacy & Autonomy**  \n",
      "   - AI should respect individual privacy, with strict data governance and user consent. People should retain control over their personal data.  \n",
      "   - *Example:* AI-driven surveillance should have legal safeguards against misuse.  \n",
      "\n",
      "5. **Robustness & Safety**  \n",
      "   - AI systems must be secure, reliable, and fail-safe to prevent unintended harm.  \n",
      "   - *Example:* Autonomous vehicles must have rigorous safety testing before deployment.  \n",
      "\n",
      "6. **Sustainability**  \n",
      "   - AI development should minimize environmental impact and support long-term ecological balance.  \n",
      "   - *Example:* Energy-efficient AI models should be prioritized over computationally wasteful ones.  \n",
      "\n",
      "7. **Democratic Governance & Accountability**  \n",
      "   - AI regulation should involve diverse stakeholders (governments, industry, civil society) to prevent monopolization and misuse.  \n",
      "   - *Example:* Public oversight boards for AI in policing.  \n",
      "\n",
      "### **Addressing Conflicts Between Principles**  \n",
      "1. **Innovation vs. Safety**  \n",
      "   - *Resolution:* Implement staged deployment (e.g., sandbox testing) where AI is rigorously evaluated before scaling.  \n",
      "\n",
      "2. **Privacy vs. Public Benefit**  \n",
      "   - *Resolution:* Use privacy-preserving techniques (e.g., federated learning, differential privacy) when AI requires sensitive data.  \n",
      "\n",
      "3. **Autonomy vs. Fairness**  \n",
      "   - *Resolution:* Allow opt-outs for AI decisions (e.g., human override in hiring algorithms) while ensuring fairness in defaults.  \n",
      "\n",
      "4. **Corporate Profit vs. Societal Good**  \n",
      "   - *Resolution:* Incentivize ethical AI through tax benefits for responsible deployments and penalties for harmful uses.  \n",
      "\n",
      "### **Implementation Mechanisms**  \n",
      "- **Ethical Impact Assessments (EIAs):** Mandatory audits before AI deployment.  \n",
      "- **Multi-Stakeholder Oversight:** Independent ethics boards with public representation.  \n",
      "- **Adaptive Regulation:** Policies that evolve with AI advancements.  \n",
      "\n",
      "### **Conclusion**  \n",
      "This framework seeks to foster innovation while safeguarding human rights and societal welfare. By embedding flexibility and accountability, it can adapt to emerging challenges while minimizing harm.  \n",
      "\n",
      "Would you refine any of these principles or suggest additional considerations?\n",
      "\n",
      "# Response from competitor 5\n",
      "\n",
      "If I could create a new ethical framework for the development and application of artificial intelligence (AI), I would include the following key principles to balance innovation with societal well-being:\n",
      "\n",
      "**Principles:**\n",
      "\n",
      "1. **Responsible Innovation**: Encourage innovation while ensuring that AI development is guided by human values, social norms, and ethical considerations.\n",
      "2. **Transparency and Explainability**: Ensure that AI systems are transparent, explainable, and accountable, enabling users to understand how decisions are made and to trust the technology.\n",
      "3. **Human-Centered Design**: Develop AI systems that prioritize human well-being, dignity, and safety, and that are designed to augment human capabilities rather than replace them.\n",
      "4. **Data Protection and Privacy**: Establish robust data protection and privacy protocols to safeguard personal and sensitive information, and to prevent AI systems from perpetuating biases and discrimination.\n",
      "5. **Fairness, Equity, and Non-Discrimination**: Ensure that AI systems are fair, equitable, and free from biases, and that they do not perpetuate existing social and economic inequalities.\n",
      "6. **Accountability and Liability**: Establish clear lines of accountability and liability for AI-related decisions and actions, and provide mechanisms for redress and compensation in cases of harm or injury.\n",
      "7. **Environmental Sustainability**: Consider the environmental impacts of AI development and deployment, and strive to minimize waste, energy consumption, and e-waste generation.\n",
      "8. **Human Rights and Social Justice**: Ensure that AI systems respect and promote human rights, social justice, and the well-being of all individuals and communities, regardless of their background, culture, or socioeconomic status.\n",
      "9. **Continuous Monitoring and Evaluation**: Regularly monitor and evaluate AI systems to identify and mitigate potential risks, and to ensure that they remain aligned with human values and societal well-being.\n",
      "10. **Education, Awareness, and Literacy**: Foster education, awareness, and literacy about AI and its impacts, to empower individuals and communities to make informed decisions about AI adoption and use.\n",
      "\n",
      "**Addressing Conflicts:**\n",
      "\n",
      "To address potential conflicts between these principles, I would propose the following framework:\n",
      "\n",
      "1. **Principles Hierarchy**: Establish a hierarchy of principles, with human well-being and safety at the top, followed by transparency, accountability, and fairness, and then by principles related to innovation, environmental sustainability, and education.\n",
      "2. **Context-Dependent Balancing**: Balance competing principles in a context-dependent manner, taking into account the specific application, industry, or societal context in which the AI system is being developed or deployed.\n",
      "3. **Stakeholder Engagement**: Engage with diverse stakeholders, including experts, policymakers, civil society organizations, and affected communities, to ensure that AI development and deployment are inclusive, participatory, and responsive to societal needs and concerns.\n",
      "4. **Case-Based Reasoning**: Use case-based reasoning and scenario planning to identify potential conflicts and trade-offs between principles, and to develop context-specific guidelines and regulations.\n",
      "5. **Iterative Review and Revision**: Regularly review and revise the ethical framework to ensure that it remains relevant, effective, and aligned with evolving societal values and technological advancements.\n",
      "6. **Independent Review and Oversight**: Establish independent review and oversight mechanisms to ensure that AI development and deployment are subject to rigorous scrutiny and evaluation, and that principles are enforced in practice.\n",
      "7. **International Cooperation**: Foster international cooperation and collaboration to develop shared standards, guidelines, and regulatory frameworks for AI development and deployment, and to promote global consistency and harmonization.\n",
      "\n",
      "**Implementation:**\n",
      "\n",
      "To implement this ethical framework, I would propose the following steps:\n",
      "\n",
      "1. **Develop Guidelines and Regulations**: Develop guidelines, regulations, and standards for AI development and deployment, based on the principles outlined above.\n",
      "2. **Establish Oversight Mechanisms**: Establish independent oversight mechanisms, such as ethics review boards, to ensure that AI development and deployment comply with the principles and guidelines.\n",
      "3. **Provide Education and Training**: Provide education and training programs for AI developers, users, and stakeholders, to promote awareness, understanding, and literacy about AI and its impacts.\n",
      "4. **Support Research and Development**: Support research and development of AI systems that prioritize human well-being, safety, and dignity, and that are designed to address societal challenges and needs.\n",
      "5. **Facilitate Public Engagement**: Facilitate public engagement, participation, and debate about AI development and deployment, to ensure that societal concerns and values are taken into account.\n",
      "\n",
      "By following this framework, we can create a more ethical, responsible, and human-centered approach to AI development and deployment, one that balances innovation with societal well-being and promotes a future where AI is used for the betterment of humanity.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
