{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"deepseek/DeepSeek-V3-0324\"\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"meta/Llama-4-Scout-17B-16E-Instruct\"\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-5\"\n",
    "token = os.environ[\"GITHUB_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-or-v\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins ghp\n",
      "Groq API Key exists and begins gith\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you approach the task of reconciling conflicting cultural values when addressing a global ethical dilemma, and what frameworks would you utilize to ensure a balanced perspective?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a system that balances the ethical implications of AI decision-making with the need for efficiency and objectivity in critical areas like healthcare and criminal justice requires a multifaceted approach. Here’s a framework for establishing such a system:\n",
       "\n",
       "### 1. **Establish Ethical Principles**\n",
       "   - **Transparency**: Ensure that AI algorithms are transparent and that stakeholders can understand how decisions are made.\n",
       "   - **Accountability**: Define clear lines of accountability for AI decisions. Who is responsible when an AI system makes a mistake?\n",
       "   - **Fairness**: Minimize bias in the algorithm's outputs. Use diverse datasets to train AI and regularly test for fairness across different demographics.\n",
       "   - **Beneficence**: Prioritize the welfare of individuals affected by AI decisions, particularly vulnerable populations in healthcare and criminal justice.\n",
       "   - **Informed Consent**: In healthcare settings, ensure that patients are informed about the use of AI tools and give consent for their implementation in decision-making processes.\n",
       "\n",
       "### 2. **Stakeholder Engagement**\n",
       "   - **Diverse Perspectives**: Involve a wide range of stakeholders, including ethicists, community representatives, legal experts, healthcare professionals, and criminal justice advocates, in the design and deployment of AI systems.\n",
       "   - **Public Consultation**: Conduct public engagement activities to gather input and understand societal values and concerns regarding AI use in sensitive contexts.\n",
       "\n",
       "### 3. **Interdisciplinary Approach**\n",
       "   - **Collaboration**: Create collaborative structures between developers, ethicists, domain experts (e.g., healthcare providers or legal professionals), and sociologists to ensure a comprehensive understanding of the implications of AI.\n",
       "   - **Continuous Learning**: Implement ongoing research initiatives to assess the impact of AI decisions and ensure that the system adapts to new findings or societal changes.\n",
       "\n",
       "### 4. **Robust Data Management**\n",
       "   - **Quality of Data**: Ensure that the data used for training AI systems is high-quality, representative, and inclusive, avoiding historical biases that could perpetuate discrimination.\n",
       "   - **Data Governance**: Establish strict data governance policies that protect privacy and ensure ethical data use, especially when dealing with sensitive information.\n",
       "\n",
       "### 5. **Algorithmic Design and Testing**\n",
       "   - **Bayesian Approaches**: Use probabilistic models that allow for uncertainty and can adapt over time as more data is collected.\n",
       "   - **Simulation and Testing**: Rigorously test AI systems in controlled environments to evaluate potential biases, unintended consequences, and their generalizability before real-world deployment.\n",
       "\n",
       "### 6. **Iterative Feedback Mechanism**\n",
       "   - **Real-Time Monitoring**: Implement monitoring systems to track AI performance and outcomes continuously, allowing for real-time adjustments and error correction.\n",
       "   - **Feedback Loops**: Create mechanisms for users to provide feedback about the AI’s recommendations to improve the system.\n",
       "\n",
       "### 7. **Legal and Regulatory Framework**\n",
       "   - **Compliance**: Ensure that AI systems comply with existing laws and regulations in healthcare and criminal justice while advocating for updates in legislation to address gaps around AI use.\n",
       "   - **Ethics Review Committees**: Establish independent ethics boards that review AI systems and their deployment in critical sectors.\n",
       "\n",
       "### 8. **Education and Training**\n",
       "   - **Training Programs**: Develop educational programs for professionals in healthcare and criminal justice focused on understanding AI technologies, their strengths, limitations, and ethical considerations.\n",
       "   - **Empowerment**: Equip practitioners with the tools and understanding necessary to interpret AI outputs and make informed decisions.\n",
       "\n",
       "### 9. **Public Awareness Campaigns**\n",
       "   - **Information Dissemination**: Create initiatives to raise public awareness about the role of AI in these sectors, fostering an informed discussion about its benefits and risks.\n",
       "   - **Trust Building**: Work to build public trust through transparent practices, accountability, and clearly communicated values.\n",
       "\n",
       "### Conclusion\n",
       "This framework outlines a proactive and structured approach to designing an AI decision-making system that balances ethical considerations with efficiency. By fostering transparency, accountability, stakeholder engagement, and continuous evaluations, we can work towards fostering trust and ensuring that AI serves to enhance, rather than undermine, the moral imperatives of the healthcare and criminal justice systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'd approach this complex challenge through several complementary frameworks:\n",
       "\n",
       "## Multi-layered Analysis Framework\n",
       "\n",
       "**1. Identify Core vs. Surface Values**\n",
       "- Distinguish between fundamental human needs (dignity, safety, autonomy) and their cultural expressions\n",
       "- Look for shared underlying concerns that manifest differently across cultures\n",
       "- Map where conflicts are truly irreconcilable vs. where they reflect different paths to similar goals\n",
       "\n",
       "**2. Stakeholder Inclusion Process**\n",
       "- Engage representatives from affected communities early and meaningfully\n",
       "- Create space for cultures to articulate their own values rather than having them interpreted by others\n",
       "- Use culturally appropriate dialogue methods\n",
       "\n",
       "## Philosophical Frameworks\n",
       "\n",
       "**Principlist Approach**: Balance competing principles (autonomy, beneficence, justice, non-maleficence) while recognizing their cultural interpretations vary\n",
       "\n",
       "**Capabilities Approach**: Focus on what enables human flourishing across cultures - education, health, political participation - while allowing diverse paths to achieve these\n",
       "\n",
       "**Contextual Ethics**: Acknowledge that universal principles may require culturally sensitive applications\n",
       "\n",
       "## Practical Methods\n",
       "\n",
       "- **Overlapping Consensus**: Seek solutions different cultures can support for their own reasons\n",
       "- **Procedural Justice**: When substantive agreement is impossible, focus on fair, inclusive decision-making processes\n",
       "- **Graduated Implementation**: Allow for regional variations within broader ethical frameworks\n",
       "\n",
       "The goal isn't forcing uniformity but finding workable approaches that respect core human dignity while honoring meaningful cultural differences. What specific dilemma did you have in mind?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m display(Markdown(answer))\n\u001b[32m     22\u001b[39m competitors.append(model_name)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43manswer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m(answer)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "# model_name = \"gpt-4o-mini\"\n",
    "\n",
    "# response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n",
    "\n",
    "\n",
    "\n",
    "claude = OpenAI(api_key=anthropic_api_key, base_url=\"https://openrouter.ai/api/v1\")\n",
    "model_name=\"anthropic/claude-sonnet-4\"\n",
    "\n",
    "response = claude.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answer.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Balancing the ethical implications of AI decision-making with efficiency and objectivity in critical areas like healthcare and criminal justice requires a multi-faceted approach, incorporating both technological and societal safeguards.  Here's a design outlining the key components:\n",
       "\n",
       "**I. Core Principles and Framework:**\n",
       "\n",
       "*   **Transparency and Explainability:**  AI models should be understandable, allowing users to comprehend the reasoning behind decisions. Prioritize explainable AI (XAI) techniques.\n",
       "*   **Fairness and Non-discrimination:**  Actively combat bias in data, algorithms, and outcomes.  Implement fairness metrics and audit for disparate impact on protected groups.\n",
       "*   **Accountability and Auditability:**  Establish clear lines of responsibility for AI system design, deployment, and outcomes.  Maintain detailed logs of decisions and data usage for auditing purposes.\n",
       "*   **Human Oversight and Control:**  Maintain a 'human-in-the-loop' or 'human-on-the-loop' approach for critical decisions. AI should augment, not replace, human judgment, particularly where significant consequences are involved.  Users should have the ability to override AI decisions based on ethical or contextual considerations.\n",
       "*   **Data Privacy and Security:**  Protect sensitive data used in AI systems, adhering to privacy regulations like GDPR and HIPAA. Employ robust security measures to prevent unauthorized access and misuse.\n",
       "*   **Beneficence and Non-maleficence:**  Ensure AI systems are designed to benefit individuals and society while minimizing potential harm.  Regularly assess and mitigate risks associated with AI deployment.\n",
       "*   **Continuous Monitoring and Evaluation:**  Implement ongoing monitoring of AI system performance, fairness, and ethical implications. Adapt and improve the system based on feedback and evolving societal norms.\n",
       "\n",
       "**II. System Components:**\n",
       "\n",
       "1.  **Data Management and Bias Mitigation:**\n",
       "\n",
       "    *   **Diverse and Representative Datasets:** Actively seek and curate datasets that accurately reflect the population affected by the AI system.\n",
       "    *   **Bias Detection and Mitigation Tools:** Employ tools to identify and mitigate bias in data, algorithms, and outcomes. This includes techniques like re-weighting data, adversarial debiasing, and fairness-aware machine learning.\n",
       "    *   **Data Auditing and Validation:**  Establish rigorous data auditing processes to ensure data quality, accuracy, and completeness. Regularly validate data sources to identify and correct errors or inconsistencies.\n",
       "    *   **Data Anonymization and De-identification:** Implement robust anonymization techniques to protect sensitive patient or individual data while still enabling meaningful analysis.\n",
       "\n",
       "2.  **AI Model Development and Deployment:**\n",
       "\n",
       "    *   **XAI Techniques:** Prioritize the use of explainable AI (XAI) techniques to provide transparency into the model's decision-making process. Examples include LIME, SHAP, and attention mechanisms.\n",
       "    *   **Model Validation and Testing:** Conduct rigorous testing and validation of AI models using diverse datasets and scenarios to assess their accuracy, robustness, and fairness.\n",
       "    *   **Fairness Metrics:** Incorporate fairness metrics into the model evaluation process to identify and address potential biases. Examples include demographic parity, equal opportunity, and predictive parity.\n",
       "    *   **Modular and Auditable Architecture:** Design the AI system with a modular architecture that allows for easy auditing and modification of individual components.\n",
       "    *   **Version Control and Model Governance:** Implement a robust version control system to track changes to the AI model and data, ensuring accountability and reproducibility.\n",
       "    *   **'Human-in-the-Loop' Integration:**  Develop interfaces that seamlessly integrate AI-generated recommendations with human decision-making processes.\n",
       "    *   **Alerting and Monitoring Systems:**  Implement real-time monitoring systems that detect anomalies, biases, or unexpected behavior in the AI system.\n",
       "\n",
       "3.  **Human Oversight and Governance:**\n",
       "\n",
       "    *   **Ethics Review Boards:** Establish ethics review boards comprised of experts in AI, ethics, law, and relevant domain knowledge (e.g., healthcare, criminal justice). These boards would review AI system designs, deployment plans, and ongoing performance.\n",
       "    *   **Clear Roles and Responsibilities:** Define clear roles and responsibilities for individuals involved in the AI system lifecycle, including developers, data scientists, ethicists, domain experts, and end-users.\n",
       "    *   **Training and Education:** Provide comprehensive training to all stakeholders on the ethical implications of AI, data privacy, and responsible AI practices.\n",
       "    *   **Feedback Mechanisms:** Establish mechanisms for individuals affected by AI decisions to provide feedback and challenge outcomes.\n",
       "    *   **Appeal Processes:**  Develop clear and accessible appeal processes for individuals who believe they have been unfairly treated by an AI system.\n",
       "    *   **Regulatory Frameworks:** Advocate for the development of clear and consistent regulatory frameworks for AI deployment in critical areas, addressing issues such as bias, transparency, accountability, and data privacy.\n",
       "\n",
       "4.  **Technology Infrastructure:**\n",
       "\n",
       "    *   **Secure Data Storage and Processing:** Implement secure data storage and processing infrastructure to protect sensitive data from unauthorized access and breaches.\n",
       "    *   **Auditing and Logging Capabilities:**  Develop robust auditing and logging capabilities to track all AI system activity, including data access, model updates, and decision-making processes.\n",
       "    *   **API Integration:** Design APIs that allow for seamless integration with existing healthcare or criminal justice systems.\n",
       "    *   **Scalability and Reliability:**  Ensure that the AI system is scalable and reliable to meet the demands of real-world deployment.\n",
       "\n",
       "**III.  Specific Considerations for Healthcare and Criminal Justice:**\n",
       "\n",
       "*   **Healthcare:**\n",
       "    *   Prioritize patient autonomy and informed consent.  Explain AI-driven diagnoses and treatment recommendations clearly to patients.\n",
       "    *   Address concerns about job displacement among healthcare professionals.  Focus on AI as a tool to augment, not replace, human expertise.\n",
       "    *   Ensure AI systems are used to improve access to healthcare for underserved populations.\n",
       "*   **Criminal Justice:**\n",
       "    *   Be extremely cautious about using AI for predictive policing or risk assessment, given the potential for perpetuating existing biases in the criminal justice system.\n",
       "    *   Focus on using AI to improve the accuracy and fairness of forensic analysis and evidence processing.\n",
       "    *   Ensure transparency and accountability in the use of AI for sentencing recommendations and parole decisions.\n",
       "\n",
       "**IV. Ongoing Monitoring and Improvement:**\n",
       "\n",
       "*   **Regular Audits:** Conduct regular audits of AI system performance, fairness, and ethical implications.\n",
       "*   **Feedback Loops:**  Establish feedback loops to continuously improve the AI system based on user feedback and real-world experience.\n",
       "*   **Adaptive Learning:**  Implement adaptive learning techniques to allow the AI system to learn from its mistakes and improve its performance over time.\n",
       "*   **Staying Current with Research:**  Stay abreast of the latest research and developments in AI ethics, fairness, and transparency, and incorporate these advances into the AI system.\n",
       "\n",
       "**Challenges:**\n",
       "\n",
       "*   **Defining and Measuring Fairness:** Fairness is a complex and multifaceted concept, and there is no single definition that is universally accepted.\n",
       "*   **Balancing Accuracy and Explainability:** Explainable AI techniques can sometimes sacrifice accuracy.\n",
       "*   **Maintaining Data Privacy:** Striking the right balance between data privacy and the need for data to train and improve AI models is a challenge.\n",
       "*   **Addressing Unforeseen Consequences:** AI systems can sometimes produce unexpected and unintended consequences.\n",
       "*   **Evolving Societal Norms:** Ethical standards and societal norms are constantly evolving, which requires ongoing monitoring and adaptation of AI systems.\n",
       "\n",
       "By implementing these components and continually evaluating the system's impact, we can strive to harness the power of AI for good while mitigating its potential risks and ensuring that it serves the best interests of individuals and society. This requires a collaborative effort involving AI developers, ethicists, policymakers, and the communities most affected by AI decisions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "# model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "# response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n",
    "\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a system to balance ethical AI decision-making with efficiency and objectivity in critical domains like healthcare and criminal justice requires a multidisciplinary approach. Below is a structured framework to achieve this balance:\n",
       "\n",
       "### **1. Foundational Ethical Principles**\n",
       "- **Transparency**: Ensure AI decision-making processes are explainable (e.g., using interpretable models like decision trees or SHAP/LIME for black-box models).  \n",
       "- **Fairness**: Mitigate biases by auditing datasets, using fairness-aware algorithms, and ensuring diverse representation in training data.  \n",
       "- **Accountability**: Assign clear responsibility for AI decisions (human-in-the-loop oversight).  \n",
       "- **Privacy & Consent**: Comply with regulations (e.g., GDPR, HIPAA) and ensure data anonymization where applicable.  \n",
       "- **Non-Maleficence**: Implement safeguards to prevent harm (e.g., fail-safes in medical diagnosis AI).  \n",
       "\n",
       "### **2. System Design Components**\n",
       "#### **A. Data & Model Development**\n",
       "- **Bias Detection & Mitigation**  \n",
       "  - Use fairness metrics (e.g., demographic parity, equalized odds).  \n",
       "  - Employ adversarial debiasing or reweighting techniques.  \n",
       "- **High-Quality, Representative Data**  \n",
       "  - Ensure datasets reflect diverse populations (e.g., racial, socioeconomic).  \n",
       "  - Continuously audit for drift or emerging biases.  \n",
       "\n",
       "#### **B. Decision-Making Process**\n",
       "- **Human-AI Collaboration**  \n",
       "  - **Healthcare**: AI for diagnostics (e.g., radiology) but require clinician validation.  \n",
       "  - **Criminal Justice**: Use risk assessment tools (e.g., COMPAS) with judicial oversight.  \n",
       "- **Explainability**  \n",
       "  - Provide clear reasoning (e.g., \"Patient flagged due to X symptoms matching Y condition with 85% confidence\").  \n",
       "  - Avoid opaque \"black boxes\" in high-stakes decisions.  \n",
       "\n",
       "#### **C. Governance & Compliance**\n",
       "- **Ethics Review Boards**  \n",
       "  - Include ethicists, domain experts, and community representatives.  \n",
       "  - Conduct impact assessments before deployment.  \n",
       "- **Regulatory Alignment**  \n",
       "  - Follow sector-specific guidelines (e.g., FDA for healthcare AI, ACLU recommendations for criminal justice).  \n",
       "- **Audit Trails**  \n",
       "  - Log all AI decisions for retrospective review.  \n",
       "\n",
       "### **3. Continuous Monitoring & Feedback**\n",
       "- **Real-World Performance Tracking**  \n",
       "  - Monitor for disparities (e.g., higher false positives in certain demographics).  \n",
       "- **Feedback Loops**  \n",
       "  - Allow end-users (doctors, judges) to contest or correct AI outputs.  \n",
       "- **Iterative Improvement**  \n",
       "  - Update models based on new data and ethical insights.  \n",
       "\n",
       "### **4. Public Trust & Stakeholder Engagement**\n",
       "- **Community Involvement**  \n",
       "  - Engage affected groups (e.g., patients, marginalized communities) in design.  \n",
       "- **Transparency Reports**  \n",
       "  - Publish performance metrics and bias audits.  \n",
       "\n",
       "### **Example Implementations**\n",
       "- **Healthcare**: IBM Watson for Oncology (with physician validation).  \n",
       "- **Criminal Justice**: Risk assessment tools with judicial discretion (avoiding sole reliance on AI).  \n",
       "\n",
       "### **Challenges & Mitigations**\n",
       "- **Efficiency vs. Ethics Trade-offs**: Optimize for \"sufficient\" explainability (e.g., simpler models where possible).  \n",
       "- **Adversarial Attacks**: Secure models against manipulation (e.g., in forensic AI).  \n",
       "\n",
       "### **Conclusion**\n",
       "A balanced AI system for critical domains must prioritize ethical safeguards without sacrificing utility. By combining **technical rigor (fairness-aware algorithms), human oversight, and robust governance**, we can achieve **objective yet morally sound outcomes**.  \n",
       "\n",
       "Would you like a deeper dive into any specific component (e.g., bias mitigation techniques or regulatory frameworks)?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "# model_name = \"deepseek-chat\"\n",
    "\n",
    "# response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n",
    "\n",
    "# endpoint = \"https://models.github.ai/inference\"\n",
    "# model = \"deepseek/DeepSeek-V3-0324\"\n",
    "\n",
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://models.github.ai/inference\")\n",
    "model_name = \"deepseek/DeepSeek-V3-0324\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a system to balance the ethical implications of AI decision-making with the need for efficient and objective outcomes in critical areas such as healthcare and criminal justice requires a multi-faceted approach. Here's a comprehensive framework to achieve this balance:\n",
       "\n",
       "**Principles**\n",
       "\n",
       "1. **Transparency**: Ensure that AI decision-making processes are transparent, explainable, and auditable.\n",
       "2. **Accountability**: Establish clear accountability mechanisms for AI-driven decisions.\n",
       "3. **Fairness**: Implement fairness and bias-detection mechanisms to prevent discriminatory outcomes.\n",
       "4. **Human Oversight**: Involve human experts in the decision-making process to review and correct AI-driven decisions.\n",
       "5. **Continuous Evaluation**: Regularly assess and update AI systems to ensure they remain aligned with societal values and norms.\n",
       "\n",
       "**System Components**\n",
       "\n",
       "1. **Data Curation**: Ensure that datasets used for AI training are diverse, representative, and free from bias.\n",
       "2. **Algorithmic Auditing**: Regularly audit AI algorithms for bias, fairness, and transparency.\n",
       "3. **Explainability Mechanisms**: Implement techniques such as model interpretability, feature attribution, and model-agnostic explanations to provide insights into AI-driven decisions.\n",
       "4. **Human-in-the-Loop**: Involve human experts in the decision-making process to review and correct AI-driven decisions.\n",
       "5. **Feedback Mechanisms**: Establish feedback loops to collect data on AI-driven decisions and their outcomes, enabling continuous evaluation and improvement.\n",
       "\n",
       "**Healthcare-Specific Considerations**\n",
       "\n",
       "1. **Clinical Validation**: Validate AI-driven decisions against established clinical guidelines and outcomes.\n",
       "2. **Patient-Centered Care**: Ensure that AI systems prioritize patient-centered care and respect patient autonomy.\n",
       "3. **Medical Liability**: Establish clear guidelines for medical liability in AI-driven decision-making.\n",
       "\n",
       "**Criminal Justice-Specific Considerations**\n",
       "\n",
       "1. **Due Process**: Ensure that AI-driven decisions in criminal justice adhere to due process principles.\n",
       "2. **Bias Detection**: Implement bias-detection mechanisms to prevent discriminatory outcomes in AI-driven decision-making.\n",
       "3. **Transparency in Sentencing**: Provide transparent explanations for AI-driven sentencing recommendations.\n",
       "\n",
       "**Implementation Roadmap**\n",
       "\n",
       "1. **Establish an Ethics Committee**: Form a committee to oversee AI development and deployment, comprising experts from diverse fields.\n",
       "2. **Develop and Deploy AI Systems**: Develop and deploy AI systems that incorporate the principles and components outlined above.\n",
       "3. **Monitor and Evaluate**: Continuously monitor and evaluate AI systems, making adjustments as needed to ensure they remain aligned with societal values and norms.\n",
       "4. **Foster Collaboration**: Encourage collaboration between AI developers, domain experts, and stakeholders to ensure that AI systems meet the needs of critical areas like healthcare and criminal justice.\n",
       "\n",
       "**Challenges and Limitations**\n",
       "\n",
       "1. **Complexity**: AI systems can be complex and difficult to interpret, making it challenging to ensure transparency and accountability.\n",
       "2. **Data Quality**: AI systems are only as good as the data they're trained on, which can be a challenge in areas with limited or biased data.\n",
       "3. **Regulatory Frameworks**: Existing regulatory frameworks may not be equipped to handle the unique challenges posed by AI decision-making.\n",
       "\n",
       "By following this framework, we can design AI systems that balance the need for efficient and objective outcomes with the need to address ethical implications in critical areas like healthcare and criminal justice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "# model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n",
    "\n",
    "# endpoint = \"https://models.github.ai/inference\"\n",
    "# model = \"meta/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://models.github.ai/inference\")\n",
    "model_name = \"meta/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ollama' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ollama = \u001b[43mOpenAI\u001b[49m(base_url=\u001b[33m'\u001b[39m\u001b[33mhttp://localhost:11434/v1\u001b[39m\u001b[33m'\u001b[39m, api_key=\u001b[33m'\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mllama3.2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
      "\u001b[31mNameError\u001b[39m: name 'OpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
