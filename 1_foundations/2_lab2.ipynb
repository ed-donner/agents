{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key exists and begins sk-\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'groq_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDeepSeek API Key not set (and this is optional)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mgroq_api_key\u001b[49m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGroq API Key exists and begins \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgroq_api_key[:\u001b[32m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'groq_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you were tasked with designing a new ethical framework for artificial intelligence that balances innovation and societal well-being, what key principles would you prioritize, and how would you address potential conflicts between those principles?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Designing a new ethical framework for artificial intelligence (AI) that balances innovation with societal well-being is a complex challenge. Here are key principles I would prioritize and strategies to address potential conflicts:\n",
       "\n",
       "### Key Principles\n",
       "\n",
       "1. **Transparency**:\n",
       "   - **Goal**: Ensure AI systems are understandable and their operations are explainable to users and stakeholders.\n",
       "   - **Implementation**: Require clear documentation of AI decision-making processes and make algorithms interpretable without needing specialized knowledge.\n",
       "\n",
       "2. **Accountability**:\n",
       "   - **Goal**: Hold developers and organizations responsible for the outcomes of AI systems.\n",
       "   - **Implementation**: Establish legal frameworks that outline liability for harm caused by AI, ensuring there are consequences for both negligent and intentional misuse.\n",
       "\n",
       "3. **Fairness and Non-discrimination**:\n",
       "   - **Goal**: Prevent bias and ensure equitable treatment across diverse populations.\n",
       "   - **Implementation**: Introduce auditing and testing protocols to identify and mitigate biases in data and algorithms, alongside diverse development teams.\n",
       "\n",
       "4. **Privacy and Data Protection**:\n",
       "   - **Goal**: Safeguard personal information and respect individuals' rights to control their data.\n",
       "   - **Implementation**: Adhere to strict data governance policies, implement data anonymization techniques, and provide users with clear options for consent and data access.\n",
       "\n",
       "5. **Safety and Security**:\n",
       "   - **Goal**: Ensure that AI systems are safe from malicious use and function correctly under various conditions.\n",
       "   - **Implementation**: Adopt rigorous testing, verification, and validation procedures before deployment, alongside proactive measures against cybersecurity threats.\n",
       "\n",
       "6. **Human-Centric Design**:\n",
       "   - **Goal**: Prioritize user needs and societal impact in AI development.\n",
       "   - **Implementation**: Engage stakeholders in the design process and conduct impact assessments to anticipate societal implications.\n",
       "\n",
       "7. **Sustainability**:\n",
       "   - **Goal**: Ensure that AI technologies contribute positively to environmental and societal sustainability.\n",
       "   - **Implementation**: Encourage development practices that consider the environmental impact of data centers and resource usage, promoting energy-efficient algorithms.\n",
       "\n",
       "8. **Collaboration and Inclusiveness**:\n",
       "   - **Goal**: Foster a cooperative environment among all stakeholders, including industry, government, and civil society.\n",
       "   - **Implementation**: Create platforms for dialogue and cross-sector collaboration to share knowledge, best practices, and standards in AI development.\n",
       "\n",
       "### Addressing Conflicts Between Principles\n",
       "\n",
       "When conflicts arise between these principles, the following strategies can be employed:\n",
       "\n",
       "1. **Stakeholder Engagement**:\n",
       "   - Regularly consult with diverse stakeholders, including marginalized communities, to evaluate the potential impact of trade-offs. For instance, if transparency risks exposing sensitive data, engage stakeholders in balancing transparency with privacy measures.\n",
       "\n",
       "2. **Prioritization Framework**:\n",
       "   - Develop a framework for evaluating and prioritizing principles based on context, impact, and societal norms. This framework should allow flexibility to adapt to different scenarios while maintaining core ethical commitments.\n",
       "\n",
       "3. **Iterative Design and Regulation**:\n",
       "   - Implement an iterative approach where AI systems are continuously monitored and assessed post-deployment, allowing for adjustments to balance conflicting principles as new information arises.\n",
       "\n",
       "4. **Ethics Committees**:\n",
       "   - Establish ethics committees or boards that include diverse representation to weigh in on conflicts and guide decision-making with a holistic view of the impacts on society.\n",
       "\n",
       "5. **Educational Initiatives**:\n",
       "   - Promote understanding of ethical AI principles among developers and users to cultivate an ethical culture in the AI ecosystem. This can help balance innovation with ethical considerations by fostering a system of shared responsibility.\n",
       "\n",
       "6. **Conformance and Compliance Checks**:\n",
       "   - Regular audits and assessments to ensure AI systems adhere to ethical principles and allow for corrective actions when conflicts are identified.\n",
       "\n",
       "By prioritizing these key principles and employing structured strategies to manage conflicts, a balanced ethical framework for AI can be created, promoting innovation while safeguarding societal well-being."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Designing an Ethical Framework for AI\n",
       "\n",
       "## Core Principles I Would Prioritize\n",
       "\n",
       "1. **Human Flourishing**: AI systems should ultimately enhance human dignity, autonomy, and well-being across diverse populations\n",
       "\n",
       "2. **Distributive Justice**: Benefits and risks should be fairly distributed, with special attention to marginalized communities\n",
       "\n",
       "3. **Transparency and Explainability**: AI decision processes should be interpretable to appropriate stakeholders\n",
       "\n",
       "4. **Accountability**: Clear lines of responsibility for AI outcomes must exist, with meaningful oversight mechanisms\n",
       "\n",
       "5. **Safety and Robustness**: Systems should be designed to prevent foreseeable harms and withstand adversarial scenarios\n",
       "\n",
       "## Addressing Conflicts Between Principles\n",
       "\n",
       "When principles conflict, I would implement:\n",
       "\n",
       "- **Contextual Assessment**: Recognize that principle priorities may shift based on domain (healthcare vs. entertainment) and risk level\n",
       "\n",
       "- **Deliberative Processes**: Include diverse stakeholders, especially those most affected, in formulating compromises\n",
       "\n",
       "- **Graduated Responsibility**: Apply stricter ethical requirements as potential impact increases\n",
       "\n",
       "- **Continuous Reassessment**: Build feedback mechanisms to evaluate outcomes and adjust ethical frameworks accordingly\n",
       "\n",
       "The most challenging tension is often between innovation and precaution. This requires both thoughtful governance structures and maintaining space for responsible development."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, this is a fascinating challenge! Designing an ethical framework for AI requires careful consideration of numerous complex factors. Here's my proposed framework, prioritizing key principles and outlining strategies to address potential conflicts:\n",
       "\n",
       "**I. Core Principles:**\n",
       "\n",
       "1.  **Human-Centricity:**\n",
       "    *   **Definition:** AI systems should be designed, developed, and deployed with the primary goal of benefiting humanity and improving the quality of life. Human autonomy, dignity, and well-being should be central considerations.\n",
       "    *   **Operationalization:**  This means prioritizing AI applications that address pressing societal challenges (e.g., healthcare, climate change, education) and avoiding applications that could lead to mass unemployment, social division, or the erosion of fundamental rights. It also means ensuring that humans remain in control and accountable for critical decisions made by AI.  Transparency and explainability are crucial for enabling human oversight.\n",
       "\n",
       "2.  **Fairness and Justice:**\n",
       "    *   **Definition:** AI systems should be free from bias and discrimination, ensuring equitable outcomes for all individuals and groups.  This includes addressing both historical biases embedded in data and algorithmic biases introduced during development.\n",
       "    *   **Operationalization:**  This requires rigorous testing and auditing of AI systems for bias, particularly in sensitive areas like criminal justice, loan applications, and hiring. It also necessitates diverse and inclusive teams in AI development to ensure that different perspectives are considered and potential biases are identified early on.  Data collection and annotation processes must be carefully scrutinized to minimize bias.  Using fairness-aware algorithms and employing techniques to mitigate bias in existing datasets are also essential.\n",
       "\n",
       "3.  **Transparency and Explainability:**\n",
       "    *   **Definition:** The decision-making processes of AI systems should be understandable and transparent to users, stakeholders, and regulators.  Explainability allows for accountability and builds trust.\n",
       "    *   **Operationalization:**  This involves developing techniques for explaining how AI systems arrive at their decisions, especially for complex machine learning models.  Documenting the design, data sources, and assumptions underlying AI systems is critical.  Providing users with clear and accessible information about how AI systems are used and how their data is being processed is also essential.  Moving beyond \"black box\" models to more interpretable models where appropriate.\n",
       "\n",
       "4.  **Privacy and Data Security:**\n",
       "    *   **Definition:**  AI systems should respect individuals' privacy rights and protect their personal data from unauthorized access, use, or disclosure.\n",
       "    *   **Operationalization:**  Implementing strong data encryption and anonymization techniques is crucial.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and use are also necessary.  Developing AI systems that minimize data requirements (e.g., federated learning, differential privacy) is a promising approach.  Establishing robust security protocols to prevent data breaches and cyberattacks is paramount.\n",
       "\n",
       "5.  **Accountability and Responsibility:**\n",
       "    *   **Definition:**  Clear lines of responsibility and accountability should be established for the design, development, deployment, and use of AI systems.  Mechanisms should be in place to address harms caused by AI systems.\n",
       "    *   **Operationalization:**  This requires defining roles and responsibilities for developers, deployers, and users of AI systems.  Establishing independent oversight bodies to monitor AI development and deployment is important.  Developing mechanisms for redress and compensation for individuals harmed by AI systems is essential.  Establishing ethical review boards to assess the potential risks and benefits of AI projects before they are implemented.\n",
       "\n",
       "6.  **Sustainability and Environmental Responsibility:**\n",
       "    *   **Definition:** AI systems should be developed and deployed in a way that minimizes their environmental impact and contributes to a sustainable future.\n",
       "    *   **Operationalization:**  This involves considering the energy consumption of AI training and deployment.  Developing more energy-efficient AI algorithms and hardware is critical.  Using AI to address environmental challenges (e.g., climate change, pollution) is a promising application.  Promoting the responsible use of natural resources in the development and deployment of AI systems.\n",
       "\n",
       "**II. Addressing Potential Conflicts Between Principles:**\n",
       "\n",
       "Conflicts between these principles are inevitable. Here's how I would approach them:\n",
       "\n",
       "1.  **Prioritization Framework:**\n",
       "    *   **Hierarchy of Values:** While all principles are important, a hierarchy might be necessary in certain situations. Generally, **Human-Centricity** and **Fairness & Justice** should take precedence, as they directly relate to fundamental human rights and well-being.  However, the specific context will heavily influence the appropriate prioritization.\n",
       "    *   **Consequence Analysis:** Carefully analyze the potential consequences of prioritizing one principle over another in a specific situation.  Consider the short-term and long-term impacts on different stakeholders.\n",
       "\n",
       "2.  **Trade-off Analysis and Ethical Deliberation:**\n",
       "    *   **Stakeholder Engagement:** Involve diverse stakeholders (e.g., developers, ethicists, policymakers, affected communities) in the decision-making process.\n",
       "    *   **Ethical Frameworks and Tools:** Utilize established ethical frameworks (e.g., utilitarianism, deontology) to guide decision-making. Employ tools like ethical impact assessments to identify and evaluate potential ethical risks.\n",
       "    *   **Transparency in Trade-offs:** Clearly communicate the trade-offs that were made and the reasons behind them.  Document the decision-making process and the rationale for the chosen course of action.\n",
       "\n",
       "3.  **Context-Specific Application:**\n",
       "    *   **Domain-Specific Guidelines:** Develop specific ethical guidelines for different AI applications (e.g., healthcare AI, autonomous vehicles, facial recognition).  These guidelines should address the unique ethical challenges associated with each domain.\n",
       "    *   **Adaptive Framework:**  Recognize that the ethical framework must be adaptable and evolve as AI technology advances and societal values change.  Regularly review and update the framework based on new knowledge and experience.\n",
       "\n",
       "4.  **Technical Solutions:**\n",
       "    *   **Fairness-Aware Algorithms:**  Employ algorithms that are designed to mitigate bias and promote fairness.\n",
       "    *   **Explainable AI (XAI) Techniques:**  Develop and deploy XAI techniques to make AI decision-making more transparent and understandable.\n",
       "    *   **Privacy-Enhancing Technologies (PETs):**  Utilize PETs to protect individuals' privacy while still enabling the use of AI for beneficial purposes.\n",
       "\n",
       "**Examples of Conflict Resolution:**\n",
       "\n",
       "*   **Innovation vs. Privacy:**  Developing a new AI-powered surveillance system for crime prevention (innovation) might conflict with individuals' privacy rights.  The resolution could involve using privacy-enhancing technologies (e.g., differential privacy) to anonymize data, limiting the scope of surveillance, and establishing strict oversight mechanisms to prevent abuse.\n",
       "*   **Fairness vs. Accuracy:**  An AI system used for loan applications might be more accurate if it considers certain demographic factors, but this could lead to unfair discrimination.  The resolution could involve removing these demographic factors from the model, even if it slightly reduces accuracy, and using fairness-aware algorithms to mitigate bias.\n",
       "*   **Transparency vs. Security:**  Revealing the inner workings of an AI system (transparency) could make it more vulnerable to hacking or manipulation (security).  The resolution could involve providing explanations at a higher level of abstraction, without revealing sensitive details, and implementing robust security measures to protect the system from attack.\n",
       "\n",
       "**III. Implementation and Enforcement:**\n",
       "\n",
       "*   **Multi-Stakeholder Governance:** Establish a multi-stakeholder governance body to oversee the implementation and enforcement of the ethical framework. This body should include representatives from government, industry, academia, civil society, and the public.\n",
       "*   **Auditing and Certification:** Implement auditing and certification processes to ensure that AI systems comply with the ethical framework.\n",
       "*   **Regulatory Frameworks:** Develop appropriate regulatory frameworks to govern the development and deployment of AI systems. These frameworks should be flexible and adaptable to accommodate future technological advancements.\n",
       "*   **Education and Training:** Provide education and training to AI developers, users, and the public on the ethical implications of AI.\n",
       "*   **Public Dialogue:** Foster public dialogue and engagement on the ethical challenges and opportunities presented by AI.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Creating an effective ethical framework for AI is an ongoing process that requires collaboration, continuous learning, and a commitment to human-centricity, fairness, and transparency. This proposed framework, with its prioritized principles and strategies for conflict resolution, provides a foundation for building AI systems that benefit society while mitigating potential harms. It's crucial to remember that this framework is not a static document but rather a living document that must be regularly reviewed and updated to reflect the evolving landscape of AI technology and societal values.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m deepseek = OpenAI(api_key=deepseek_api_key, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.deepseek.com/v1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mdeepseek-chat\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mdeepseek\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/course/agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/course/agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/course/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/course/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}"
     ]
    }
   ],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'claude-3-7-sonnet-latest', 'gemini-2.0-flash']\n",
      "[\"Designing a new ethical framework for artificial intelligence (AI) that balances innovation with societal well-being is a complex challenge. Here are key principles I would prioritize and strategies to address potential conflicts:\\n\\n### Key Principles\\n\\n1. **Transparency**:\\n   - **Goal**: Ensure AI systems are understandable and their operations are explainable to users and stakeholders.\\n   - **Implementation**: Require clear documentation of AI decision-making processes and make algorithms interpretable without needing specialized knowledge.\\n\\n2. **Accountability**:\\n   - **Goal**: Hold developers and organizations responsible for the outcomes of AI systems.\\n   - **Implementation**: Establish legal frameworks that outline liability for harm caused by AI, ensuring there are consequences for both negligent and intentional misuse.\\n\\n3. **Fairness and Non-discrimination**:\\n   - **Goal**: Prevent bias and ensure equitable treatment across diverse populations.\\n   - **Implementation**: Introduce auditing and testing protocols to identify and mitigate biases in data and algorithms, alongside diverse development teams.\\n\\n4. **Privacy and Data Protection**:\\n   - **Goal**: Safeguard personal information and respect individuals' rights to control their data.\\n   - **Implementation**: Adhere to strict data governance policies, implement data anonymization techniques, and provide users with clear options for consent and data access.\\n\\n5. **Safety and Security**:\\n   - **Goal**: Ensure that AI systems are safe from malicious use and function correctly under various conditions.\\n   - **Implementation**: Adopt rigorous testing, verification, and validation procedures before deployment, alongside proactive measures against cybersecurity threats.\\n\\n6. **Human-Centric Design**:\\n   - **Goal**: Prioritize user needs and societal impact in AI development.\\n   - **Implementation**: Engage stakeholders in the design process and conduct impact assessments to anticipate societal implications.\\n\\n7. **Sustainability**:\\n   - **Goal**: Ensure that AI technologies contribute positively to environmental and societal sustainability.\\n   - **Implementation**: Encourage development practices that consider the environmental impact of data centers and resource usage, promoting energy-efficient algorithms.\\n\\n8. **Collaboration and Inclusiveness**:\\n   - **Goal**: Foster a cooperative environment among all stakeholders, including industry, government, and civil society.\\n   - **Implementation**: Create platforms for dialogue and cross-sector collaboration to share knowledge, best practices, and standards in AI development.\\n\\n### Addressing Conflicts Between Principles\\n\\nWhen conflicts arise between these principles, the following strategies can be employed:\\n\\n1. **Stakeholder Engagement**:\\n   - Regularly consult with diverse stakeholders, including marginalized communities, to evaluate the potential impact of trade-offs. For instance, if transparency risks exposing sensitive data, engage stakeholders in balancing transparency with privacy measures.\\n\\n2. **Prioritization Framework**:\\n   - Develop a framework for evaluating and prioritizing principles based on context, impact, and societal norms. This framework should allow flexibility to adapt to different scenarios while maintaining core ethical commitments.\\n\\n3. **Iterative Design and Regulation**:\\n   - Implement an iterative approach where AI systems are continuously monitored and assessed post-deployment, allowing for adjustments to balance conflicting principles as new information arises.\\n\\n4. **Ethics Committees**:\\n   - Establish ethics committees or boards that include diverse representation to weigh in on conflicts and guide decision-making with a holistic view of the impacts on society.\\n\\n5. **Educational Initiatives**:\\n   - Promote understanding of ethical AI principles among developers and users to cultivate an ethical culture in the AI ecosystem. This can help balance innovation with ethical considerations by fostering a system of shared responsibility.\\n\\n6. **Conformance and Compliance Checks**:\\n   - Regular audits and assessments to ensure AI systems adhere to ethical principles and allow for corrective actions when conflicts are identified.\\n\\nBy prioritizing these key principles and employing structured strategies to manage conflicts, a balanced ethical framework for AI can be created, promoting innovation while safeguarding societal well-being.\", '# Designing an Ethical Framework for AI\\n\\n## Core Principles I Would Prioritize\\n\\n1. **Human Flourishing**: AI systems should ultimately enhance human dignity, autonomy, and well-being across diverse populations\\n\\n2. **Distributive Justice**: Benefits and risks should be fairly distributed, with special attention to marginalized communities\\n\\n3. **Transparency and Explainability**: AI decision processes should be interpretable to appropriate stakeholders\\n\\n4. **Accountability**: Clear lines of responsibility for AI outcomes must exist, with meaningful oversight mechanisms\\n\\n5. **Safety and Robustness**: Systems should be designed to prevent foreseeable harms and withstand adversarial scenarios\\n\\n## Addressing Conflicts Between Principles\\n\\nWhen principles conflict, I would implement:\\n\\n- **Contextual Assessment**: Recognize that principle priorities may shift based on domain (healthcare vs. entertainment) and risk level\\n\\n- **Deliberative Processes**: Include diverse stakeholders, especially those most affected, in formulating compromises\\n\\n- **Graduated Responsibility**: Apply stricter ethical requirements as potential impact increases\\n\\n- **Continuous Reassessment**: Build feedback mechanisms to evaluate outcomes and adjust ethical frameworks accordingly\\n\\nThe most challenging tension is often between innovation and precaution. This requires both thoughtful governance structures and maintaining space for responsible development.', 'Okay, this is a fascinating challenge! Designing an ethical framework for AI requires careful consideration of numerous complex factors. Here\\'s my proposed framework, prioritizing key principles and outlining strategies to address potential conflicts:\\n\\n**I. Core Principles:**\\n\\n1.  **Human-Centricity:**\\n    *   **Definition:** AI systems should be designed, developed, and deployed with the primary goal of benefiting humanity and improving the quality of life. Human autonomy, dignity, and well-being should be central considerations.\\n    *   **Operationalization:**  This means prioritizing AI applications that address pressing societal challenges (e.g., healthcare, climate change, education) and avoiding applications that could lead to mass unemployment, social division, or the erosion of fundamental rights. It also means ensuring that humans remain in control and accountable for critical decisions made by AI.  Transparency and explainability are crucial for enabling human oversight.\\n\\n2.  **Fairness and Justice:**\\n    *   **Definition:** AI systems should be free from bias and discrimination, ensuring equitable outcomes for all individuals and groups.  This includes addressing both historical biases embedded in data and algorithmic biases introduced during development.\\n    *   **Operationalization:**  This requires rigorous testing and auditing of AI systems for bias, particularly in sensitive areas like criminal justice, loan applications, and hiring. It also necessitates diverse and inclusive teams in AI development to ensure that different perspectives are considered and potential biases are identified early on.  Data collection and annotation processes must be carefully scrutinized to minimize bias.  Using fairness-aware algorithms and employing techniques to mitigate bias in existing datasets are also essential.\\n\\n3.  **Transparency and Explainability:**\\n    *   **Definition:** The decision-making processes of AI systems should be understandable and transparent to users, stakeholders, and regulators.  Explainability allows for accountability and builds trust.\\n    *   **Operationalization:**  This involves developing techniques for explaining how AI systems arrive at their decisions, especially for complex machine learning models.  Documenting the design, data sources, and assumptions underlying AI systems is critical.  Providing users with clear and accessible information about how AI systems are used and how their data is being processed is also essential.  Moving beyond \"black box\" models to more interpretable models where appropriate.\\n\\n4.  **Privacy and Data Security:**\\n    *   **Definition:**  AI systems should respect individuals\\' privacy rights and protect their personal data from unauthorized access, use, or disclosure.\\n    *   **Operationalization:**  Implementing strong data encryption and anonymization techniques is crucial.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and use are also necessary.  Developing AI systems that minimize data requirements (e.g., federated learning, differential privacy) is a promising approach.  Establishing robust security protocols to prevent data breaches and cyberattacks is paramount.\\n\\n5.  **Accountability and Responsibility:**\\n    *   **Definition:**  Clear lines of responsibility and accountability should be established for the design, development, deployment, and use of AI systems.  Mechanisms should be in place to address harms caused by AI systems.\\n    *   **Operationalization:**  This requires defining roles and responsibilities for developers, deployers, and users of AI systems.  Establishing independent oversight bodies to monitor AI development and deployment is important.  Developing mechanisms for redress and compensation for individuals harmed by AI systems is essential.  Establishing ethical review boards to assess the potential risks and benefits of AI projects before they are implemented.\\n\\n6.  **Sustainability and Environmental Responsibility:**\\n    *   **Definition:** AI systems should be developed and deployed in a way that minimizes their environmental impact and contributes to a sustainable future.\\n    *   **Operationalization:**  This involves considering the energy consumption of AI training and deployment.  Developing more energy-efficient AI algorithms and hardware is critical.  Using AI to address environmental challenges (e.g., climate change, pollution) is a promising application.  Promoting the responsible use of natural resources in the development and deployment of AI systems.\\n\\n**II. Addressing Potential Conflicts Between Principles:**\\n\\nConflicts between these principles are inevitable. Here\\'s how I would approach them:\\n\\n1.  **Prioritization Framework:**\\n    *   **Hierarchy of Values:** While all principles are important, a hierarchy might be necessary in certain situations. Generally, **Human-Centricity** and **Fairness & Justice** should take precedence, as they directly relate to fundamental human rights and well-being.  However, the specific context will heavily influence the appropriate prioritization.\\n    *   **Consequence Analysis:** Carefully analyze the potential consequences of prioritizing one principle over another in a specific situation.  Consider the short-term and long-term impacts on different stakeholders.\\n\\n2.  **Trade-off Analysis and Ethical Deliberation:**\\n    *   **Stakeholder Engagement:** Involve diverse stakeholders (e.g., developers, ethicists, policymakers, affected communities) in the decision-making process.\\n    *   **Ethical Frameworks and Tools:** Utilize established ethical frameworks (e.g., utilitarianism, deontology) to guide decision-making. Employ tools like ethical impact assessments to identify and evaluate potential ethical risks.\\n    *   **Transparency in Trade-offs:** Clearly communicate the trade-offs that were made and the reasons behind them.  Document the decision-making process and the rationale for the chosen course of action.\\n\\n3.  **Context-Specific Application:**\\n    *   **Domain-Specific Guidelines:** Develop specific ethical guidelines for different AI applications (e.g., healthcare AI, autonomous vehicles, facial recognition).  These guidelines should address the unique ethical challenges associated with each domain.\\n    *   **Adaptive Framework:**  Recognize that the ethical framework must be adaptable and evolve as AI technology advances and societal values change.  Regularly review and update the framework based on new knowledge and experience.\\n\\n4.  **Technical Solutions:**\\n    *   **Fairness-Aware Algorithms:**  Employ algorithms that are designed to mitigate bias and promote fairness.\\n    *   **Explainable AI (XAI) Techniques:**  Develop and deploy XAI techniques to make AI decision-making more transparent and understandable.\\n    *   **Privacy-Enhancing Technologies (PETs):**  Utilize PETs to protect individuals\\' privacy while still enabling the use of AI for beneficial purposes.\\n\\n**Examples of Conflict Resolution:**\\n\\n*   **Innovation vs. Privacy:**  Developing a new AI-powered surveillance system for crime prevention (innovation) might conflict with individuals\\' privacy rights.  The resolution could involve using privacy-enhancing technologies (e.g., differential privacy) to anonymize data, limiting the scope of surveillance, and establishing strict oversight mechanisms to prevent abuse.\\n*   **Fairness vs. Accuracy:**  An AI system used for loan applications might be more accurate if it considers certain demographic factors, but this could lead to unfair discrimination.  The resolution could involve removing these demographic factors from the model, even if it slightly reduces accuracy, and using fairness-aware algorithms to mitigate bias.\\n*   **Transparency vs. Security:**  Revealing the inner workings of an AI system (transparency) could make it more vulnerable to hacking or manipulation (security).  The resolution could involve providing explanations at a higher level of abstraction, without revealing sensitive details, and implementing robust security measures to protect the system from attack.\\n\\n**III. Implementation and Enforcement:**\\n\\n*   **Multi-Stakeholder Governance:** Establish a multi-stakeholder governance body to oversee the implementation and enforcement of the ethical framework. This body should include representatives from government, industry, academia, civil society, and the public.\\n*   **Auditing and Certification:** Implement auditing and certification processes to ensure that AI systems comply with the ethical framework.\\n*   **Regulatory Frameworks:** Develop appropriate regulatory frameworks to govern the development and deployment of AI systems. These frameworks should be flexible and adaptable to accommodate future technological advancements.\\n*   **Education and Training:** Provide education and training to AI developers, users, and the public on the ethical implications of AI.\\n*   **Public Dialogue:** Foster public dialogue and engagement on the ethical challenges and opportunities presented by AI.\\n\\n**Conclusion:**\\n\\nCreating an effective ethical framework for AI is an ongoing process that requires collaboration, continuous learning, and a commitment to human-centricity, fairness, and transparency. This proposed framework, with its prioritized principles and strategies for conflict resolution, provides a foundation for building AI systems that benefit society while mitigating potential harms. It\\'s crucial to remember that this framework is not a static document but rather a living document that must be regularly reviewed and updated to reflect the evolving landscape of AI technology and societal values.\\n']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) that balances innovation with societal well-being is a complex challenge. Here are key principles I would prioritize and strategies to address potential conflicts:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency**:\n",
      "   - **Goal**: Ensure AI systems are understandable and their operations are explainable to users and stakeholders.\n",
      "   - **Implementation**: Require clear documentation of AI decision-making processes and make algorithms interpretable without needing specialized knowledge.\n",
      "\n",
      "2. **Accountability**:\n",
      "   - **Goal**: Hold developers and organizations responsible for the outcomes of AI systems.\n",
      "   - **Implementation**: Establish legal frameworks that outline liability for harm caused by AI, ensuring there are consequences for both negligent and intentional misuse.\n",
      "\n",
      "3. **Fairness and Non-discrimination**:\n",
      "   - **Goal**: Prevent bias and ensure equitable treatment across diverse populations.\n",
      "   - **Implementation**: Introduce auditing and testing protocols to identify and mitigate biases in data and algorithms, alongside diverse development teams.\n",
      "\n",
      "4. **Privacy and Data Protection**:\n",
      "   - **Goal**: Safeguard personal information and respect individuals' rights to control their data.\n",
      "   - **Implementation**: Adhere to strict data governance policies, implement data anonymization techniques, and provide users with clear options for consent and data access.\n",
      "\n",
      "5. **Safety and Security**:\n",
      "   - **Goal**: Ensure that AI systems are safe from malicious use and function correctly under various conditions.\n",
      "   - **Implementation**: Adopt rigorous testing, verification, and validation procedures before deployment, alongside proactive measures against cybersecurity threats.\n",
      "\n",
      "6. **Human-Centric Design**:\n",
      "   - **Goal**: Prioritize user needs and societal impact in AI development.\n",
      "   - **Implementation**: Engage stakeholders in the design process and conduct impact assessments to anticipate societal implications.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - **Goal**: Ensure that AI technologies contribute positively to environmental and societal sustainability.\n",
      "   - **Implementation**: Encourage development practices that consider the environmental impact of data centers and resource usage, promoting energy-efficient algorithms.\n",
      "\n",
      "8. **Collaboration and Inclusiveness**:\n",
      "   - **Goal**: Foster a cooperative environment among all stakeholders, including industry, government, and civil society.\n",
      "   - **Implementation**: Create platforms for dialogue and cross-sector collaboration to share knowledge, best practices, and standards in AI development.\n",
      "\n",
      "### Addressing Conflicts Between Principles\n",
      "\n",
      "When conflicts arise between these principles, the following strategies can be employed:\n",
      "\n",
      "1. **Stakeholder Engagement**:\n",
      "   - Regularly consult with diverse stakeholders, including marginalized communities, to evaluate the potential impact of trade-offs. For instance, if transparency risks exposing sensitive data, engage stakeholders in balancing transparency with privacy measures.\n",
      "\n",
      "2. **Prioritization Framework**:\n",
      "   - Develop a framework for evaluating and prioritizing principles based on context, impact, and societal norms. This framework should allow flexibility to adapt to different scenarios while maintaining core ethical commitments.\n",
      "\n",
      "3. **Iterative Design and Regulation**:\n",
      "   - Implement an iterative approach where AI systems are continuously monitored and assessed post-deployment, allowing for adjustments to balance conflicting principles as new information arises.\n",
      "\n",
      "4. **Ethics Committees**:\n",
      "   - Establish ethics committees or boards that include diverse representation to weigh in on conflicts and guide decision-making with a holistic view of the impacts on society.\n",
      "\n",
      "5. **Educational Initiatives**:\n",
      "   - Promote understanding of ethical AI principles among developers and users to cultivate an ethical culture in the AI ecosystem. This can help balance innovation with ethical considerations by fostering a system of shared responsibility.\n",
      "\n",
      "6. **Conformance and Compliance Checks**:\n",
      "   - Regular audits and assessments to ensure AI systems adhere to ethical principles and allow for corrective actions when conflicts are identified.\n",
      "\n",
      "By prioritizing these key principles and employing structured strategies to manage conflicts, a balanced ethical framework for AI can be created, promoting innovation while safeguarding societal well-being.\n",
      "Competitor: claude-3-7-sonnet-latest\n",
      "\n",
      "# Designing an Ethical Framework for AI\n",
      "\n",
      "## Core Principles I Would Prioritize\n",
      "\n",
      "1. **Human Flourishing**: AI systems should ultimately enhance human dignity, autonomy, and well-being across diverse populations\n",
      "\n",
      "2. **Distributive Justice**: Benefits and risks should be fairly distributed, with special attention to marginalized communities\n",
      "\n",
      "3. **Transparency and Explainability**: AI decision processes should be interpretable to appropriate stakeholders\n",
      "\n",
      "4. **Accountability**: Clear lines of responsibility for AI outcomes must exist, with meaningful oversight mechanisms\n",
      "\n",
      "5. **Safety and Robustness**: Systems should be designed to prevent foreseeable harms and withstand adversarial scenarios\n",
      "\n",
      "## Addressing Conflicts Between Principles\n",
      "\n",
      "When principles conflict, I would implement:\n",
      "\n",
      "- **Contextual Assessment**: Recognize that principle priorities may shift based on domain (healthcare vs. entertainment) and risk level\n",
      "\n",
      "- **Deliberative Processes**: Include diverse stakeholders, especially those most affected, in formulating compromises\n",
      "\n",
      "- **Graduated Responsibility**: Apply stricter ethical requirements as potential impact increases\n",
      "\n",
      "- **Continuous Reassessment**: Build feedback mechanisms to evaluate outcomes and adjust ethical frameworks accordingly\n",
      "\n",
      "The most challenging tension is often between innovation and precaution. This requires both thoughtful governance structures and maintaining space for responsible development.\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Okay, this is a fascinating challenge! Designing an ethical framework for AI requires careful consideration of numerous complex factors. Here's my proposed framework, prioritizing key principles and outlining strategies to address potential conflicts:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centricity:**\n",
      "    *   **Definition:** AI systems should be designed, developed, and deployed with the primary goal of benefiting humanity and improving the quality of life. Human autonomy, dignity, and well-being should be central considerations.\n",
      "    *   **Operationalization:**  This means prioritizing AI applications that address pressing societal challenges (e.g., healthcare, climate change, education) and avoiding applications that could lead to mass unemployment, social division, or the erosion of fundamental rights. It also means ensuring that humans remain in control and accountable for critical decisions made by AI.  Transparency and explainability are crucial for enabling human oversight.\n",
      "\n",
      "2.  **Fairness and Justice:**\n",
      "    *   **Definition:** AI systems should be free from bias and discrimination, ensuring equitable outcomes for all individuals and groups.  This includes addressing both historical biases embedded in data and algorithmic biases introduced during development.\n",
      "    *   **Operationalization:**  This requires rigorous testing and auditing of AI systems for bias, particularly in sensitive areas like criminal justice, loan applications, and hiring. It also necessitates diverse and inclusive teams in AI development to ensure that different perspectives are considered and potential biases are identified early on.  Data collection and annotation processes must be carefully scrutinized to minimize bias.  Using fairness-aware algorithms and employing techniques to mitigate bias in existing datasets are also essential.\n",
      "\n",
      "3.  **Transparency and Explainability:**\n",
      "    *   **Definition:** The decision-making processes of AI systems should be understandable and transparent to users, stakeholders, and regulators.  Explainability allows for accountability and builds trust.\n",
      "    *   **Operationalization:**  This involves developing techniques for explaining how AI systems arrive at their decisions, especially for complex machine learning models.  Documenting the design, data sources, and assumptions underlying AI systems is critical.  Providing users with clear and accessible information about how AI systems are used and how their data is being processed is also essential.  Moving beyond \"black box\" models to more interpretable models where appropriate.\n",
      "\n",
      "4.  **Privacy and Data Security:**\n",
      "    *   **Definition:**  AI systems should respect individuals' privacy rights and protect their personal data from unauthorized access, use, or disclosure.\n",
      "    *   **Operationalization:**  Implementing strong data encryption and anonymization techniques is crucial.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and use are also necessary.  Developing AI systems that minimize data requirements (e.g., federated learning, differential privacy) is a promising approach.  Establishing robust security protocols to prevent data breaches and cyberattacks is paramount.\n",
      "\n",
      "5.  **Accountability and Responsibility:**\n",
      "    *   **Definition:**  Clear lines of responsibility and accountability should be established for the design, development, deployment, and use of AI systems.  Mechanisms should be in place to address harms caused by AI systems.\n",
      "    *   **Operationalization:**  This requires defining roles and responsibilities for developers, deployers, and users of AI systems.  Establishing independent oversight bodies to monitor AI development and deployment is important.  Developing mechanisms for redress and compensation for individuals harmed by AI systems is essential.  Establishing ethical review boards to assess the potential risks and benefits of AI projects before they are implemented.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**\n",
      "    *   **Definition:** AI systems should be developed and deployed in a way that minimizes their environmental impact and contributes to a sustainable future.\n",
      "    *   **Operationalization:**  This involves considering the energy consumption of AI training and deployment.  Developing more energy-efficient AI algorithms and hardware is critical.  Using AI to address environmental challenges (e.g., climate change, pollution) is a promising application.  Promoting the responsible use of natural resources in the development and deployment of AI systems.\n",
      "\n",
      "**II. Addressing Potential Conflicts Between Principles:**\n",
      "\n",
      "Conflicts between these principles are inevitable. Here's how I would approach them:\n",
      "\n",
      "1.  **Prioritization Framework:**\n",
      "    *   **Hierarchy of Values:** While all principles are important, a hierarchy might be necessary in certain situations. Generally, **Human-Centricity** and **Fairness & Justice** should take precedence, as they directly relate to fundamental human rights and well-being.  However, the specific context will heavily influence the appropriate prioritization.\n",
      "    *   **Consequence Analysis:** Carefully analyze the potential consequences of prioritizing one principle over another in a specific situation.  Consider the short-term and long-term impacts on different stakeholders.\n",
      "\n",
      "2.  **Trade-off Analysis and Ethical Deliberation:**\n",
      "    *   **Stakeholder Engagement:** Involve diverse stakeholders (e.g., developers, ethicists, policymakers, affected communities) in the decision-making process.\n",
      "    *   **Ethical Frameworks and Tools:** Utilize established ethical frameworks (e.g., utilitarianism, deontology) to guide decision-making. Employ tools like ethical impact assessments to identify and evaluate potential ethical risks.\n",
      "    *   **Transparency in Trade-offs:** Clearly communicate the trade-offs that were made and the reasons behind them.  Document the decision-making process and the rationale for the chosen course of action.\n",
      "\n",
      "3.  **Context-Specific Application:**\n",
      "    *   **Domain-Specific Guidelines:** Develop specific ethical guidelines for different AI applications (e.g., healthcare AI, autonomous vehicles, facial recognition).  These guidelines should address the unique ethical challenges associated with each domain.\n",
      "    *   **Adaptive Framework:**  Recognize that the ethical framework must be adaptable and evolve as AI technology advances and societal values change.  Regularly review and update the framework based on new knowledge and experience.\n",
      "\n",
      "4.  **Technical Solutions:**\n",
      "    *   **Fairness-Aware Algorithms:**  Employ algorithms that are designed to mitigate bias and promote fairness.\n",
      "    *   **Explainable AI (XAI) Techniques:**  Develop and deploy XAI techniques to make AI decision-making more transparent and understandable.\n",
      "    *   **Privacy-Enhancing Technologies (PETs):**  Utilize PETs to protect individuals' privacy while still enabling the use of AI for beneficial purposes.\n",
      "\n",
      "**Examples of Conflict Resolution:**\n",
      "\n",
      "*   **Innovation vs. Privacy:**  Developing a new AI-powered surveillance system for crime prevention (innovation) might conflict with individuals' privacy rights.  The resolution could involve using privacy-enhancing technologies (e.g., differential privacy) to anonymize data, limiting the scope of surveillance, and establishing strict oversight mechanisms to prevent abuse.\n",
      "*   **Fairness vs. Accuracy:**  An AI system used for loan applications might be more accurate if it considers certain demographic factors, but this could lead to unfair discrimination.  The resolution could involve removing these demographic factors from the model, even if it slightly reduces accuracy, and using fairness-aware algorithms to mitigate bias.\n",
      "*   **Transparency vs. Security:**  Revealing the inner workings of an AI system (transparency) could make it more vulnerable to hacking or manipulation (security).  The resolution could involve providing explanations at a higher level of abstraction, without revealing sensitive details, and implementing robust security measures to protect the system from attack.\n",
      "\n",
      "**III. Implementation and Enforcement:**\n",
      "\n",
      "*   **Multi-Stakeholder Governance:** Establish a multi-stakeholder governance body to oversee the implementation and enforcement of the ethical framework. This body should include representatives from government, industry, academia, civil society, and the public.\n",
      "*   **Auditing and Certification:** Implement auditing and certification processes to ensure that AI systems comply with the ethical framework.\n",
      "*   **Regulatory Frameworks:** Develop appropriate regulatory frameworks to govern the development and deployment of AI systems. These frameworks should be flexible and adaptable to accommodate future technological advancements.\n",
      "*   **Education and Training:** Provide education and training to AI developers, users, and the public on the ethical implications of AI.\n",
      "*   **Public Dialogue:** Foster public dialogue and engagement on the ethical challenges and opportunities presented by AI.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Creating an effective ethical framework for AI is an ongoing process that requires collaboration, continuous learning, and a commitment to human-centricity, fairness, and transparency. This proposed framework, with its prioritized principles and strategies for conflict resolution, provides a foundation for building AI systems that benefit society while mitigating potential harms. It's crucial to remember that this framework is not a static document but rather a living document that must be regularly reviewed and updated to reflect the evolving landscape of AI technology and societal values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) that balances innovation with societal well-being is a complex challenge. Here are key principles I would prioritize and strategies to address potential conflicts:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency**:\n",
      "   - **Goal**: Ensure AI systems are understandable and their operations are explainable to users and stakeholders.\n",
      "   - **Implementation**: Require clear documentation of AI decision-making processes and make algorithms interpretable without needing specialized knowledge.\n",
      "\n",
      "2. **Accountability**:\n",
      "   - **Goal**: Hold developers and organizations responsible for the outcomes of AI systems.\n",
      "   - **Implementation**: Establish legal frameworks that outline liability for harm caused by AI, ensuring there are consequences for both negligent and intentional misuse.\n",
      "\n",
      "3. **Fairness and Non-discrimination**:\n",
      "   - **Goal**: Prevent bias and ensure equitable treatment across diverse populations.\n",
      "   - **Implementation**: Introduce auditing and testing protocols to identify and mitigate biases in data and algorithms, alongside diverse development teams.\n",
      "\n",
      "4. **Privacy and Data Protection**:\n",
      "   - **Goal**: Safeguard personal information and respect individuals' rights to control their data.\n",
      "   - **Implementation**: Adhere to strict data governance policies, implement data anonymization techniques, and provide users with clear options for consent and data access.\n",
      "\n",
      "5. **Safety and Security**:\n",
      "   - **Goal**: Ensure that AI systems are safe from malicious use and function correctly under various conditions.\n",
      "   - **Implementation**: Adopt rigorous testing, verification, and validation procedures before deployment, alongside proactive measures against cybersecurity threats.\n",
      "\n",
      "6. **Human-Centric Design**:\n",
      "   - **Goal**: Prioritize user needs and societal impact in AI development.\n",
      "   - **Implementation**: Engage stakeholders in the design process and conduct impact assessments to anticipate societal implications.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - **Goal**: Ensure that AI technologies contribute positively to environmental and societal sustainability.\n",
      "   - **Implementation**: Encourage development practices that consider the environmental impact of data centers and resource usage, promoting energy-efficient algorithms.\n",
      "\n",
      "8. **Collaboration and Inclusiveness**:\n",
      "   - **Goal**: Foster a cooperative environment among all stakeholders, including industry, government, and civil society.\n",
      "   - **Implementation**: Create platforms for dialogue and cross-sector collaboration to share knowledge, best practices, and standards in AI development.\n",
      "\n",
      "### Addressing Conflicts Between Principles\n",
      "\n",
      "When conflicts arise between these principles, the following strategies can be employed:\n",
      "\n",
      "1. **Stakeholder Engagement**:\n",
      "   - Regularly consult with diverse stakeholders, including marginalized communities, to evaluate the potential impact of trade-offs. For instance, if transparency risks exposing sensitive data, engage stakeholders in balancing transparency with privacy measures.\n",
      "\n",
      "2. **Prioritization Framework**:\n",
      "   - Develop a framework for evaluating and prioritizing principles based on context, impact, and societal norms. This framework should allow flexibility to adapt to different scenarios while maintaining core ethical commitments.\n",
      "\n",
      "3. **Iterative Design and Regulation**:\n",
      "   - Implement an iterative approach where AI systems are continuously monitored and assessed post-deployment, allowing for adjustments to balance conflicting principles as new information arises.\n",
      "\n",
      "4. **Ethics Committees**:\n",
      "   - Establish ethics committees or boards that include diverse representation to weigh in on conflicts and guide decision-making with a holistic view of the impacts on society.\n",
      "\n",
      "5. **Educational Initiatives**:\n",
      "   - Promote understanding of ethical AI principles among developers and users to cultivate an ethical culture in the AI ecosystem. This can help balance innovation with ethical considerations by fostering a system of shared responsibility.\n",
      "\n",
      "6. **Conformance and Compliance Checks**:\n",
      "   - Regular audits and assessments to ensure AI systems adhere to ethical principles and allow for corrective actions when conflicts are identified.\n",
      "\n",
      "By prioritizing these key principles and employing structured strategies to manage conflicts, a balanced ethical framework for AI can be created, promoting innovation while safeguarding societal well-being.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Designing an Ethical Framework for AI\n",
      "\n",
      "## Core Principles I Would Prioritize\n",
      "\n",
      "1. **Human Flourishing**: AI systems should ultimately enhance human dignity, autonomy, and well-being across diverse populations\n",
      "\n",
      "2. **Distributive Justice**: Benefits and risks should be fairly distributed, with special attention to marginalized communities\n",
      "\n",
      "3. **Transparency and Explainability**: AI decision processes should be interpretable to appropriate stakeholders\n",
      "\n",
      "4. **Accountability**: Clear lines of responsibility for AI outcomes must exist, with meaningful oversight mechanisms\n",
      "\n",
      "5. **Safety and Robustness**: Systems should be designed to prevent foreseeable harms and withstand adversarial scenarios\n",
      "\n",
      "## Addressing Conflicts Between Principles\n",
      "\n",
      "When principles conflict, I would implement:\n",
      "\n",
      "- **Contextual Assessment**: Recognize that principle priorities may shift based on domain (healthcare vs. entertainment) and risk level\n",
      "\n",
      "- **Deliberative Processes**: Include diverse stakeholders, especially those most affected, in formulating compromises\n",
      "\n",
      "- **Graduated Responsibility**: Apply stricter ethical requirements as potential impact increases\n",
      "\n",
      "- **Continuous Reassessment**: Build feedback mechanisms to evaluate outcomes and adjust ethical frameworks accordingly\n",
      "\n",
      "The most challenging tension is often between innovation and precaution. This requires both thoughtful governance structures and maintaining space for responsible development.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Okay, this is a fascinating challenge! Designing an ethical framework for AI requires careful consideration of numerous complex factors. Here's my proposed framework, prioritizing key principles and outlining strategies to address potential conflicts:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centricity:**\n",
      "    *   **Definition:** AI systems should be designed, developed, and deployed with the primary goal of benefiting humanity and improving the quality of life. Human autonomy, dignity, and well-being should be central considerations.\n",
      "    *   **Operationalization:**  This means prioritizing AI applications that address pressing societal challenges (e.g., healthcare, climate change, education) and avoiding applications that could lead to mass unemployment, social division, or the erosion of fundamental rights. It also means ensuring that humans remain in control and accountable for critical decisions made by AI.  Transparency and explainability are crucial for enabling human oversight.\n",
      "\n",
      "2.  **Fairness and Justice:**\n",
      "    *   **Definition:** AI systems should be free from bias and discrimination, ensuring equitable outcomes for all individuals and groups.  This includes addressing both historical biases embedded in data and algorithmic biases introduced during development.\n",
      "    *   **Operationalization:**  This requires rigorous testing and auditing of AI systems for bias, particularly in sensitive areas like criminal justice, loan applications, and hiring. It also necessitates diverse and inclusive teams in AI development to ensure that different perspectives are considered and potential biases are identified early on.  Data collection and annotation processes must be carefully scrutinized to minimize bias.  Using fairness-aware algorithms and employing techniques to mitigate bias in existing datasets are also essential.\n",
      "\n",
      "3.  **Transparency and Explainability:**\n",
      "    *   **Definition:** The decision-making processes of AI systems should be understandable and transparent to users, stakeholders, and regulators.  Explainability allows for accountability and builds trust.\n",
      "    *   **Operationalization:**  This involves developing techniques for explaining how AI systems arrive at their decisions, especially for complex machine learning models.  Documenting the design, data sources, and assumptions underlying AI systems is critical.  Providing users with clear and accessible information about how AI systems are used and how their data is being processed is also essential.  Moving beyond \"black box\" models to more interpretable models where appropriate.\n",
      "\n",
      "4.  **Privacy and Data Security:**\n",
      "    *   **Definition:**  AI systems should respect individuals' privacy rights and protect their personal data from unauthorized access, use, or disclosure.\n",
      "    *   **Operationalization:**  Implementing strong data encryption and anonymization techniques is crucial.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and use are also necessary.  Developing AI systems that minimize data requirements (e.g., federated learning, differential privacy) is a promising approach.  Establishing robust security protocols to prevent data breaches and cyberattacks is paramount.\n",
      "\n",
      "5.  **Accountability and Responsibility:**\n",
      "    *   **Definition:**  Clear lines of responsibility and accountability should be established for the design, development, deployment, and use of AI systems.  Mechanisms should be in place to address harms caused by AI systems.\n",
      "    *   **Operationalization:**  This requires defining roles and responsibilities for developers, deployers, and users of AI systems.  Establishing independent oversight bodies to monitor AI development and deployment is important.  Developing mechanisms for redress and compensation for individuals harmed by AI systems is essential.  Establishing ethical review boards to assess the potential risks and benefits of AI projects before they are implemented.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**\n",
      "    *   **Definition:** AI systems should be developed and deployed in a way that minimizes their environmental impact and contributes to a sustainable future.\n",
      "    *   **Operationalization:**  This involves considering the energy consumption of AI training and deployment.  Developing more energy-efficient AI algorithms and hardware is critical.  Using AI to address environmental challenges (e.g., climate change, pollution) is a promising application.  Promoting the responsible use of natural resources in the development and deployment of AI systems.\n",
      "\n",
      "**II. Addressing Potential Conflicts Between Principles:**\n",
      "\n",
      "Conflicts between these principles are inevitable. Here's how I would approach them:\n",
      "\n",
      "1.  **Prioritization Framework:**\n",
      "    *   **Hierarchy of Values:** While all principles are important, a hierarchy might be necessary in certain situations. Generally, **Human-Centricity** and **Fairness & Justice** should take precedence, as they directly relate to fundamental human rights and well-being.  However, the specific context will heavily influence the appropriate prioritization.\n",
      "    *   **Consequence Analysis:** Carefully analyze the potential consequences of prioritizing one principle over another in a specific situation.  Consider the short-term and long-term impacts on different stakeholders.\n",
      "\n",
      "2.  **Trade-off Analysis and Ethical Deliberation:**\n",
      "    *   **Stakeholder Engagement:** Involve diverse stakeholders (e.g., developers, ethicists, policymakers, affected communities) in the decision-making process.\n",
      "    *   **Ethical Frameworks and Tools:** Utilize established ethical frameworks (e.g., utilitarianism, deontology) to guide decision-making. Employ tools like ethical impact assessments to identify and evaluate potential ethical risks.\n",
      "    *   **Transparency in Trade-offs:** Clearly communicate the trade-offs that were made and the reasons behind them.  Document the decision-making process and the rationale for the chosen course of action.\n",
      "\n",
      "3.  **Context-Specific Application:**\n",
      "    *   **Domain-Specific Guidelines:** Develop specific ethical guidelines for different AI applications (e.g., healthcare AI, autonomous vehicles, facial recognition).  These guidelines should address the unique ethical challenges associated with each domain.\n",
      "    *   **Adaptive Framework:**  Recognize that the ethical framework must be adaptable and evolve as AI technology advances and societal values change.  Regularly review and update the framework based on new knowledge and experience.\n",
      "\n",
      "4.  **Technical Solutions:**\n",
      "    *   **Fairness-Aware Algorithms:**  Employ algorithms that are designed to mitigate bias and promote fairness.\n",
      "    *   **Explainable AI (XAI) Techniques:**  Develop and deploy XAI techniques to make AI decision-making more transparent and understandable.\n",
      "    *   **Privacy-Enhancing Technologies (PETs):**  Utilize PETs to protect individuals' privacy while still enabling the use of AI for beneficial purposes.\n",
      "\n",
      "**Examples of Conflict Resolution:**\n",
      "\n",
      "*   **Innovation vs. Privacy:**  Developing a new AI-powered surveillance system for crime prevention (innovation) might conflict with individuals' privacy rights.  The resolution could involve using privacy-enhancing technologies (e.g., differential privacy) to anonymize data, limiting the scope of surveillance, and establishing strict oversight mechanisms to prevent abuse.\n",
      "*   **Fairness vs. Accuracy:**  An AI system used for loan applications might be more accurate if it considers certain demographic factors, but this could lead to unfair discrimination.  The resolution could involve removing these demographic factors from the model, even if it slightly reduces accuracy, and using fairness-aware algorithms to mitigate bias.\n",
      "*   **Transparency vs. Security:**  Revealing the inner workings of an AI system (transparency) could make it more vulnerable to hacking or manipulation (security).  The resolution could involve providing explanations at a higher level of abstraction, without revealing sensitive details, and implementing robust security measures to protect the system from attack.\n",
      "\n",
      "**III. Implementation and Enforcement:**\n",
      "\n",
      "*   **Multi-Stakeholder Governance:** Establish a multi-stakeholder governance body to oversee the implementation and enforcement of the ethical framework. This body should include representatives from government, industry, academia, civil society, and the public.\n",
      "*   **Auditing and Certification:** Implement auditing and certification processes to ensure that AI systems comply with the ethical framework.\n",
      "*   **Regulatory Frameworks:** Develop appropriate regulatory frameworks to govern the development and deployment of AI systems. These frameworks should be flexible and adaptable to accommodate future technological advancements.\n",
      "*   **Education and Training:** Provide education and training to AI developers, users, and the public on the ethical implications of AI.\n",
      "*   **Public Dialogue:** Foster public dialogue and engagement on the ethical challenges and opportunities presented by AI.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Creating an effective ethical framework for AI is an ongoing process that requires collaboration, continuous learning, and a commitment to human-centricity, fairness, and transparency. This proposed framework, with its prioritized principles and strategies for conflict resolution, provides a foundation for building AI systems that benefit society while mitigating potential harms. It's crucial to remember that this framework is not a static document but rather a living document that must be regularly reviewed and updated to reflect the evolving landscape of AI technology and societal values.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 3 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If you were tasked with designing a new ethical framework for artificial intelligence that balances innovation and societal well-being, what key principles would you prioritize, and how would you address potential conflicts between those principles?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Designing a new ethical framework for artificial intelligence (AI) that balances innovation with societal well-being is a complex challenge. Here are key principles I would prioritize and strategies to address potential conflicts:\n",
      "\n",
      "### Key Principles\n",
      "\n",
      "1. **Transparency**:\n",
      "   - **Goal**: Ensure AI systems are understandable and their operations are explainable to users and stakeholders.\n",
      "   - **Implementation**: Require clear documentation of AI decision-making processes and make algorithms interpretable without needing specialized knowledge.\n",
      "\n",
      "2. **Accountability**:\n",
      "   - **Goal**: Hold developers and organizations responsible for the outcomes of AI systems.\n",
      "   - **Implementation**: Establish legal frameworks that outline liability for harm caused by AI, ensuring there are consequences for both negligent and intentional misuse.\n",
      "\n",
      "3. **Fairness and Non-discrimination**:\n",
      "   - **Goal**: Prevent bias and ensure equitable treatment across diverse populations.\n",
      "   - **Implementation**: Introduce auditing and testing protocols to identify and mitigate biases in data and algorithms, alongside diverse development teams.\n",
      "\n",
      "4. **Privacy and Data Protection**:\n",
      "   - **Goal**: Safeguard personal information and respect individuals' rights to control their data.\n",
      "   - **Implementation**: Adhere to strict data governance policies, implement data anonymization techniques, and provide users with clear options for consent and data access.\n",
      "\n",
      "5. **Safety and Security**:\n",
      "   - **Goal**: Ensure that AI systems are safe from malicious use and function correctly under various conditions.\n",
      "   - **Implementation**: Adopt rigorous testing, verification, and validation procedures before deployment, alongside proactive measures against cybersecurity threats.\n",
      "\n",
      "6. **Human-Centric Design**:\n",
      "   - **Goal**: Prioritize user needs and societal impact in AI development.\n",
      "   - **Implementation**: Engage stakeholders in the design process and conduct impact assessments to anticipate societal implications.\n",
      "\n",
      "7. **Sustainability**:\n",
      "   - **Goal**: Ensure that AI technologies contribute positively to environmental and societal sustainability.\n",
      "   - **Implementation**: Encourage development practices that consider the environmental impact of data centers and resource usage, promoting energy-efficient algorithms.\n",
      "\n",
      "8. **Collaboration and Inclusiveness**:\n",
      "   - **Goal**: Foster a cooperative environment among all stakeholders, including industry, government, and civil society.\n",
      "   - **Implementation**: Create platforms for dialogue and cross-sector collaboration to share knowledge, best practices, and standards in AI development.\n",
      "\n",
      "### Addressing Conflicts Between Principles\n",
      "\n",
      "When conflicts arise between these principles, the following strategies can be employed:\n",
      "\n",
      "1. **Stakeholder Engagement**:\n",
      "   - Regularly consult with diverse stakeholders, including marginalized communities, to evaluate the potential impact of trade-offs. For instance, if transparency risks exposing sensitive data, engage stakeholders in balancing transparency with privacy measures.\n",
      "\n",
      "2. **Prioritization Framework**:\n",
      "   - Develop a framework for evaluating and prioritizing principles based on context, impact, and societal norms. This framework should allow flexibility to adapt to different scenarios while maintaining core ethical commitments.\n",
      "\n",
      "3. **Iterative Design and Regulation**:\n",
      "   - Implement an iterative approach where AI systems are continuously monitored and assessed post-deployment, allowing for adjustments to balance conflicting principles as new information arises.\n",
      "\n",
      "4. **Ethics Committees**:\n",
      "   - Establish ethics committees or boards that include diverse representation to weigh in on conflicts and guide decision-making with a holistic view of the impacts on society.\n",
      "\n",
      "5. **Educational Initiatives**:\n",
      "   - Promote understanding of ethical AI principles among developers and users to cultivate an ethical culture in the AI ecosystem. This can help balance innovation with ethical considerations by fostering a system of shared responsibility.\n",
      "\n",
      "6. **Conformance and Compliance Checks**:\n",
      "   - Regular audits and assessments to ensure AI systems adhere to ethical principles and allow for corrective actions when conflicts are identified.\n",
      "\n",
      "By prioritizing these key principles and employing structured strategies to manage conflicts, a balanced ethical framework for AI can be created, promoting innovation while safeguarding societal well-being.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Designing an Ethical Framework for AI\n",
      "\n",
      "## Core Principles I Would Prioritize\n",
      "\n",
      "1. **Human Flourishing**: AI systems should ultimately enhance human dignity, autonomy, and well-being across diverse populations\n",
      "\n",
      "2. **Distributive Justice**: Benefits and risks should be fairly distributed, with special attention to marginalized communities\n",
      "\n",
      "3. **Transparency and Explainability**: AI decision processes should be interpretable to appropriate stakeholders\n",
      "\n",
      "4. **Accountability**: Clear lines of responsibility for AI outcomes must exist, with meaningful oversight mechanisms\n",
      "\n",
      "5. **Safety and Robustness**: Systems should be designed to prevent foreseeable harms and withstand adversarial scenarios\n",
      "\n",
      "## Addressing Conflicts Between Principles\n",
      "\n",
      "When principles conflict, I would implement:\n",
      "\n",
      "- **Contextual Assessment**: Recognize that principle priorities may shift based on domain (healthcare vs. entertainment) and risk level\n",
      "\n",
      "- **Deliberative Processes**: Include diverse stakeholders, especially those most affected, in formulating compromises\n",
      "\n",
      "- **Graduated Responsibility**: Apply stricter ethical requirements as potential impact increases\n",
      "\n",
      "- **Continuous Reassessment**: Build feedback mechanisms to evaluate outcomes and adjust ethical frameworks accordingly\n",
      "\n",
      "The most challenging tension is often between innovation and precaution. This requires both thoughtful governance structures and maintaining space for responsible development.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Okay, this is a fascinating challenge! Designing an ethical framework for AI requires careful consideration of numerous complex factors. Here's my proposed framework, prioritizing key principles and outlining strategies to address potential conflicts:\n",
      "\n",
      "**I. Core Principles:**\n",
      "\n",
      "1.  **Human-Centricity:**\n",
      "    *   **Definition:** AI systems should be designed, developed, and deployed with the primary goal of benefiting humanity and improving the quality of life. Human autonomy, dignity, and well-being should be central considerations.\n",
      "    *   **Operationalization:**  This means prioritizing AI applications that address pressing societal challenges (e.g., healthcare, climate change, education) and avoiding applications that could lead to mass unemployment, social division, or the erosion of fundamental rights. It also means ensuring that humans remain in control and accountable for critical decisions made by AI.  Transparency and explainability are crucial for enabling human oversight.\n",
      "\n",
      "2.  **Fairness and Justice:**\n",
      "    *   **Definition:** AI systems should be free from bias and discrimination, ensuring equitable outcomes for all individuals and groups.  This includes addressing both historical biases embedded in data and algorithmic biases introduced during development.\n",
      "    *   **Operationalization:**  This requires rigorous testing and auditing of AI systems for bias, particularly in sensitive areas like criminal justice, loan applications, and hiring. It also necessitates diverse and inclusive teams in AI development to ensure that different perspectives are considered and potential biases are identified early on.  Data collection and annotation processes must be carefully scrutinized to minimize bias.  Using fairness-aware algorithms and employing techniques to mitigate bias in existing datasets are also essential.\n",
      "\n",
      "3.  **Transparency and Explainability:**\n",
      "    *   **Definition:** The decision-making processes of AI systems should be understandable and transparent to users, stakeholders, and regulators.  Explainability allows for accountability and builds trust.\n",
      "    *   **Operationalization:**  This involves developing techniques for explaining how AI systems arrive at their decisions, especially for complex machine learning models.  Documenting the design, data sources, and assumptions underlying AI systems is critical.  Providing users with clear and accessible information about how AI systems are used and how their data is being processed is also essential.  Moving beyond \"black box\" models to more interpretable models where appropriate.\n",
      "\n",
      "4.  **Privacy and Data Security:**\n",
      "    *   **Definition:**  AI systems should respect individuals' privacy rights and protect their personal data from unauthorized access, use, or disclosure.\n",
      "    *   **Operationalization:**  Implementing strong data encryption and anonymization techniques is crucial.  Adhering to privacy regulations (e.g., GDPR, CCPA) and obtaining informed consent for data collection and use are also necessary.  Developing AI systems that minimize data requirements (e.g., federated learning, differential privacy) is a promising approach.  Establishing robust security protocols to prevent data breaches and cyberattacks is paramount.\n",
      "\n",
      "5.  **Accountability and Responsibility:**\n",
      "    *   **Definition:**  Clear lines of responsibility and accountability should be established for the design, development, deployment, and use of AI systems.  Mechanisms should be in place to address harms caused by AI systems.\n",
      "    *   **Operationalization:**  This requires defining roles and responsibilities for developers, deployers, and users of AI systems.  Establishing independent oversight bodies to monitor AI development and deployment is important.  Developing mechanisms for redress and compensation for individuals harmed by AI systems is essential.  Establishing ethical review boards to assess the potential risks and benefits of AI projects before they are implemented.\n",
      "\n",
      "6.  **Sustainability and Environmental Responsibility:**\n",
      "    *   **Definition:** AI systems should be developed and deployed in a way that minimizes their environmental impact and contributes to a sustainable future.\n",
      "    *   **Operationalization:**  This involves considering the energy consumption of AI training and deployment.  Developing more energy-efficient AI algorithms and hardware is critical.  Using AI to address environmental challenges (e.g., climate change, pollution) is a promising application.  Promoting the responsible use of natural resources in the development and deployment of AI systems.\n",
      "\n",
      "**II. Addressing Potential Conflicts Between Principles:**\n",
      "\n",
      "Conflicts between these principles are inevitable. Here's how I would approach them:\n",
      "\n",
      "1.  **Prioritization Framework:**\n",
      "    *   **Hierarchy of Values:** While all principles are important, a hierarchy might be necessary in certain situations. Generally, **Human-Centricity** and **Fairness & Justice** should take precedence, as they directly relate to fundamental human rights and well-being.  However, the specific context will heavily influence the appropriate prioritization.\n",
      "    *   **Consequence Analysis:** Carefully analyze the potential consequences of prioritizing one principle over another in a specific situation.  Consider the short-term and long-term impacts on different stakeholders.\n",
      "\n",
      "2.  **Trade-off Analysis and Ethical Deliberation:**\n",
      "    *   **Stakeholder Engagement:** Involve diverse stakeholders (e.g., developers, ethicists, policymakers, affected communities) in the decision-making process.\n",
      "    *   **Ethical Frameworks and Tools:** Utilize established ethical frameworks (e.g., utilitarianism, deontology) to guide decision-making. Employ tools like ethical impact assessments to identify and evaluate potential ethical risks.\n",
      "    *   **Transparency in Trade-offs:** Clearly communicate the trade-offs that were made and the reasons behind them.  Document the decision-making process and the rationale for the chosen course of action.\n",
      "\n",
      "3.  **Context-Specific Application:**\n",
      "    *   **Domain-Specific Guidelines:** Develop specific ethical guidelines for different AI applications (e.g., healthcare AI, autonomous vehicles, facial recognition).  These guidelines should address the unique ethical challenges associated with each domain.\n",
      "    *   **Adaptive Framework:**  Recognize that the ethical framework must be adaptable and evolve as AI technology advances and societal values change.  Regularly review and update the framework based on new knowledge and experience.\n",
      "\n",
      "4.  **Technical Solutions:**\n",
      "    *   **Fairness-Aware Algorithms:**  Employ algorithms that are designed to mitigate bias and promote fairness.\n",
      "    *   **Explainable AI (XAI) Techniques:**  Develop and deploy XAI techniques to make AI decision-making more transparent and understandable.\n",
      "    *   **Privacy-Enhancing Technologies (PETs):**  Utilize PETs to protect individuals' privacy while still enabling the use of AI for beneficial purposes.\n",
      "\n",
      "**Examples of Conflict Resolution:**\n",
      "\n",
      "*   **Innovation vs. Privacy:**  Developing a new AI-powered surveillance system for crime prevention (innovation) might conflict with individuals' privacy rights.  The resolution could involve using privacy-enhancing technologies (e.g., differential privacy) to anonymize data, limiting the scope of surveillance, and establishing strict oversight mechanisms to prevent abuse.\n",
      "*   **Fairness vs. Accuracy:**  An AI system used for loan applications might be more accurate if it considers certain demographic factors, but this could lead to unfair discrimination.  The resolution could involve removing these demographic factors from the model, even if it slightly reduces accuracy, and using fairness-aware algorithms to mitigate bias.\n",
      "*   **Transparency vs. Security:**  Revealing the inner workings of an AI system (transparency) could make it more vulnerable to hacking or manipulation (security).  The resolution could involve providing explanations at a higher level of abstraction, without revealing sensitive details, and implementing robust security measures to protect the system from attack.\n",
      "\n",
      "**III. Implementation and Enforcement:**\n",
      "\n",
      "*   **Multi-Stakeholder Governance:** Establish a multi-stakeholder governance body to oversee the implementation and enforcement of the ethical framework. This body should include representatives from government, industry, academia, civil society, and the public.\n",
      "*   **Auditing and Certification:** Implement auditing and certification processes to ensure that AI systems comply with the ethical framework.\n",
      "*   **Regulatory Frameworks:** Develop appropriate regulatory frameworks to govern the development and deployment of AI systems. These frameworks should be flexible and adaptable to accommodate future technological advancements.\n",
      "*   **Education and Training:** Provide education and training to AI developers, users, and the public on the ethical implications of AI.\n",
      "*   **Public Dialogue:** Foster public dialogue and engagement on the ethical challenges and opportunities presented by AI.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Creating an effective ethical framework for AI is an ongoing process that requires collaboration, continuous learning, and a commitment to human-centricity, fairness, and transparency. This proposed framework, with its prioritized principles and strategies for conflict resolution, provides a foundation for building AI systems that benefit society while mitigating potential harms. It's crucial to remember that this framework is not a static document but rather a living document that must be regularly reviewed and updated to reflect the evolving landscape of AI technology and societal values.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"3\", \"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: claude-3-7-sonnet-latest\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
