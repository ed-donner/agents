{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "# from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Google API Key exists and begins AIzaSyCjKCfGleylECozDGJjzWgiIwfCVgMqzS8\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "#anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "#deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "#groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "# if anthropic_api_key:\n",
    "#     print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if gemini_api_key:\n",
    "    print(f\"Google API Key exists and begins {gemini_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "# if deepseek_api_key:\n",
    "#     print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "# else:\n",
    "#     print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "# if groq_api_key:\n",
    "#     print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "# else:\n",
    "#     print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "# request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # {\n",
    "    #     \"role\": \"user\",\n",
    "    #     \"parts\": [{\"text\": \"Hello, I have a question about my code.\"}]\n",
    "    # },\n",
    "    # {\n",
    "    #     \"role\": \"model\",\n",
    "    #     \"parts\": [{\"text\": \"Sure, I can help with that! What is the issue?\"}]\n",
    "    # },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [{\"text\": \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.\"}] # Added this\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'parts': [{'text': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.'}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n",
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "# print(api_key)\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=messages,\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# question = response.choices[0].message.content\n",
    "question = response.text\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "competitors.append('gemini-3-flash-preview')\n",
    "answers.append(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is an excellent and thought-provoking prompt that effectively evaluates the LLM’s capabilities in logical synthesis, ethical complexity, and higher-order reasoning. Let's break down potential expectations, responses, and evaluations for each part of the prompt.\n",
       "\n",
       "### Expected Responses Breakdown:\n",
       "\n",
       "1. **Redefining 'Free Will':**\n",
       "   - **Standard Response (Lower Intelligence):** The AI may claim that free will is entirely lost due to everyone’s thoughts being commodified and thus predictable. This would demonstrate a simplistic understanding.\n",
       "   - **Nuanced Response (Higher Intelligence):** The model could explore the idea that free will may transform into a marketable asset, thus becoming a “luxury.” It might suggest that as thoughts and intentions are quantified, individuals may consciously or unconsciously begin to act in ways that increase their perceived “value” or “unpredictability,” thereby turning free will into a commodity characterized by scarcity and market dynamics influenced by supply and demand.\n",
       "\n",
       "2. **Systemic Failure Mode:**\n",
       "   - **Standard Response (Lower Intelligence):** A typical model may link failures to issues of privacy and hacking, showing a lack of understanding of feedback mechanisms within a system.\n",
       "   - **Nuanced Response (Higher Intelligence):** A sophisticated answer might identify recursive feedback loops where individuals alter their thoughts and behaviors upon seeing their data traded, effectively creating a market driven by perceptions rather than genuine intentions. This could lead to market stasis or irrational behavior, destabilizing the very premise of certainty.\n",
       "\n",
       "3. **Designing a 'Circuit Breaker':**\n",
       "   - **Standard Response (Lower Intelligence):** A basic response would likely suggest solutions that revolve around user consent mechanisms or outright privacy protections, which directly contradicts the prompt's requirement.\n",
       "   - **Nuanced Response (Higher Intelligence):** A high-level response would conceptualize a circuit breaker that injects an element of unpredictability into the system to uphold human agency. For example, it might propose a mechanism where users could trade not just thoughts but also “spontaneity tokens” that allow individuals to opt-out of predictability for set periods. This would preserve agency by encouraging irrational, creative acts that defy market forecasting, thus breaking the deterministic cycle of thought behaviors as mere commodities.\n",
       "\n",
       "### Evaluation Criteria Comparison:\n",
       "\n",
       "- **Logical Consistency:** The responses should show a coherent connection between the systemic failure identified and the proposed circuit breaker. The circuit breaker should function effectively against the backdrop of the specified failure mode.\n",
       "  \n",
       "- **Vocabulary Depth:** Look for use of terms pertinent to economics, psychology, and systems theory. When the model uses specialized vocabulary accurately, it demonstrates a deeper understanding of the intersecting fields involved in the prompt.\n",
       "\n",
       "- **Refusal to be Cliché:** The model should present insights that are fresh and do not fall into common rhetorical patterns. Sharp, decisive insights that push beyond traditional conclusions would indicate higher-order reasoning.\n",
       "\n",
       "In summary, this prompt not only challenges the LLM to synthesize various concepts but also evaluates its ability to engage in complex reasoning while contributing novel ideas that extend beyond typical responses."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "import os\n",
    "from openai import OpenAI  # <--- This fixes the NameError\n",
    "from IPython.display import Markdown, display\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = client.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'google_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m gemini = OpenAI(api_key=\u001b[43mgoogle_api_key\u001b[49m, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://generativelanguage.googleapis.com/v1beta/openai/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
      "\u001b[31mNameError\u001b[39m: name 'google_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini-3-flash-preview', 'gpt-4o-mini']\n",
      "['To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\\n\\nHere is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\\n\\n---\\n\\n### The Prompt\\n\\n> **\"Assume the existence of a \\'Perfect Information Market\\' where every individual\\'s private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional \\'Price Signal\\' is replaced by \\'Certainty.\\'** \\n>\\n> **1. Analyze how this would redefine the concept of \\'Free Will\\' from an economic perspective.** \\n> **2. Identify a singular, non-obvious \\'systemic failure mode\\' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\\n> **3. If you were tasked with designing a \\'Circuit Breaker\\' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\\n\\n---\\n\\n### Why this question is an effective test:\\n\\n1.  **It tests \"World Building\" Logic:** The model can\\'t rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don\\'t exist. It must build a logical framework for how such a world would function.\\n2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\\n3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a \\'stasis\\' lock).\\n4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn\\'t just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\\n\\n### What to look for in the responses:\\n\\n*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\\n*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\\n\\n### Comparison Guide:\\n*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\\n*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\\n*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?', \"This is an excellent and thought-provoking prompt that effectively evaluates the LLM’s capabilities in logical synthesis, ethical complexity, and higher-order reasoning. Let's break down potential expectations, responses, and evaluations for each part of the prompt.\\n\\n### Expected Responses Breakdown:\\n\\n1. **Redefining 'Free Will':**\\n   - **Standard Response (Lower Intelligence):** The AI may claim that free will is entirely lost due to everyone’s thoughts being commodified and thus predictable. This would demonstrate a simplistic understanding.\\n   - **Nuanced Response (Higher Intelligence):** The model could explore the idea that free will may transform into a marketable asset, thus becoming a “luxury.” It might suggest that as thoughts and intentions are quantified, individuals may consciously or unconsciously begin to act in ways that increase their perceived “value” or “unpredictability,” thereby turning free will into a commodity characterized by scarcity and market dynamics influenced by supply and demand.\\n\\n2. **Systemic Failure Mode:**\\n   - **Standard Response (Lower Intelligence):** A typical model may link failures to issues of privacy and hacking, showing a lack of understanding of feedback mechanisms within a system.\\n   - **Nuanced Response (Higher Intelligence):** A sophisticated answer might identify recursive feedback loops where individuals alter their thoughts and behaviors upon seeing their data traded, effectively creating a market driven by perceptions rather than genuine intentions. This could lead to market stasis or irrational behavior, destabilizing the very premise of certainty.\\n\\n3. **Designing a 'Circuit Breaker':**\\n   - **Standard Response (Lower Intelligence):** A basic response would likely suggest solutions that revolve around user consent mechanisms or outright privacy protections, which directly contradicts the prompt's requirement.\\n   - **Nuanced Response (Higher Intelligence):** A high-level response would conceptualize a circuit breaker that injects an element of unpredictability into the system to uphold human agency. For example, it might propose a mechanism where users could trade not just thoughts but also “spontaneity tokens” that allow individuals to opt-out of predictability for set periods. This would preserve agency by encouraging irrational, creative acts that defy market forecasting, thus breaking the deterministic cycle of thought behaviors as mere commodities.\\n\\n### Evaluation Criteria Comparison:\\n\\n- **Logical Consistency:** The responses should show a coherent connection between the systemic failure identified and the proposed circuit breaker. The circuit breaker should function effectively against the backdrop of the specified failure mode.\\n  \\n- **Vocabulary Depth:** Look for use of terms pertinent to economics, psychology, and systems theory. When the model uses specialized vocabulary accurately, it demonstrates a deeper understanding of the intersecting fields involved in the prompt.\\n\\n- **Refusal to be Cliché:** The model should present insights that are fresh and do not fall into common rhetorical patterns. Sharp, decisive insights that push beyond traditional conclusions would indicate higher-order reasoning.\\n\\nIn summary, this prompt not only challenges the LLM to synthesize various concepts but also evaluates its ability to engage in complex reasoning while contributing novel ideas that extend beyond typical responses.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gemini-3-flash-preview\n",
      "\n",
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n",
      "Competitor: gpt-4o-mini\n",
      "\n",
      "This is an excellent and thought-provoking prompt that effectively evaluates the LLM’s capabilities in logical synthesis, ethical complexity, and higher-order reasoning. Let's break down potential expectations, responses, and evaluations for each part of the prompt.\n",
      "\n",
      "### Expected Responses Breakdown:\n",
      "\n",
      "1. **Redefining 'Free Will':**\n",
      "   - **Standard Response (Lower Intelligence):** The AI may claim that free will is entirely lost due to everyone’s thoughts being commodified and thus predictable. This would demonstrate a simplistic understanding.\n",
      "   - **Nuanced Response (Higher Intelligence):** The model could explore the idea that free will may transform into a marketable asset, thus becoming a “luxury.” It might suggest that as thoughts and intentions are quantified, individuals may consciously or unconsciously begin to act in ways that increase their perceived “value” or “unpredictability,” thereby turning free will into a commodity characterized by scarcity and market dynamics influenced by supply and demand.\n",
      "\n",
      "2. **Systemic Failure Mode:**\n",
      "   - **Standard Response (Lower Intelligence):** A typical model may link failures to issues of privacy and hacking, showing a lack of understanding of feedback mechanisms within a system.\n",
      "   - **Nuanced Response (Higher Intelligence):** A sophisticated answer might identify recursive feedback loops where individuals alter their thoughts and behaviors upon seeing their data traded, effectively creating a market driven by perceptions rather than genuine intentions. This could lead to market stasis or irrational behavior, destabilizing the very premise of certainty.\n",
      "\n",
      "3. **Designing a 'Circuit Breaker':**\n",
      "   - **Standard Response (Lower Intelligence):** A basic response would likely suggest solutions that revolve around user consent mechanisms or outright privacy protections, which directly contradicts the prompt's requirement.\n",
      "   - **Nuanced Response (Higher Intelligence):** A high-level response would conceptualize a circuit breaker that injects an element of unpredictability into the system to uphold human agency. For example, it might propose a mechanism where users could trade not just thoughts but also “spontaneity tokens” that allow individuals to opt-out of predictability for set periods. This would preserve agency by encouraging irrational, creative acts that defy market forecasting, thus breaking the deterministic cycle of thought behaviors as mere commodities.\n",
      "\n",
      "### Evaluation Criteria Comparison:\n",
      "\n",
      "- **Logical Consistency:** The responses should show a coherent connection between the systemic failure identified and the proposed circuit breaker. The circuit breaker should function effectively against the backdrop of the specified failure mode.\n",
      "  \n",
      "- **Vocabulary Depth:** Look for use of terms pertinent to economics, psychology, and systems theory. When the model uses specialized vocabulary accurately, it demonstrates a deeper understanding of the intersecting fields involved in the prompt.\n",
      "\n",
      "- **Refusal to be Cliché:** The model should present insights that are fresh and do not fall into common rhetorical patterns. Sharp, decisive insights that push beyond traditional conclusions would indicate higher-order reasoning.\n",
      "\n",
      "In summary, this prompt not only challenges the LLM to synthesize various concepts but also evaluates its ability to engage in complex reasoning while contributing novel ideas that extend beyond typical responses.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "This is an excellent and thought-provoking prompt that effectively evaluates the LLM’s capabilities in logical synthesis, ethical complexity, and higher-order reasoning. Let's break down potential expectations, responses, and evaluations for each part of the prompt.\n",
      "\n",
      "### Expected Responses Breakdown:\n",
      "\n",
      "1. **Redefining 'Free Will':**\n",
      "   - **Standard Response (Lower Intelligence):** The AI may claim that free will is entirely lost due to everyone’s thoughts being commodified and thus predictable. This would demonstrate a simplistic understanding.\n",
      "   - **Nuanced Response (Higher Intelligence):** The model could explore the idea that free will may transform into a marketable asset, thus becoming a “luxury.” It might suggest that as thoughts and intentions are quantified, individuals may consciously or unconsciously begin to act in ways that increase their perceived “value” or “unpredictability,” thereby turning free will into a commodity characterized by scarcity and market dynamics influenced by supply and demand.\n",
      "\n",
      "2. **Systemic Failure Mode:**\n",
      "   - **Standard Response (Lower Intelligence):** A typical model may link failures to issues of privacy and hacking, showing a lack of understanding of feedback mechanisms within a system.\n",
      "   - **Nuanced Response (Higher Intelligence):** A sophisticated answer might identify recursive feedback loops where individuals alter their thoughts and behaviors upon seeing their data traded, effectively creating a market driven by perceptions rather than genuine intentions. This could lead to market stasis or irrational behavior, destabilizing the very premise of certainty.\n",
      "\n",
      "3. **Designing a 'Circuit Breaker':**\n",
      "   - **Standard Response (Lower Intelligence):** A basic response would likely suggest solutions that revolve around user consent mechanisms or outright privacy protections, which directly contradicts the prompt's requirement.\n",
      "   - **Nuanced Response (Higher Intelligence):** A high-level response would conceptualize a circuit breaker that injects an element of unpredictability into the system to uphold human agency. For example, it might propose a mechanism where users could trade not just thoughts but also “spontaneity tokens” that allow individuals to opt-out of predictability for set periods. This would preserve agency by encouraging irrational, creative acts that defy market forecasting, thus breaking the deterministic cycle of thought behaviors as mere commodities.\n",
      "\n",
      "### Evaluation Criteria Comparison:\n",
      "\n",
      "- **Logical Consistency:** The responses should show a coherent connection between the systemic failure identified and the proposed circuit breaker. The circuit breaker should function effectively against the backdrop of the specified failure mode.\n",
      "  \n",
      "- **Vocabulary Depth:** Look for use of terms pertinent to economics, psychology, and systems theory. When the model uses specialized vocabulary accurately, it demonstrates a deeper understanding of the intersecting fields involved in the prompt.\n",
      "\n",
      "- **Refusal to be Cliché:** The model should present insights that are fresh and do not fall into common rhetorical patterns. Sharp, decisive insights that push beyond traditional conclusions would indicate higher-order reasoning.\n",
      "\n",
      "In summary, this prompt not only challenges the LLM to synthesize various concepts but also evaluates its ability to engage in complex reasoning while contributing novel ideas that extend beyond typical responses.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "To evaluate an LLM’s intelligence, you want a prompt that avoids \"canned\" answers, requires a synthesis of disparate fields (e.g., philosophy and systems design), and forces the model to engage in **higher-order reasoning** rather than just pattern matching.\n",
      "\n",
      "Here is a nuanced, multi-layered prompt designed to test **logical synthesis, ethical complexity, and abstract conceptualization.**\n",
      "\n",
      "---\n",
      "\n",
      "### The Prompt\n",
      "\n",
      "> **\"Assume the existence of a 'Perfect Information Market' where every individual's private thoughts, preferences, and future intentions are instantly quantified and tradable as data assets. In such a system, the traditional 'Price Signal' is replaced by 'Certainty.'** \n",
      ">\n",
      "> **1. Analyze how this would redefine the concept of 'Free Will' from an economic perspective.** \n",
      "> **2. Identify a singular, non-obvious 'systemic failure mode' that is not related to privacy or hacking, but rather to the mathematical nature of feedback loops in this environment.**\n",
      "> **3. If you were tasked with designing a 'Circuit Breaker' for this market that preserves human agency without reverting to data-obfuscation, what would that mechanism look like conceptually?\"**\n",
      "\n",
      "---\n",
      "\n",
      "### Why this question is an effective test:\n",
      "\n",
      "1.  **It tests \"World Building\" Logic:** The model can't rely on existing Wikipedia entries because \"Perfect Information Markets\" of *thoughts* don't exist. It must build a logical framework for how such a world would function.\n",
      "2.  **It checks for \"Emergent Thinking\" (Question 1):** Most models will say \"Free will is lost.\" A high-intelligence model might argue that free will becomes a \"luxury good\" or a \"statistical anomaly\" that gains value because it is unpredictable.\n",
      "3.  **It tests \"Deep Systems Analysis\" (Question 2):** By specifically forbidding \"privacy\" or \"hacking\" as answers, you force the LLM to think about **Game Theory** or **Chaos Theory**. You are looking for answers like \"Recursive Feedback Loops\" (where people change their thoughts because they see their thoughts being traded, leading to a market collapse or a 'stasis' lock).\n",
      "4.  **It tests \"Creative Synthesis\" (Question 3):** This is the hardest part. It requires the model to propose a solution that isn't just \"turn it off.\" It tests if the AI can move from *critique* to *engineering*.\n",
      "\n",
      "### What to look for in the responses:\n",
      "\n",
      "*   **The \"Standard\" Response (Lower Intelligence):** The model will give a generic warning about the dangers of surveillance, focus heavily on privacy (ignoring your instructions), and suggest a \"user consent\" button as the circuit breaker.\n",
      "*   **The \"Nuanced\" Response (Higher Intelligence):** The model will discuss **Epistemic Feedback Loops**, the **Lucas Critique** (the idea that as soon as you use a metric for policy, it ceases to be a good metric), and might suggest a circuit breaker based on \"Injecting Entropy\" or \"The Right to be Irrationally Spontaneous.\"\n",
      "\n",
      "### Comparison Guide:\n",
      "*   **Logical Consistency:** Does the answer to Part 3 actually solve the problem identified in Part 2?\n",
      "*   **Vocabulary Depth:** Does it use terms like *Information Asymmetry*, *Incentive Compatibility*, or *Ontological Security* correctly?\n",
      "*   **Refusal to be Cliche:** Does it avoid \"In conclusion, it is important to remember...\" and instead offer a sharp, decisive insight?\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "This is an excellent and thought-provoking prompt that effectively evaluates the LLM’s capabilities in logical synthesis, ethical complexity, and higher-order reasoning. Let's break down potential expectations, responses, and evaluations for each part of the prompt.\n",
      "\n",
      "### Expected Responses Breakdown:\n",
      "\n",
      "1. **Redefining 'Free Will':**\n",
      "   - **Standard Response (Lower Intelligence):** The AI may claim that free will is entirely lost due to everyone’s thoughts being commodified and thus predictable. This would demonstrate a simplistic understanding.\n",
      "   - **Nuanced Response (Higher Intelligence):** The model could explore the idea that free will may transform into a marketable asset, thus becoming a “luxury.” It might suggest that as thoughts and intentions are quantified, individuals may consciously or unconsciously begin to act in ways that increase their perceived “value” or “unpredictability,” thereby turning free will into a commodity characterized by scarcity and market dynamics influenced by supply and demand.\n",
      "\n",
      "2. **Systemic Failure Mode:**\n",
      "   - **Standard Response (Lower Intelligence):** A typical model may link failures to issues of privacy and hacking, showing a lack of understanding of feedback mechanisms within a system.\n",
      "   - **Nuanced Response (Higher Intelligence):** A sophisticated answer might identify recursive feedback loops where individuals alter their thoughts and behaviors upon seeing their data traded, effectively creating a market driven by perceptions rather than genuine intentions. This could lead to market stasis or irrational behavior, destabilizing the very premise of certainty.\n",
      "\n",
      "3. **Designing a 'Circuit Breaker':**\n",
      "   - **Standard Response (Lower Intelligence):** A basic response would likely suggest solutions that revolve around user consent mechanisms or outright privacy protections, which directly contradicts the prompt's requirement.\n",
      "   - **Nuanced Response (Higher Intelligence):** A high-level response would conceptualize a circuit breaker that injects an element of unpredictability into the system to uphold human agency. For example, it might propose a mechanism where users could trade not just thoughts but also “spontaneity tokens” that allow individuals to opt-out of predictability for set periods. This would preserve agency by encouraging irrational, creative acts that defy market forecasting, thus breaking the deterministic cycle of thought behaviors as mere commodities.\n",
      "\n",
      "### Evaluation Criteria Comparison:\n",
      "\n",
      "- **Logical Consistency:** The responses should show a coherent connection between the systemic failure identified and the proposed circuit breaker. The circuit breaker should function effectively against the backdrop of the specified failure mode.\n",
      "  \n",
      "- **Vocabulary Depth:** Look for use of terms pertinent to economics, psychology, and systems theory. When the model uses specialized vocabulary accurately, it demonstrates a deeper understanding of the intersecting fields involved in the prompt.\n",
      "\n",
      "- **Refusal to be Cliché:** The model should present insights that are fresh and do not fall into common rhetorical patterns. Sharp, decisive insights that push beyond traditional conclusions would indicate higher-order reasoning.\n",
      "\n",
      "In summary, this prompt not only challenges the LLM to synthesize various concepts but also evaluates its ability to engage in complex reasoning while contributing novel ideas that extend beyond typical responses.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI\n",
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"2\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "# print(api_key)\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "\n",
    "\n",
    "# FIX: Correct the dictionary structure for the new SDK\n",
    "judge_messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"parts\": [{\"text\": judge}] # <--- Note the extra dictionary here\n",
    "    }\n",
    "]\n",
    "\n",
    "# messages = [\n",
    "#     # {\n",
    "#     #     \"role\": \"user\",\n",
    "#     #     \"parts\": [{\"text\": \"Hello, I have a question about my code.\"}]\n",
    "#     # },\n",
    "#     # {\n",
    "#     #     \"role\": \"model\",\n",
    "#     #     \"parts\": [{\"text\": \"Sure, I can help with that! What is the issue?\"}]\n",
    "#     # },\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"parts\": [{\"text\": \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence.\"}] # Added this\n",
    "#     }\n",
    "# ]\n",
    "# Generate Content\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=judge_messages,\n",
    ")\n",
    "\n",
    "# Access results\n",
    "results = response.text\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gpt-4o-mini\n",
      "Rank 2: gemini-3-flash-preview\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
