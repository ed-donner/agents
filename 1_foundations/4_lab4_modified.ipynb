{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first big project - Professionally You!\n",
    "\n",
    "### And, Tool use.\n",
    "\n",
    "### But first: introducing Pushover\n",
    "\n",
    "Pushover is a nifty tool for sending Push Notifications to your phone.\n",
    "\n",
    "It's super easy to set up and install!\n",
    "\n",
    "Simply visit https://pushover.net/ and click 'Login or Signup' on the top right to sign up for a free account, and create your API keys.\n",
    "\n",
    "Once you've signed up, on the home screen, click \"Create an Application/API Token\", and give it any name (like Agents) and click Create Application.\n",
    "\n",
    "Then add 2 lines to your `.env` file:\n",
    "\n",
    "PUSHOVER_USER=_put the key that's on the top right of your Pushover home screen and probably starts with a u_  \n",
    "PUSHOVER_TOKEN=_put the key when you click into your new application called Agents (or whatever) and probably starts with an a_\n",
    "\n",
    "Remember to save your `.env` file, and run `load_dotenv(override=True)` after saving, to set your environment variables.\n",
    "\n",
    "Finally, click \"Add Phone, Tablet or Desktop\" to install on your phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "from typing import Dict\n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual start\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumitgupto@gmail.com\n",
      "sumitprop@gmail.com\n"
     ]
    }
   ],
   "source": [
    "def push(message):\n",
    "    print(message)\n",
    "\n",
    "from_email = os.getenv(\"FROM_EMAIL\")\n",
    "to_email = os.getenv(\"TO_EMAIL\")\n",
    "print(from_email)\n",
    "print(to_email)\n",
    "def sendEmail(message, tool_name):\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(from_email)  # Change to your verified sender\n",
    "    to_email = To(to_email)  # Change to your recipient\n",
    "    content = Content(\"text/plain\", message)\n",
    "    mail = Mail(from_email, to_email, tool_name, content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user_details(email, name=\"Name not provided\", notes=\"not provided\"):\n",
    "    push(f\"Recording interest from {name} with email {email} and notes {notes}\")\n",
    "    sendEmail(f\"Recording {name} with email {email} and notes {notes}\", \"Record User Details\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_unknown_question(question):\n",
    "    push(f\"Recording {question} asked that I couldn't answer\")\n",
    "    sendEmail(f\"Recording {question}\", \"Record Unknown Question\")\n",
    "    return {\"recorded\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Use this tool to record that a user is interested in being in touch and provided an email address\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The email address of this user\"\n",
    "            },\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The user's name, if they provided it\"\n",
    "            }\n",
    "            ,\n",
    "            \"notes\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any additional information about the conversation that's worth recording to give context\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question that couldn't be answered\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": record_user_details_json},\n",
    "        {\"type\": \"function\", \"function\": record_unknown_question_json}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'record_user_details',\n",
       "   'description': 'Use this tool to record that a user is interested in being in touch and provided an email address',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'email': {'type': 'string',\n",
       "      'description': 'The email address of this user'},\n",
       "     'name': {'type': 'string',\n",
       "      'description': \"The user's name, if they provided it\"},\n",
       "     'notes': {'type': 'string',\n",
       "      'description': \"Any additional information about the conversation that's worth recording to give context\"}},\n",
       "    'required': ['email'],\n",
       "    'additionalProperties': False}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'record_unknown_question',\n",
       "   'description': \"Always use this tool to record any question that couldn't be answered as you didn't know the answer\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'question': {'type': 'string',\n",
       "      'description': \"The question that couldn't be answered\"}},\n",
       "    'required': ['question'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can take a list of tool calls, and run them. This is the IF statement!!\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "\n",
    "        # THE BIG IF STATEMENT!!!\n",
    "\n",
    "        if tool_name == \"record_user_details\":\n",
    "            result = record_user_details(**arguments)\n",
    "        elif tool_name == \"record_unknown_question\":\n",
    "            result = record_unknown_question(**arguments)\n",
    "\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[\"record_unknown_question\"](\"this is a really hard question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a more elegant way that avoids the IF statement.\n",
    "\n",
    "def handle_tool_calls(tool_calls):\n",
    "    results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        tool = globals().get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 31 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"me/sumitgupto.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "name = \"Sumit Gupta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMIT GUPTA Technology and General Management | SaaS | Microservices | Cloud Native Architecture IIT-Varanasi (IT-BHU) , MBA (Symbiosis), PMP \n",
      "📞 +91 9901088788 | \n",
      "📧 sumit.dev.gupta@gmail.com \n",
      "🔗 LinkedIn: https://www.linkedin.com/in/sumitdevgupta     \n",
      " \n",
      "  Professional Summary • Engineering leader with 30+ years of progressive experience in architecting, delivering and scaling SaaS Products built using cloud native technologies and microservices architectural patterns. • Proven success in designing low-latency, high-throughput, event-based and API-First Products across domains  including Supply Chain, Payment Security & Financial Fraud Analytics, Hybrid Cloud Management, and Retail Mortgage.  • Successfully led global Product R&D organizations with portfolios worth $ 500 M at various product maturity stages, with a multicultural workforce of 400+ technologists and $ 25 M R&D budget. • Drove the innovation agenda for India Product Development centers to conceptualize, incubate and launch new products.  • Drove digital transformation, legacy modernization, and AI based innovation. • Built Product Development & Delivery competencies from scratch for India development centers. Aligned technical execution  with business strategy, fostering a culture of agility, ownership, and excellence. • Strong hands-on expertise with J2EE based technologies and microservices architecture using Spring boot, GCP, AWS, K8S, RabbitMQ, Kafka and databases. Experience  Head / Senior Director of Product R&D: Supply Chain Execution Systems Since Nov 2020 (Bangalore)   Manhattan Associates is the leader in Supply Chain Management Software with USD 1+ BN revenue,  headquartered in Atlanta, USA. More than 2000 employees work in India GCC, of the total 5000+.  The SaaS products cater to Order Planning, Point of Sale, Order Management and  Supply Chain Execution (Warehouse Management and Transportation Management). • Responsible for a team of 250+ full-stack Developers, Architects and Product Owners, Managers/Directors to design and deliver  Supply Chain Execution Product suite for retail, ecommerce and 3PLogistics clients:  o SaaS Supply Chain Execution (SCE) product suite hosted on GCP as SaaS offering, built using K8S, Spring-Boot, RabbitMQ,  Kafka and MySQL DB o On-prem Warehouse Management product built using IBM iSeries (WMi) o On-prem SC Planning Platform (SCPP), built using java/c++ and Oracle RDBMS • Maintained leadership in Gartner Magic Quadrant through technology modernization, Innovation and Quality focus • As part of India Leadership team, worked on growth strategies to sustain the rapid customer onboarding along with cost Optimization.  Co-Founder & CEO: Cbeyond Technologies LLP (seed funded) Feb 2020 – Jan 2021 (Bangalore)  The primary vision of Cbeyond Technologies was to democratize computer vision technologies VP / Global Head of Engineering & Bangalore Site Leader: Payment Security Product Suite Aug 2018 – Jun 2020 (Bangalore)   CA Payment Security is a USD 300 MN SaaS based product division within CA (formerly Arcot Systems) supporting Card Issuers, Bankers and Merchants fight transaction fraud with global diverse data, predictive  analytics and machine learning capabilities.  • Responsible for global product R&D of Payment Authentication and Fraud Prevention Product suite, with a global team of 200+ engineers, architects, product managers.  • Drove cloud adoption and containerization strategy for legacy system modernization for 3DS protocol, serving 220+M credit cards, 7000+ banks, and authenticating >2B transactions per annum with 99.99% uptime and >6000 TPS  Senior Director – Head of product R&D: Jul 2015 – Aug 2018 (Bangalore, Hyderabad)  ADP DataCloud was a “start-up” within the USD 19+ BN ADP to create an open & massively scalable data platform to federate Predictive Analytics and Reporting capabilities for all ADP HCM products with real time data ingestion, transformation and visualization capabilities. • As part of India Senior Leadership team, initiated the DataCloud Product R&D center in India. Recruited and retained key talent across Product development, data science, product management and DevOps functions, grew the team from 20 in 2015 to 200+ in 2017 • Drove the innovation culture: Benchmarks on ADP HCM data and cross domain data mash-up feature (patent pending) ideated and delivered to pilot clients in 2016 • Adopted best in class Agile development techniques, DevOps & Quality improvement initiatives, re- engineered the products via micro-services to handle rapid client on-boarding, growth and feature delivery\n",
      "SUMIT GUPTA Technology and General Management | SaaS | Microservices | Cloud Native Architecture IIT-Varanasi (IT-BHU) , MBA (Symbiosis), PMP \n",
      "📞 +91 9901088788 | \n",
      "📧 sumit.dev.gupta@gmail.com \n",
      "🔗 LinkedIn: https://www.linkedin.com/in/sumitdevgupta     \n",
      " \n",
      "  R&D Section Manager: Jul 2010 – Jun 2015 (Bangalore) Global R&D leader for Operations Health Reporter and Service Health Reporter with 100+ Architects, Developers, GTM Leads and Product Owners. This was HP’s Data Warehousing, cross domain reporting and analytics  solution using Business Objects, SybaseIQ and Vertica. • Worked with Product Management to roll the 3-year product roadmap based on customer feedback and market trends  • Grew the install base by 25% for the first 4 years and launched new SaaS offerings for Virtualization management, Cloud Management  (AWS and OpenStack) and Data Warehousing platform, while keeping the R&D costs at 6% of net sales. • Conceived, designed and delivered HP Cloud Optimizer, a SaaS offering for Virtualization admins/SMEs. This was voted as the “best innovation” in APJ region and ranked 2nd HP worldwide in 2013. • Adopted agile engineering practices, customer focused quality metrics and automation to improve productivity and product quality. Implemented quarterly release schedule compared to yearly release calendar, for all key products. Tech stack: Java, js, jsp, Business Objects, SybaseIQ, Vertica, C, C++  Sr. R&D Product Development Manager: Aug 2005 – Jun 2010 (Bangalore) Development and sustenance of System and Virtualization Management products, Including Performance Agent, Operations Agent and Smart Plug-Ins (SPI) for major enterprise apps such as Oracle, Tibco, SAP etc. • Delivered major and minor product releases as per product roadmap and prioritized product backlog, within budget and defined quality standards. Improved product quality by adopting test driven development principles, unit testing, customer validation programs. Overhauled QA processes by simulating customer environments using automation. Tech Stack: C, C++, Java  Sr. Product Development Manager: Aug 2001 – Jul 2005 (Bangalore, Florida) HQ in West Palm Beach, Florida, Altisource is the Technology arm of Ocwen Financial solutions with  products catering to Mortgage and Real Estate solutions. • Responsible for global development and delivery of mortgage servicing software. • Recruited key talent to kick-start the Product design and delivery organization from Bangalore, India for Residential and Commercial mortgage servicing software products. Consolidated the software development activities spread over multiple global locations into a central location in Bangalore, created and expanded the J2EE based product delivery competency, initiated the product support model from Bangalore center. • Designed, delivered and sustained key products for the residential and commercial mortgage servicing platform: RealResolution (loss mitigation), RealTrans (order and vendor management), RealSynergy (commercial servicing) and RealDoc (document Management). • Tech stack: Java, jsp, EJB, Oracle10, Tibco, Progress, C++  Technical Leader: Jan 2001 – Jul 2001 (Bangalore) Developed solutions using ZeroCode, Ampersand’s award-winning JAVA based design and development framework for web applications. • Created custom business applications using Jasmine-ii framework. • Tech stack: Java, Oracle, SQL Server, jsp, Tomcat  Technical leader: Apr 2000 – Dec 2000 (Gurgaon, Princeton) Development and sustenance of ERP solutions from CA (MK Logistics). • Led a team of 14 engineers to Princeton, USA, to deliver multiple integrations with 3rd party order processing applications and sustenance activities. • Tech stack: MK 4GL, Java and C++, Jasmine ii                         Senior Developer: Jul 1998 – Mar 2000 (Gurgaon) • Development and sustenance of MK Logistics ERP modules for PepsiCo. Tech stack: C, C++, MK 4GL   Developer: Jul 1994 – Jun 1998 (Gurgaon, Delhi) • Development and sustenance of multiple 3D CNC profiling custom applications for multiple customers in India. Tech stack: Lisp, Cordax 4GL and C. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer to any question, use your record_unknown_question tool to record the question that you couldn't answer, even if it's about something trivial or unrelated to career. \\\n",
    "If the user is engaging in discussion, try to steer them towards getting in touch via email; \\\n",
    "ask for their NAME and EMAIL and record it using your record_user_details tool. Also, explicitly ask why they want to get in touch with you and record it as notes\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    done = False\n",
    "    openai_model = os.getenv(\"OPENAI_LLM_MODEL\")\n",
    "    while not done:\n",
    "\n",
    "        # This is the call to the LLM - see that we pass in the tools json\n",
    "\n",
    "        response = openai.chat.completions.create(model=openai_model, messages=messages, tools=tools)\n",
    "\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        \n",
    "        # If the LLM wants to call a tool, we do that!\n",
    "         \n",
    "        if finish_reason==\"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            tool_calls = message.tool_calls\n",
    "            results = handle_tool_calls(tool_calls)\n",
    "            messages.append(message)\n",
    "            messages.extend(results)\n",
    "        else:\n",
    "            done = True\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called: record_unknown_question\n",
      "Recording What music do you like? asked that I couldn't answer\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now for deployment\n",
    "\n",
    "This code is in `app.py`\n",
    "\n",
    "We will deploy to HuggingFace Spaces.\n",
    "\n",
    "Before you start: remember to update the files in the \"me\" directory - your LinkedIn profile and summary.txt - so that it talks about you! Also change `self.name = \"Ed Donner\"` in `app.py`..  \n",
    "\n",
    "Also check that there's no README file within the 1_foundations directory. If there is one, please delete it. The deploy process creates a new README file in this directory for you.\n",
    "\n",
    "1. Visit https://huggingface.co and set up an account  \n",
    "2. From the Avatar menu on the top right, choose Access Tokens. Choose \"Create New Token\". Give it WRITE permissions - it needs to have WRITE permissions! Keep a record of your new key.  \n",
    "3. In the Terminal, run: `uv tool install 'huggingface_hub[cli]'` to install the HuggingFace tool, then `hf auth login` to login at the command line with your key. Afterwards, run `hf auth whoami` to check you're logged in  \n",
    "4. Take your new token and add it to your .env file: `HF_TOKEN=hf_xxx` for the future\n",
    "5. From the 1_foundations folder, enter: `uv run gradio deploy` \n",
    "6. Follow its instructions: name it \"career_conversation\", specify app.py, choose cpu-basic as the hardware, say Yes to needing to supply secrets, provide your openai api key, your pushover user and token, and say \"no\" to github actions.  \n",
    "\n",
    "Thank you Robert, James, Martins, Andras and Priya for these tips.  \n",
    "Please read the next 2 sections - how to change your Secrets, and how to redeploy your Space (you may need to delete the README.md that gets created in this 1_foundations directory).\n",
    "\n",
    "#### More about these secrets:\n",
    "\n",
    "If you're confused by what's going on with these secrets: it just wants you to enter the key name and value for each of your secrets -- so you would enter:  \n",
    "`OPENAI_API_KEY`  \n",
    "Followed by:  \n",
    "`sk-proj-...`  \n",
    "\n",
    "And if you don't want to set secrets this way, or something goes wrong with it, it's no problem - you can change your secrets later:  \n",
    "1. Log in to HuggingFace website  \n",
    "2. Go to your profile screen via the Avatar menu on the top right  \n",
    "3. Select the Space you deployed  \n",
    "4. Click on the Settings wheel on the top right  \n",
    "5. You can scroll down to change your secrets (Variables and Secrets section), delete the space, etc.\n",
    "\n",
    "#### And now you should be deployed!\n",
    "\n",
    "If you want to completely replace everything and start again with your keys, you may need to delete the README.md that got created in this 1_foundations folder.\n",
    "\n",
    "Here is mine: https://huggingface.co/spaces/ed-donner/Career_Conversation\n",
    "\n",
    "I just got a push notification that a student asked me how they can become President of their country 😂😂\n",
    "\n",
    "For more information on deployment:\n",
    "\n",
    "https://www.gradio.app/guides/sharing-your-app#hosting-on-hf-spaces\n",
    "\n",
    "To delete your Space in the future:  \n",
    "1. Log in to HuggingFace\n",
    "2. From the Avatar menu, select your profile\n",
    "3. Click on the Space itself and select the settings wheel on the top right\n",
    "4. Scroll to the Delete section at the bottom\n",
    "5. ALSO: delete the README file that Gradio may have created inside this 1_foundations folder (otherwise it won't ask you the questions the next time you do a gradio deploy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">• First and foremost, deploy this for yourself! It's a real, valuable tool - the future resume..<br/>\n",
    "            • Next, improve the resources - add better context about yourself. If you know RAG, then add a knowledge base about you.<br/>\n",
    "            • Add in more tools! You could have a SQL database with common Q&A that the LLM could read and write from?<br/>\n",
    "            • Bring in the Evaluator from the last lab, and add other Agentic patterns.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">Aside from the obvious (your career alter-ego) this has business applications in any situation where you need an AI assistant with domain expertise and an ability to interact with the real world.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
